{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","collapsed_sections":["CsZYuP9onEl1","B--CLs46QMLR","daZm9aPyRUAM","0Pe8VJFxQSS7","6o91I0EXQaF4"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["### setup"],"metadata":{"id":"CsZYuP9onEl1"}},{"cell_type":"code","source":["!pip install Levenshtein\n","!pip install einops\n","!pip install einops_exts\n","!pip install torch\n","!pip install transformers\n","!pip install tqdm\n","!pip install sentencepiece\n","# !pip install fair-esm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"CpeO8QHj-_z5","outputId":"a89e700d-1d44-4f1e-91a7-ac8ccaff23a1","executionInfo":{"status":"ok","timestamp":1739121787811,"user_tz":480,"elapsed":15012,"user":{"displayName":"Venkata Srikar Kavirayuni","userId":"10910189441313353201"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: Levenshtein in /usr/local/lib/python3.11/dist-packages (0.26.1)\n","Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in /usr/local/lib/python3.11/dist-packages (from Levenshtein) (3.12.1)\n","Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.0)\n","Requirement already satisfied: einops_exts in /usr/local/lib/python3.11/dist-packages (0.0.4)\n","Requirement already satisfied: einops>=0.4 in /usr/local/lib/python3.11/dist-packages (from einops_exts) (0.8.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import GPT2LMHeadModel, GPT2Tokenizer\n","import pandas as pd\n","import re\n","import math\n","import json\n","from tqdm import tqdm\n","from einops import rearrange, repeat\n","# import esm\n","\n","# Set up GPU if available\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Using device: {device}\")\n","\n","# # Load ESM-2 model\n","# esm_model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n","# batch_converter = alphabet.get_batch_converter()\n","# esm_model = esm_model.to(device)  # Move to GPU if available\n","# esm_model.eval()  # Set to evaluation mode\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"CYInyPD_--Vo","outputId":"c65eb1e1-19b1-46ec-ca89-fd403bec2da5","executionInfo":{"status":"ok","timestamp":1739121795596,"user_tz":480,"elapsed":7783,"user":{"displayName":"Venkata Srikar Kavirayuni","userId":"10910189441313353201"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}]},{"cell_type":"markdown","source":["### data"],"metadata":{"id":"B--CLs46QMLR"}},{"cell_type":"code","source":["def preprocess_snp_data(file_path):\n","    snp_df = pd.read_csv(file_path)\n","\n","    # Basic preprocessing and length calculations\n","    snp_df['smiles_length'] = snp_df['smiles'].apply(len)\n","    snp_df['protein_length'] = snp_df['protein_sequence'].apply(len)\n","\n","    return snp_df\n","\n","def filter_datasets(dataset):\n","    return dataset[\n","        (dataset['smiles'].notna()) &\n","        (dataset['protein_sequence'].notna()) &\n","        (dataset['smiles_length'] > 0) &\n","        (dataset['protein_length'] > 0)\n","    ]\n","\n","class ProteinGenerationDataset(Dataset):\n","    def __init__(self, dataframe, max_length):\n","        self.dataframe = dataframe\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.dataframe)\n","\n","    def __getitem__(self, idx):\n","        row = self.dataframe.iloc[idx]\n","        return row['smiles'], row['protein_sequence']\n","\n","def collate_fn(batch):\n","    \"\"\"\n","    Custom collate function to handle padding within batches.\n","    Args:\n","        batch: List of tuples (smiles, protein)\n","    Returns:\n","        Padded and batched tensors\n","    \"\"\"\n","    smiles, proteins = zip(*batch)\n","\n","    # SMILES strings don't need padding as PolyBERT handles that internally\n","    smiles = list(smiles)\n","\n","    # Get max length in this batch for proteins (not exceeding dataset max_length)\n","    max_protein_len = min(max(len(p) for p in proteins), max_length)\n","\n","    # Pad proteins to max length in batch\n","    padded_proteins = []\n","    protein_masks = []\n","\n","    for protein in proteins:\n","        if len(protein) > max_protein_len:\n","            padded = protein[:max_protein_len]\n","            mask = [1] * max_protein_len\n","        else:\n","            padded = protein + ' ' * (max_protein_len - len(protein))\n","            mask = [1] * len(protein) + [0] * (max_protein_len - len(protein))\n","\n","        padded_proteins.append(padded)\n","        protein_masks.append(mask)\n","\n","    return {\n","        'smiles': smiles,\n","        'proteins': padded_proteins,\n","        'protein_masks': torch.tensor(protein_masks, dtype=torch.bool)\n","    }"],"metadata":{"id":"t6vR0DNfQRUZ","executionInfo":{"status":"ok","timestamp":1739121795600,"user_tz":480,"elapsed":1,"user":{"displayName":"Venkata Srikar Kavirayuni","userId":"10910189441313353201"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["### utils"],"metadata":{"id":"Y84XLPeXQIEv"}},{"cell_type":"code","source":["# Model Components\n","class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, max_len=5000):\n","        super().__init__()\n","        position = torch.arange(max_len).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n","        pe = torch.zeros(max_len, 1, d_model)\n","        pe[:, 0, 0::2] = torch.sin(position * div_term)\n","        pe[:, 0, 1::2] = torch.cos(position * div_term)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        return x + self.pe[:x.size(0)]\n","\n","class PerceiverAttention(nn.Module):\n","    def __init__(self, dim, dim_head=64, heads=8):\n","        super().__init__()\n","        self.scale = dim_head ** -0.5\n","        self.heads = heads\n","        inner_dim = dim_head * heads\n","\n","        self.norm_media = nn.LayerNorm(dim)\n","        self.norm_latents = nn.LayerNorm(dim)\n","        self.to_q = nn.Linear(dim, inner_dim, bias=False)\n","        self.to_kv = nn.Linear(dim, inner_dim * 2, bias=False)\n","        self.to_out = nn.Linear(inner_dim, dim, bias=False)\n","\n","    def forward(self, x, latents):\n","        \"\"\"\n","        x: [batch_size, seq_len_x, dim]\n","        latents: [batch_size, seq_len_l, dim]\n","        \"\"\"\n","        batch_size = x.shape[0]\n","\n","        x = self.norm_media(x)\n","        latents = self.norm_latents(latents)\n","\n","        # Ensure latents has correct batch size\n","        if latents.size(0) != batch_size:\n","            latents = latents.expand(batch_size, -1, -1)\n","\n","        q = self.to_q(latents)\n","        q = rearrange(q, 'b n (h d) -> b h n d', h=self.heads)\n","        q = q * self.scale\n","\n","        # Ensure proper concatenation\n","        kv_input = torch.cat((x, latents), dim=1)  # concatenate along sequence dimension\n","        k, v = self.to_kv(kv_input).chunk(2, dim=-1)\n","        k = rearrange(k, 'b n (h d) -> b h n d', h=self.heads)\n","        v = rearrange(v, 'b n (h d) -> b h n d', h=self.heads)\n","\n","        sim = torch.einsum('b h i d, b h j d -> b h i j', q, k)\n","        attn = sim.softmax(dim=-1)\n","        out = torch.einsum('b h i j, b h j d -> b h i d', attn, v)\n","        out = rearrange(out, 'b h n d -> b n (h d)')\n","\n","        return self.to_out(out)\n","\n","class GatedCrossAttentionBlock(nn.Module):\n","    def __init__(self, dim, dim_head=64, heads=8, ff_mult=4):\n","        super().__init__()\n","        self.attn = PerceiverAttention(dim=dim, dim_head=dim_head, heads=heads)\n","        self.attn_gate = nn.Parameter(torch.tensor([0.]))\n","        self.ff = FeedForward(dim, mult=ff_mult)\n","        self.ff_gate = nn.Parameter(torch.tensor([0.]))\n","\n","    def forward(self, x, media):\n","        \"\"\"\n","        x: [batch_size, seq_len_x, dim]\n","        media: [batch_size, seq_len_m, dim]\n","        \"\"\"\n","        batch_size = x.shape[0]\n","        target_batch_size = media.size(0)\n","\n","        # Handle batch size mismatch\n","        if batch_size > target_batch_size:\n","            media = media.expand(batch_size, -1, -1)\n","        elif batch_size < target_batch_size:\n","            x = x.expand(target_batch_size, -1, -1)\n","\n","        gate = self.attn_gate.tanh()\n","        x = self.attn(media, x) * gate + x\n","        x = self.ff(x) * self.ff_gate.tanh() + x\n","        return x\n","\n","class PerceiverResampler(nn.Module):\n","    def __init__(self, dim, depth, dim_head=64, heads=8, num_latents=64):\n","        super().__init__()\n","        # Initialize latents without batch dimension\n","        self.latents = nn.Parameter(torch.randn(num_latents, dim))\n","        self.layers = nn.ModuleList([])\n","\n","        for _ in range(depth):\n","            self.layers.append(nn.ModuleList([\n","                PerceiverAttention(dim=dim, dim_head=dim_head, heads=heads),\n","                FeedForward(dim=dim)\n","            ]))\n","\n","    def forward(self, x):\n","        batch_size = x.shape[0]\n","        # Expand latents to batch size\n","        latents = repeat(self.latents, 'n d -> b n d', b=batch_size)\n","\n","        for attn, ff in self.layers:\n","            latents = attn(x, latents) + latents\n","            latents = ff(latents) + latents\n","\n","        return latents\n","\n","class FeedForward(nn.Module):\n","    def __init__(self, dim, mult=4):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.LayerNorm(dim),\n","            nn.Linear(dim, dim * mult, bias=False),\n","            nn.GELU(),\n","            nn.Linear(dim * mult, dim, bias=False)\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)\n","\n","# class PerceiverResampler(nn.Module):\n","#     def __init__(self, dim, depth, dim_head=64, heads=8, num_latents=64):\n","#         super().__init__()\n","#         self.latents = nn.Parameter(torch.randn(num_latents, dim))\n","#         self.layers = nn.ModuleList([])\n","\n","#         for _ in range(depth):\n","#             self.layers.append(nn.ModuleList([\n","#                 PerceiverAttention(dim=dim, dim_head=dim_head, heads=heads),\n","#                 FeedForward(dim=dim)\n","#             ]))\n","\n","#     def forward(self, x):\n","#         latents = repeat(self.latents, 'n d -> b n d', b=x.shape[0])\n","\n","#         for attn, ff in self.layers:\n","#             latents = attn(x, latents) + latents\n","#             latents = ff(latents) + latents\n","\n","#         return latents\n","\n","# class GatedCrossAttentionBlock(nn.Module):\n","#     def __init__(self, dim, dim_head=64, heads=8, ff_mult=4):\n","#         super().__init__()\n","#         self.attn = PerceiverAttention(dim=dim, dim_head=dim_head, heads=heads)\n","#         self.attn_gate = nn.Parameter(torch.tensor([0.]))\n","#         self.ff = FeedForward(dim, mult=ff_mult)\n","#         self.ff_gate = nn.Parameter(torch.tensor([0.]))\n","\n","#     def forward(self, x, media):\n","#         gate = self.attn_gate.tanh()\n","#         x = self.attn(media, x) * gate + x\n","#         x = self.ff(x) * self.ff_gate.tanh() + x\n","#         return x"],"metadata":{"id":"XEODw7FYQJEy","executionInfo":{"status":"ok","timestamp":1739121795603,"user_tz":480,"elapsed":1,"user":{"displayName":"Venkata Srikar Kavirayuni","userId":"10910189441313353201"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["### PolyBert Encoder"],"metadata":{"id":"daZm9aPyRUAM"}},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModel\n","import torch\n"],"metadata":{"id":"00Y8KtCzni07","executionInfo":{"status":"ok","timestamp":1739121795605,"user_tz":480,"elapsed":1,"user":{"displayName":"Venkata Srikar Kavirayuni","userId":"10910189441313353201"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# class PolyBERTEncoder(nn.Module):\n","#     def __init__(self, output_dim):\n","#         super().__init__()\n","#         self.polybert = AutoModel.from_pretrained('kuelumbus/polyBERT')\n","#         self.tokenizer = AutoTokenizer.from_pretrained('kuelumbus/polyBERT')\n","#         self.output_dim = output_dim\n","#         # Add a projection layer to match the required dimension\n","#         self.projection = nn.Linear(self.polybert.config.hidden_size, output_dim)\n","\n","#     def mean_pooling(self, model_output, attention_mask):\n","#         token_embeddings = model_output[0]\n","#         input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n","#         return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n","\n","#     def forward(self, smiles_strings):\n","#         # Tokenize the SMILES strings\n","#         encoded_input = self.tokenizer(smiles_strings,\n","#                                      padding=True,\n","#                                      truncation=True,\n","#                                      return_tensors='pt').to(next(self.polybert.parameters()).device)\n","\n","#         # Get PolyBERT embeddings\n","#         with torch.no_grad():\n","#             model_output = self.polybert(**encoded_input)\n","\n","#         # Debug prints\n","#         print(\"Model Output Keys:\", model_output.keys())  # Check available keys\n","#         # print(\"Last Hidden State:\", model_output.last_hidden_state)\n","#         print(\"Last Hidden State Shape:\", model_output.last_hidden_state.shape)\n","\n","#         # Pool the embeddings\n","#         pooled_output = self.mean_pooling(model_output, encoded_input['attention_mask'])\n","\n","#         # print(\"Pooled Output:\", pooled_output)\n","#         print(\"Pooled Output Shape:\", pooled_output.shape)\n","\n","#         # Project to required dimension\n","#         projected_output = self.projection(pooled_output)\n","\n","#         return projected_output"],"metadata":{"id":"rj3wpaKHRVmv","executionInfo":{"status":"ok","timestamp":1739121795608,"user_tz":480,"elapsed":3,"user":{"displayName":"Venkata Srikar Kavirayuni","userId":"10910189441313353201"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["class PolyBERTEncoder(nn.Module):\n","    def __init__(self, output_dim):\n","        super().__init__()\n","        self.polybert = AutoModel.from_pretrained('kuelumbus/polyBERT')\n","        self.tokenizer = AutoTokenizer.from_pretrained('kuelumbus/polyBERT')\n","        self.output_dim = output_dim\n","        # Project each token embedding to required dimension\n","        self.projection = nn.Linear(self.polybert.config.hidden_size, output_dim)\n","\n","    def forward(self, smiles_strings):\n","        # Tokenize the SMILES strings\n","        encoded_input = self.tokenizer(smiles_strings,\n","                                     padding=True,\n","                                     truncation=True,\n","                                     return_tensors='pt').to(next(self.polybert.parameters()).device)\n","\n","        # Get PolyBERT embeddings\n","        with torch.no_grad():\n","            model_output = self.polybert(**encoded_input)\n","\n","        # Debug prints\n","        print(\"Model Output Keys:\", model_output.keys())\n","        print(\"Last Hidden State Shape:\", model_output.last_hidden_state.shape)  # [batch_size, seq_len, hidden_size]\n","\n","        # Get sequence embeddings\n","        sequence_embeddings = model_output.last_hidden_state\n","\n","        # Project each token embedding to required dimension\n","        projected_output = self.projection(sequence_embeddings)  # [batch_size, seq_len, output_dim]\n","        print(\"Projected Output Shape:\", projected_output.shape)\n","\n","        return projected_output"],"metadata":{"id":"-2VWy9ecrDNX","executionInfo":{"status":"ok","timestamp":1739121795644,"user_tz":480,"elapsed":36,"user":{"displayName":"Venkata Srikar Kavirayuni","userId":"10910189441313353201"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["### ProtFlamingo"],"metadata":{"id":"0Pe8VJFxQSS7"}},{"cell_type":"code","execution_count":8,"metadata":{"id":"c1CcCRv-9vxW","executionInfo":{"status":"ok","timestamp":1739121795647,"user_tz":480,"elapsed":2,"user":{"displayName":"Venkata Srikar Kavirayuni","userId":"10910189441313353201"}}},"outputs":[],"source":["class ProtFlamingo(nn.Module):\n","    def __init__(self, model_path, max_len, cross_attn_every=1, dim_head=64, heads=8, perceiver_depth=2, perceiver_num_latents=64):\n","        super().__init__()\n","\n","        self.protGPT2_model = GPT2LMHeadModel.from_pretrained(model_path)\n","        self.protGPT2_tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n","        self.max_len = max_len\n","\n","        if self.protGPT2_tokenizer.pad_token is None:\n","            self.protGPT2_tokenizer.pad_token = self.protGPT2_tokenizer.eos_token\n","            self.protGPT2_model.config.pad_token_id = self.protGPT2_model.config.eos_token_id\n","\n","        self.cross_attn_every = cross_attn_every\n","\n","        # PolyBERT encoder for SMILES strings\n","        self.polybert_encoder = PolyBERTEncoder(self.protGPT2_model.config.n_embd)\n","        self.positional_encoding = PositionalEncoding(self.protGPT2_model.config.n_embd, max_len=max_len)\n","\n","        # Single perceiver resampler for SMILES embeddings\n","        self.smiles_perceiver = PerceiverResampler(\n","            dim=self.protGPT2_model.config.n_embd,\n","            depth=perceiver_depth,\n","            dim_head=dim_head,\n","            heads=heads,\n","            num_latents=perceiver_num_latents\n","        )\n","\n","        # Cross attention layers\n","        num_gpt_layers = len(self.protGPT2_model.transformer.h)\n","        self.cross_attn = nn.ModuleList([\n","            GatedCrossAttentionBlock(dim=self.protGPT2_model.config.n_embd, dim_head=dim_head, heads=heads)\n","            for _ in range(num_gpt_layers)\n","        ])\n","\n","        # Combine GPT layers with cross attention\n","        self.layers = nn.ModuleList()\n","        for i, block in enumerate(self.protGPT2_model.transformer.h):\n","            self.layers.append(block)\n","            if i % cross_attn_every == 0 and i != 0:\n","                self.layers.append(GatedCrossAttentionBlock(dim=self.protGPT2_model.config.n_embd, dim_head=dim_head, heads=heads))\n","\n","    def forward(self, smiles_strings):\n","      device = next(self.parameters()).device\n","\n","      # Get SMILES embeddings through PolyBERT\n","      print(\"Getting SMILES embeddings...\")\n","      smiles_embeddings = self.polybert_encoder(smiles_strings)  # [batch_size, seq_len, hidden_dim]\n","      processed_smiles = self.smiles_perceiver(smiles_embeddings)\n","      print(\"processed smiles thru encoder and perceiver...\")\n","\n","      # Initialize with start token\n","      print(\"gpt initialized...\")\n","      gpt_input = self.protGPT2_tokenizer.encode_plus(\n","          \"<|endoftext|>\",\n","          return_tensors=\"pt\",\n","          padding='max_length',\n","          max_length=self.max_len,\n","          truncation=True\n","      ).to(device)\n","\n","      print(\"input ids and hidden states defined (gpt + positional)...\")\n","      input_ids = gpt_input.input_ids.long()\n","      hidden_states = self.protGPT2_model.transformer.wte(input_ids)\n","      hidden_states = self.positional_encoding(hidden_states)\n","\n","      # Create proper attention mask\n","      attention_mask = gpt_input.attention_mask\n","      # Extend attention mask for batch size and heads\n","      batch_size = hidden_states.shape[0]\n","      num_heads = self.protGPT2_model.config.n_head\n","      seq_length = hidden_states.shape[1]\n","\n","      # Create 4D attention mask [batch_size, num_heads, seq_length, seq_length]\n","      attention_mask = attention_mask.view(batch_size, 1, 1, seq_length)\n","      attention_mask = attention_mask.expand(batch_size, num_heads, seq_length, seq_length)\n","      attention_mask = attention_mask.to(dtype=hidden_states.dtype)  # Convert to same dtype as hidden states\n","\n","      print(\"start to pass thru layers with cross attn\")\n","      for i, layer in enumerate(self.layers):\n","          if isinstance(layer, GatedCrossAttentionBlock):\n","              print('LAYER DEFINE _______ gated layer')\n","              hidden_states = layer(hidden_states, processed_smiles)\n","          else:\n","              print('LAYER DEFINE _______ no gated layer')\n","              hidden_states = layer(hidden_states, attention_mask=attention_mask)[0]\n","\n","      print('done... returning lm head of hidden states (Decoded)')\n","      return self.protGPT2_model.lm_head(hidden_states)\n","\n","    def custom_generate(self, smiles_string, max_length=200):\n","        device = next(self.parameters()).device\n","\n","        # Get SMILES embeddings\n","        smiles_embeddings = self.polybert_encoder(smiles_string)\n","        processed_smiles = self.smiles_perceiver(smiles_embeddings)\n","\n","        # Initialize with start token\n","        input_ids = torch.tensor([[self.protGPT2_tokenizer.bos_token_id]]).to(device)\n","\n","        # Autoregressive generation\n","        for _ in range(max_length):\n","            inputs_embeds = self.protGPT2_model.transformer.wte(input_ids)\n","            inputs_embeds = self.positional_encoding(inputs_embeds)\n","\n","            hidden_states = inputs_embeds\n","            cross_attn_idx = 0\n","\n","            for i, layer in enumerate(self.layers):\n","                if isinstance(layer, GatedCrossAttentionBlock):\n","                    hidden_states = layer(hidden_states, processed_smiles)\n","                    cross_attn_idx += 1\n","                else:\n","                    hidden_states = layer(hidden_states, attention_mask=None)[0]\n","\n","            next_token_logits = self.protGPT2_model.lm_head(hidden_states[:, -1, :])\n","            next_token = torch.argmax(next_token_logits, dim=-1).unsqueeze(0)\n","\n","            input_ids = torch.cat([input_ids, next_token], dim=-1)\n","\n","            if next_token.item() == self.protGPT2_tokenizer.eos_token_id:\n","                break\n","\n","        return self.protGPT2_tokenizer.decode(input_ids[0], skip_special_tokens=True)\n","\n","    def generate(self, smiles_string, max_length=50):\n","        return self.custom_generate(smiles_string, max_length)\n","\n","    def state_dict(self):\n","        state_dict = super().state_dict()\n","        state_dict['smiles_perceiver'] = self.smiles_perceiver.state_dict()\n","        state_dict['cross_attn'] = self.cross_attn.state_dict()\n","        state_dict['polybert_encoder'] = self.polybert_encoder.state_dict()\n","        return state_dict\n","\n","    def load_state_dict(self, state_dict):\n","        smiles_perceiver_state = state_dict.pop('smiles_perceiver')\n","        cross_attn_state = state_dict.pop('cross_attn')\n","        polybert_encoder_state = state_dict.pop('polybert_encoder')\n","\n","        super().load_state_dict(state_dict)\n","\n","        self.smiles_perceiver.load_state_dict(smiles_perceiver_state)\n","        self.cross_attn.load_state_dict(cross_attn_state)\n","        self.polybert_encoder.load_state_dict(polybert_encoder_state)"]},{"cell_type":"markdown","source":["### training"],"metadata":{"id":"6o91I0EXQaF4"}},{"cell_type":"code","source":["def train(model, train_loader, val_loader, num_epochs, device, l2_reg=1e-5):\n","    optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=l2_reg)\n","    criterion = nn.CrossEntropyLoss(ignore_index=model.protGPT2_tokenizer.pad_token_id)\n","    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        total_loss = 0\n","        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n","            smiles_strings = batch['smiles']\n","            proteins = batch['proteins']\n","            protein_masks = batch['protein_masks'].to(device)\n","\n","            optimizer.zero_grad()\n","\n","            outputs = model(smiles_strings)\n","\n","            target_encoding = model.protGPT2_tokenizer(\n","                proteins,\n","                return_tensors=\"pt\",\n","                padding='max_length',\n","                max_length=model.max_len,\n","                truncation=True\n","            ).to(device)\n","\n","            # Use masked loss\n","            loss = criterion(\n","                outputs.view(-1, outputs.size(-1)),\n","                target_encoding.input_ids.view(-1)\n","            )\n","\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","            optimizer.step()\n","\n","            total_loss += loss.item()\n","\n","        avg_loss = total_loss / len(train_loader)\n","        print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}\")\n","\n","        val_loss = validate(model, val_loader, criterion, device)\n","        print(f\"Validation Loss: {val_loss:.4f}\")\n","\n","        scheduler.step()\n","        torch.save(model.state_dict(), f'model_checkpoint_epoch_{epoch+1}.pth')\n","\n","def validate(model, val_loader, criterion, device):\n","    model.eval()\n","    total_loss = 0\n","    with torch.no_grad():\n","        for batch in val_loader:\n","            smiles_strings = batch['smiles']\n","            proteins = batch['proteins']\n","            protein_masks = batch['protein_masks'].to(device)\n","\n","            outputs = model(smiles_strings)\n","            target_encoding = model.protGPT2_tokenizer(\n","                proteins,\n","                return_tensors=\"pt\",\n","                padding='max_length',\n","                max_length=model.max_len,\n","                truncation=True\n","            ).to(device)\n","\n","            loss = criterion(\n","                outputs.view(-1, outputs.size(-1)),\n","                target_encoding.input_ids.view(-1)\n","            )\n","            total_loss += loss.item()\n","\n","    return total_loss / len(val_loader)\n","\n","def generate_and_evaluate(model, test_loader, device):\n","    model.eval()\n","    results = []\n","\n","    with torch.no_grad():\n","        for batch in tqdm(test_loader, desc=\"Generating proteins\"):\n","            smiles_strings = batch['smiles']\n","            target_proteins = batch['proteins']\n","\n","            generated_proteins = []\n","            for smiles in smiles_strings:\n","                generated_protein = model.generate(smiles)\n","                generated_proteins.append(generated_protein)\n","\n","            for smiles, gen_protein, target_protein in zip(smiles_strings, generated_proteins, target_proteins):\n","                results.append({\n","                    'SMILES': smiles,\n","                    'Generated Protein': gen_protein,\n","                    'Target Protein': target_protein.strip()  # Remove padding\n","                })\n","\n","    return results"],"metadata":{"id":"wWmS0warQa-n","executionInfo":{"status":"ok","timestamp":1739121795668,"user_tz":480,"elapsed":21,"user":{"displayName":"Venkata Srikar Kavirayuni","userId":"10910189441313353201"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["### inference + training"],"metadata":{"id":"CfYBZUMhfOTB"}},{"cell_type":"code","source":["# Set device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Using device: {device}\")\n","\n","# Load and preprocess data\n","train_data = preprocess_snp_data('/content/training.csv')\n","val_data = preprocess_snp_data('/content/validation.csv')\n","test_data = preprocess_snp_data('/content/testing.csv')\n","\n","train_data = filter_datasets(train_data)\n","val_data = filter_datasets(val_data)\n","test_data = filter_datasets(test_data)\n","\n","# Calculate max sequence length\n","max_length = max(\n","    train_data['protein_length'].max(),\n","    val_data['protein_length'].max(),\n","    test_data['protein_length'].max()\n",")\n","max_length = min(max_length, 1024)  # Cap at 1024 or your desired maximum\n","print(f\"Max sequence length: {max_length}\")\n","\n","# Create datasets\n","train_dataset = ProteinGenerationDataset(train_data, max_length)\n","val_dataset = ProteinGenerationDataset(val_data, max_length)\n","test_dataset = ProteinGenerationDataset(test_data, max_length)\n","\n","# Create dataloaders with custom collate function\n","train_loader = DataLoader(\n","    train_dataset,\n","    batch_size=2,  # Adjust based on your GPU memory\n","    shuffle=True,\n","    num_workers=4,\n","    collate_fn=collate_fn\n",")\n","\n","val_loader = DataLoader(\n","    val_dataset,\n","    batch_size=8,\n","    shuffle=False,\n","    num_workers=4,\n","    collate_fn=collate_fn\n",")\n","\n","test_loader = DataLoader(\n","    test_dataset,\n","    batch_size=8,\n","    shuffle=False,\n","    num_workers=4,\n","    collate_fn=collate_fn\n",")\n","\n","# Initialize model\n","model = ProtFlamingo(\n","    model_path='nferruz/ProtGPT2',\n","    max_len=max_length,\n","    cross_attn_every=1,\n","    dim_head=64,\n","    heads=8,\n","    perceiver_depth=2,\n","    perceiver_num_latents=64\n",").to(device)\n","\n","# Training loop\n","print(\"Starting training...\")\n","num_epochs = 10\n","train(model, train_loader, val_loader, num_epochs, device)\n","\n","# Generate and evaluate\n","print(\"Generating proteins for test set...\")\n","test_results = generate_and_evaluate(model, test_loader, device)\n","\n","# Save results\n","print(\"Saving results...\")\n","results_path = 'test_results.json'\n","with open(results_path, 'w') as f:\n","    json.dump(test_results, f, indent=2)\n","\n","print(f\"Results saved to {results_path}\")\n","\n","# Optional: Print some example results\n","print(\"\\nExample generations:\")\n","for i, result in enumerate(test_results[:3]):  # Show first 3 examples\n","    print(f\"\\nExample {i+1}:\")\n","    print(f\"SMILES: {result['SMILES']}\")\n","    print(f\"Generated Protein: {result['Generated Protein'][:50]}...\")  # Show first 50 chars\n","    print(f\"Target Protein: {result['Target Protein'][:50]}...\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"e-67RvdafPdi","executionInfo":{"status":"error","timestamp":1739121812728,"user_tz":480,"elapsed":17059,"user":{"displayName":"Venkata Srikar Kavirayuni","userId":"10910189441313353201"}},"outputId":"669f80a0-0d2e-42e7-a70d-de771ad1becf"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","Max sequence length: 914\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Starting training...\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch 1/10:   0%|          | 0/70 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"]},{"output_type":"stream","name":"stdout","text":["Getting SMILES embeddings...\n","Model Output Keys: odict_keys(['last_hidden_state'])\n","Last Hidden State Shape: torch.Size([2, 61, 600])\n","Projected Output Shape: torch.Size([2, 61, 1280])\n","processed smiles thru encoder and perceiver...\n","gpt initialized...\n","input ids and hidden states defined (gpt + positional)...\n","start to pass thru layers with cross attn\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","done... returning lm head of hidden states (Decoded)\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch 1/10:   1%|▏         | 1/70 [00:02<02:51,  2.48s/it]"]},{"output_type":"stream","name":"stdout","text":["Getting SMILES embeddings...\n","Model Output Keys: odict_keys(['last_hidden_state'])\n","Last Hidden State Shape: torch.Size([2, 30, 600])\n","Projected Output Shape: torch.Size([2, 30, 1280])\n","processed smiles thru encoder and perceiver...\n","gpt initialized...\n","input ids and hidden states defined (gpt + positional)...\n","start to pass thru layers with cross attn\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","LAYER DEFINE _______ no gated layer\n","LAYER DEFINE _______ gated layer\n","done... returning lm head of hidden states (Decoded)\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch 1/10:   1%|▏         | 1/70 [00:03<03:28,  3.02s/it]\n"]},{"output_type":"error","ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 352.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 260.88 MiB is free. Process 141585 has 39.29 GiB memory in use. Of the allocated memory 36.14 GiB is allocated by PyTorch, and 2.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-5e20f35ba5bd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;31m# Generate and evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-776914937335>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, num_epochs, device, l2_reg)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmiles_strings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             target_encoding = model.protGPT2_tokenizer(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-0eb2154fca75>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, smiles_strings)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'done... returning lm head of hidden states (Decoded)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotGPT2_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcustom_generate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmiles_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 352.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 260.88 MiB is free. Process 141585 has 39.29 GiB memory in use. Of the allocated memory 36.14 GiB is allocated by PyTorch, and 2.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"]}]}]}