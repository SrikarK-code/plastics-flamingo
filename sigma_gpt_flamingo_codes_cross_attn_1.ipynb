{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### setup"
      ],
      "metadata": {
        "id": "CsZYuP9onEl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Levenshtein\n",
        "!pip install einops\n",
        "!pip install einops_exts\n",
        "!pip install torch\n",
        "!pip install transformers\n",
        "!pip install tqdm\n",
        "!pip install sentencepiece\n",
        "# !pip install fair-esm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CpeO8QHj-_z5",
        "outputId": "be4cd1e2-f27d-4d52-d811-c96db1f41fcd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Levenshtein in /usr/local/lib/python3.11/dist-packages (0.27.1)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in /usr/local/lib/python3.11/dist-packages (from Levenshtein) (3.12.2)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n",
            "Requirement already satisfied: einops_exts in /usr/local/lib/python3.11/dist-packages (0.0.4)\n",
            "Requirement already satisfied: einops>=0.4 in /usr/local/lib/python3.11/dist-packages (from einops_exts) (0.8.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import pandas as pd\n",
        "import re\n",
        "import math\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from einops import rearrange, repeat\n",
        "# import esm\n",
        "\n",
        "# Set up GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# # Load ESM-2 model\n",
        "# esm_model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
        "# batch_converter = alphabet.get_batch_converter()\n",
        "# esm_model = esm_model.to(device)  # Move to GPU if available\n",
        "# esm_model.eval()  # Set to evaluation mode\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CYInyPD_--Vo",
        "outputId": "ff5bc0f5-3cf3-42a2-f583-0dcdc985c180"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### data"
      ],
      "metadata": {
        "id": "B--CLs46QMLR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DyL8K36gQgPj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "0UGP9rWlQgn_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75ae6af8-b6d6-4e05-832b-6917d3dc95ff"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aN6Of5EMJ2Ju"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_snp_data(file_path):\n",
        "    snp_df = pd.read_csv(file_path)\n",
        "\n",
        "    # Basic preprocessing and length calculations\n",
        "    snp_df['smiles_length'] = snp_df['smiles'].apply(len)\n",
        "    snp_df['protein_length'] = snp_df['protein_sequence'].apply(len)\n",
        "\n",
        "    return snp_df\n",
        "\n",
        "def filter_datasets(dataset):\n",
        "    return dataset[\n",
        "        (dataset['smiles'].notna()) &\n",
        "        (dataset['protein_sequence'].notna()) &\n",
        "        (dataset['smiles_length'] > 0) &\n",
        "        (dataset['protein_length'] > 0)\n",
        "    ]\n",
        "\n",
        "class ProteinGenerationDataset(Dataset):\n",
        "    def __init__(self, dataframe, max_length):\n",
        "        self.dataframe = dataframe\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.dataframe.iloc[idx]\n",
        "        return row['smiles'], row['protein_sequence']\n",
        "\n",
        "def collate_fn(batch):\n",
        "    \"\"\"\n",
        "    Custom collate function to handle padding within batches.\n",
        "    Args:\n",
        "        batch: List of tuples (smiles, protein)\n",
        "    Returns:\n",
        "        Padded and batched tensors\n",
        "    \"\"\"\n",
        "    smiles, proteins = zip(*batch)\n",
        "\n",
        "    # SMILES strings don't need padding as PolyBERT handles that internally\n",
        "    smiles = list(smiles)\n",
        "\n",
        "    # Get max length in this batch for proteins (not exceeding dataset max_length)\n",
        "    max_protein_len = min(max(len(p) for p in proteins), max_length)\n",
        "\n",
        "    # Pad proteins to max length in batch\n",
        "    padded_proteins = []\n",
        "    protein_masks = []\n",
        "\n",
        "    for protein in proteins:\n",
        "        if len(protein) > max_protein_len:\n",
        "            padded = protein[:max_protein_len]\n",
        "            mask = [1] * max_protein_len\n",
        "        else:\n",
        "            padded = protein + ' ' * (max_protein_len - len(protein))\n",
        "            mask = [1] * len(protein) + [0] * (max_protein_len - len(protein))\n",
        "\n",
        "        padded_proteins.append(padded)\n",
        "        protein_masks.append(mask)\n",
        "\n",
        "    return {\n",
        "        'smiles': smiles,\n",
        "        'proteins': padded_proteins,\n",
        "        'protein_masks': torch.tensor(protein_masks, dtype=torch.bool)\n",
        "    }"
      ],
      "metadata": {
        "id": "t6vR0DNfQRUZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### utils"
      ],
      "metadata": {
        "id": "Y84XLPeXQIEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Components\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super().__init__()\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, 1, d_model)\n",
        "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:x.size(0)]\n",
        "\n",
        "class DoublePositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super().__init__()\n",
        "        # Use the full embedding dimension divided into two halves\n",
        "        self.d_model = d_model\n",
        "        half_dim = d_model // 2\n",
        "\n",
        "        # Create position encodings for both input and output positions\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, half_dim, 2) * (-math.log(10000.0) / half_dim))\n",
        "\n",
        "        # Input position encodings\n",
        "        pe_input = torch.zeros(max_len, half_dim)\n",
        "        pe_input[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe_input[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        # Output position encodings\n",
        "        pe_output = torch.zeros(max_len, half_dim)\n",
        "        pe_output[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe_output[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        self.register_buffer('pe_input', pe_input)\n",
        "        self.register_buffer('pe_output', pe_output)\n",
        "\n",
        "    def forward(self, x, input_positions, output_positions):\n",
        "        batch_size, seq_length, _ = x.shape\n",
        "\n",
        "        # Create a tensor of zeros with the same shape as the input\n",
        "        pos_encoding = torch.zeros_like(x)\n",
        "\n",
        "        # For each item in the batch\n",
        "        for b in range(batch_size):\n",
        "            for t in range(seq_length):\n",
        "                # Get the input and output positions for this token\n",
        "                input_pos = input_positions[b, t] if input_positions is not None else t\n",
        "                output_pos = output_positions[b, t] if output_positions is not None else t\n",
        "\n",
        "                if input_pos < self.pe_input.size(0) and output_pos < self.pe_output.size(0):\n",
        "                    # Fill the first half with input position encoding\n",
        "                    pos_encoding[b, t, :self.d_model//2] = self.pe_input[input_pos]\n",
        "                    # Fill the second half with output position encoding\n",
        "                    pos_encoding[b, t, self.d_model//2:] = self.pe_output[output_pos]\n",
        "\n",
        "        return x + pos_encoding\n",
        "\n",
        "class PerceiverAttention(nn.Module):\n",
        "    def __init__(self, dim, dim_head=64, heads=8):\n",
        "        super().__init__()\n",
        "        self.scale = dim_head ** -0.5\n",
        "        self.heads = heads\n",
        "        inner_dim = dim_head * heads\n",
        "\n",
        "        self.norm_media = nn.LayerNorm(dim)\n",
        "        self.norm_latents = nn.LayerNorm(dim)\n",
        "        self.to_q = nn.Linear(dim, inner_dim, bias=False)\n",
        "        self.to_kv = nn.Linear(dim, inner_dim * 2, bias=False)\n",
        "        self.to_out = nn.Linear(inner_dim, dim, bias=False)\n",
        "\n",
        "    def forward(self, x, latents):\n",
        "        \"\"\"\n",
        "        x: [batch_size, seq_len_x, dim]\n",
        "        latents: [batch_size, seq_len_l, dim]\n",
        "        \"\"\"\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        x = self.norm_media(x)\n",
        "        latents = self.norm_latents(latents)\n",
        "\n",
        "        # Ensure latents has correct batch size\n",
        "        if latents.size(0) != batch_size:\n",
        "            latents = latents.expand(batch_size, -1, -1)\n",
        "\n",
        "        q = self.to_q(latents)\n",
        "        q = rearrange(q, 'b n (h d) -> b h n d', h=self.heads)\n",
        "        q = q * self.scale\n",
        "\n",
        "        # Ensure proper concatenation\n",
        "        kv_input = torch.cat((x, latents), dim=1)  # concatenate along sequence dimension\n",
        "        k, v = self.to_kv(kv_input).chunk(2, dim=-1)\n",
        "        k = rearrange(k, 'b n (h d) -> b h n d', h=self.heads)\n",
        "        v = rearrange(v, 'b n (h d) -> b h n d', h=self.heads)\n",
        "\n",
        "        sim = torch.einsum('b h i d, b h j d -> b h i j', q, k)\n",
        "        attn = sim.softmax(dim=-1)\n",
        "        out = torch.einsum('b h i j, b h j d -> b h i d', attn, v)\n",
        "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
        "\n",
        "        return self.to_out(out)\n",
        "\n",
        "class GatedCrossAttentionBlock(nn.Module):\n",
        "    def __init__(self, dim, dim_head=64, heads=8, ff_mult=4):\n",
        "        super().__init__()\n",
        "        self.attn = PerceiverAttention(dim=dim, dim_head=dim_head, heads=heads)\n",
        "        self.attn_gate = nn.Parameter(torch.tensor([0.]))\n",
        "        self.ff = FeedForward(dim, mult=ff_mult)\n",
        "        self.ff_gate = nn.Parameter(torch.tensor([0.]))\n",
        "\n",
        "    def forward(self, x, media):\n",
        "        \"\"\"\n",
        "        x: [batch_size, seq_len_x, dim]\n",
        "        media: [batch_size, seq_len_m, dim]\n",
        "        \"\"\"\n",
        "        batch_size = x.shape[0]\n",
        "        target_batch_size = media.size(0)\n",
        "\n",
        "        # Handle batch size mismatch\n",
        "        if batch_size > target_batch_size:\n",
        "            media = media.expand(batch_size, -1, -1)\n",
        "        elif batch_size < target_batch_size:\n",
        "            x = x.expand(target_batch_size, -1, -1)\n",
        "\n",
        "        gate = self.attn_gate.tanh()\n",
        "        x = self.attn(media, x) * gate + x\n",
        "        x = self.ff(x) * self.ff_gate.tanh() + x\n",
        "        return x\n",
        "\n",
        "class PerceiverResampler(nn.Module):\n",
        "    def __init__(self, dim, depth, dim_head=64, heads=8, num_latents=64):\n",
        "        super().__init__()\n",
        "        # Initialize latents without batch dimension\n",
        "        self.latents = nn.Parameter(torch.randn(num_latents, dim))\n",
        "        self.layers = nn.ModuleList([])\n",
        "\n",
        "        for _ in range(depth):\n",
        "            self.layers.append(nn.ModuleList([\n",
        "                PerceiverAttention(dim=dim, dim_head=dim_head, heads=heads),\n",
        "                FeedForward(dim=dim)\n",
        "            ]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        # Expand latents to batch size\n",
        "        latents = repeat(self.latents, 'n d -> b n d', b=batch_size)\n",
        "\n",
        "        for attn, ff in self.layers:\n",
        "            latents = attn(x, latents) + latents\n",
        "            latents = ff(latents) + latents\n",
        "\n",
        "        return latents\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim, mult=4):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.Linear(dim, dim * mult, bias=False),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(dim * mult, dim, bias=False)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# class PerceiverResampler(nn.Module):\n",
        "#     def __init__(self, dim, depth, dim_head=64, heads=8, num_latents=64):\n",
        "#         super().__init__()\n",
        "#         self.latents = nn.Parameter(torch.randn(num_latents, dim))\n",
        "#         self.layers = nn.ModuleList([])\n",
        "\n",
        "#         for _ in range(depth):\n",
        "#             self.layers.append(nn.ModuleList([\n",
        "#                 PerceiverAttention(dim=dim, dim_head=dim_head, heads=heads),\n",
        "#                 FeedForward(dim=dim)\n",
        "#             ]))\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         latents = repeat(self.latents, 'n d -> b n d', b=x.shape[0])\n",
        "\n",
        "#         for attn, ff in self.layers:\n",
        "#             latents = attn(x, latents) + latents\n",
        "#             latents = ff(latents) + latents\n",
        "\n",
        "#         return latents\n",
        "\n",
        "# class GatedCrossAttentionBlock(nn.Module):\n",
        "#     def __init__(self, dim, dim_head=64, heads=8, ff_mult=4):\n",
        "#         super().__init__()\n",
        "#         self.attn = PerceiverAttention(dim=dim, dim_head=dim_head, heads=heads)\n",
        "#         self.attn_gate = nn.Parameter(torch.tensor([0.]))\n",
        "#         self.ff = FeedForward(dim, mult=ff_mult)\n",
        "#         self.ff_gate = nn.Parameter(torch.tensor([0.]))\n",
        "\n",
        "#     def forward(self, x, media):\n",
        "#         gate = self.attn_gate.tanh()\n",
        "#         x = self.attn(media, x) * gate + x\n",
        "#         x = self.ff(x) * self.ff_gate.tanh() + x\n",
        "#         return x"
      ],
      "metadata": {
        "id": "XEODw7FYQJEy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PolyBert Encoder"
      ],
      "metadata": {
        "id": "daZm9aPyRUAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "00Y8KtCzni07"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class PolyBERTEncoder(nn.Module):\n",
        "#     def __init__(self, output_dim):\n",
        "#         super().__init__()\n",
        "#         self.polybert = AutoModel.from_pretrained('kuelumbus/polyBERT')\n",
        "#         self.tokenizer = AutoTokenizer.from_pretrained('kuelumbus/polyBERT')\n",
        "#         self.output_dim = output_dim\n",
        "#         # Add a projection layer to match the required dimension\n",
        "#         self.projection = nn.Linear(self.polybert.config.hidden_size, output_dim)\n",
        "\n",
        "#     def mean_pooling(self, model_output, attention_mask):\n",
        "#         token_embeddings = model_output[0]\n",
        "#         input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "#         return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "\n",
        "#     def forward(self, smiles_strings):\n",
        "#         # Tokenize the SMILES strings\n",
        "#         encoded_input = self.tokenizer(smiles_strings,\n",
        "#                                      padding=True,\n",
        "#                                      truncation=True,\n",
        "#                                      return_tensors='pt').to(next(self.polybert.parameters()).device)\n",
        "\n",
        "#         # Get PolyBERT embeddings\n",
        "#         with torch.no_grad():\n",
        "#             model_output = self.polybert(**encoded_input)\n",
        "\n",
        "#         # Debug prints\n",
        "#         print(\"Model Output Keys:\", model_output.keys())  # Check available keys\n",
        "#         # print(\"Last Hidden State:\", model_output.last_hidden_state)\n",
        "#         print(\"Last Hidden State Shape:\", model_output.last_hidden_state.shape)\n",
        "\n",
        "#         # Pool the embeddings\n",
        "#         pooled_output = self.mean_pooling(model_output, encoded_input['attention_mask'])\n",
        "\n",
        "#         # print(\"Pooled Output:\", pooled_output)\n",
        "#         print(\"Pooled Output Shape:\", pooled_output.shape)\n",
        "\n",
        "#         # Project to required dimension\n",
        "#         projected_output = self.projection(pooled_output)\n",
        "\n",
        "#         return projected_output"
      ],
      "metadata": {
        "id": "rj3wpaKHRVmv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PolyBERTEncoder(nn.Module):\n",
        "    def __init__(self, output_dim):\n",
        "        super().__init__()\n",
        "        self.polybert = AutoModel.from_pretrained('kuelumbus/polyBERT')\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained('kuelumbus/polyBERT')\n",
        "        self.output_dim = output_dim\n",
        "        # Project each token embedding to required dimension\n",
        "        self.projection = nn.Linear(self.polybert.config.hidden_size, output_dim)\n",
        "\n",
        "    def forward(self, smiles_strings):\n",
        "        # Tokenize the SMILES strings\n",
        "        encoded_input = self.tokenizer(smiles_strings,\n",
        "                                     padding=True,\n",
        "                                     truncation=True,\n",
        "                                     return_tensors='pt').to(next(self.polybert.parameters()).device)\n",
        "\n",
        "        # Get PolyBERT embeddings\n",
        "        with torch.no_grad():\n",
        "            model_output = self.polybert(**encoded_input)\n",
        "\n",
        "        # Debug prints\n",
        "        # print(\"Model Output Keys:\", model_output.keys())\n",
        "        # print(\"Last Hidden State Shape:\", model_output.last_hidden_state.shape)  # [batch_size, seq_len, hidden_size]\n",
        "\n",
        "        # Get sequence embeddings\n",
        "        sequence_embeddings = model_output.last_hidden_state\n",
        "\n",
        "        # Project each token embedding to required dimension\n",
        "        projected_output = self.projection(sequence_embeddings)  # [batch_size, seq_len, output_dim]\n",
        "        # print(\"Projected Output Shape:\", projected_output.shape)\n",
        "\n",
        "        return projected_output"
      ],
      "metadata": {
        "id": "-2VWy9ecrDNX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ProtFlamingo"
      ],
      "metadata": {
        "id": "0Pe8VJFxQSS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n"
      ],
      "metadata": {
        "id": "d3FCpZZidXy3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "c1CcCRv-9vxW"
      },
      "outputs": [],
      "source": [
        "class SigmaProtFlamingo(nn.Module):\n",
        "    def __init__(self, model_path, max_len, cross_attn_every=3, dim_head=64, heads=8, perceiver_depth=2, perceiver_num_latents=64):\n",
        "        super().__init__()\n",
        "\n",
        "        self.protGPT2_model = GPT2LMHeadModel.from_pretrained(model_path)\n",
        "        self.protGPT2_tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
        "        self.max_len = max_len\n",
        "\n",
        "        if self.protGPT2_tokenizer.pad_token is None:\n",
        "            self.protGPT2_tokenizer.pad_token = self.protGPT2_tokenizer.eos_token\n",
        "            self.protGPT2_model.config.pad_token_id = self.protGPT2_model.config.eos_token_id\n",
        "\n",
        "        self.cross_attn_every = cross_attn_every\n",
        "\n",
        "        # PolyBERT encoder for SMILES strings\n",
        "        self.polybert_encoder = PolyBERTEncoder(self.protGPT2_model.config.n_embd)\n",
        "\n",
        "        # Replace single positional encoding with double positional encoding\n",
        "        self.positional_encoding = DoublePositionalEncoding(self.protGPT2_model.config.n_embd, max_len=max_len)\n",
        "\n",
        "        # Single perceiver resampler for SMILES embeddings\n",
        "        self.smiles_perceiver = PerceiverResampler(\n",
        "            dim=self.protGPT2_model.config.n_embd,\n",
        "            depth=perceiver_depth,\n",
        "            dim_head=dim_head,\n",
        "            heads=heads,\n",
        "            num_latents=perceiver_num_latents\n",
        "        )\n",
        "\n",
        "        # Cross attention layers\n",
        "        num_gpt_layers = len(self.protGPT2_model.transformer.h)\n",
        "        self.cross_attn = nn.ModuleList([\n",
        "            GatedCrossAttentionBlock(dim=self.protGPT2_model.config.n_embd, dim_head=dim_head, heads=heads)\n",
        "            for _ in range(num_gpt_layers)\n",
        "        ])\n",
        "\n",
        "        # Combine GPT layers with cross attention\n",
        "        self.layers = nn.ModuleList()\n",
        "        for i, block in enumerate(self.protGPT2_model.transformer.h):\n",
        "            self.layers.append(block)\n",
        "            if i % cross_attn_every == 0 and i != 0:\n",
        "                self.layers.append(GatedCrossAttentionBlock(dim=self.protGPT2_model.config.n_embd, dim_head=dim_head, heads=heads))\n",
        "\n",
        "    def forward(self, smiles_strings, order=None, targets=None, optimize=False, kv_cache=None, burst=False):\n",
        "        device = next(self.parameters()).device\n",
        "\n",
        "        # Get SMILES embeddings through PolyBERT\n",
        "        smiles_embeddings = self.polybert_encoder(smiles_strings)\n",
        "        processed_smiles = self.smiles_perceiver(smiles_embeddings)\n",
        "\n",
        "        # Initialize with start token\n",
        "        gpt_input = self.protGPT2_tokenizer.encode_plus(\n",
        "            \"<|endoftext|>\",\n",
        "            return_tensors=\"pt\",\n",
        "            padding='max_length',\n",
        "            max_length=self.max_len,\n",
        "            truncation=True\n",
        "        ).to(device)\n",
        "\n",
        "        input_ids = gpt_input.input_ids.long()\n",
        "        seq_length = input_ids.size(1)\n",
        "        batch_size = 1 if isinstance(smiles_strings, str) else len(smiles_strings)\n",
        "\n",
        "        hidden_states = self.protGPT2_model.transformer.wte(input_ids)\n",
        "\n",
        "        # If no order is provided, use left-to-right\n",
        "        if order is None:\n",
        "            order = torch.arange(seq_length, device=device).unsqueeze(0).repeat(batch_size, 1)\n",
        "\n",
        "        # Make sure order is the right length\n",
        "        if order.size(1) > seq_length:\n",
        "            order = order[:, :seq_length]\n",
        "        elif order.size(1) < seq_length:\n",
        "            # Pad order if needed\n",
        "            padding = torch.arange(order.size(1), seq_length, device=device).unsqueeze(0).repeat(batch_size, 1)\n",
        "            order = torch.cat([order, padding], dim=1)\n",
        "\n",
        "        # Map the input tokens according to the order\n",
        "        # When using random order, we need to reshuffle the input tokens\n",
        "        if not optimize and not burst:  # Only shuffle during training\n",
        "            reordered_input_ids = torch.zeros_like(input_ids)\n",
        "            for b in range(batch_size):\n",
        "                # Reorder the input tokens according to the order\n",
        "                reordered_input_ids[b] = input_ids[b, order[b]]\n",
        "\n",
        "            # Re-embed with reordered tokens\n",
        "            hidden_states = self.protGPT2_model.transformer.wte(reordered_input_ids)\n",
        "\n",
        "        # Get input and output positions from the order\n",
        "        # Input positions: the current position in the order\n",
        "        # Output positions: the next position in the order\n",
        "        input_positions = order\n",
        "        # Shift the order by 1 to get output positions (target positions)\n",
        "        output_positions = torch.roll(order, -1, dims=1)\n",
        "        # The last position wraps to the first position\n",
        "        output_positions[:, -1] = order[:, 0]\n",
        "\n",
        "        # Apply double positional encoding\n",
        "        hidden_states = self.positional_encoding(hidden_states, input_positions, output_positions)\n",
        "\n",
        "        # Create attention mask based on the order\n",
        "        attention_mask = gpt_input.attention_mask\n",
        "        num_heads = self.protGPT2_model.config.n_head\n",
        "\n",
        "        # Create 4D attention mask [batch_size, num_heads, seq_length, seq_length]\n",
        "        attention_mask = attention_mask.view(batch_size, 1, 1, seq_length)\n",
        "        attention_mask = attention_mask.expand(batch_size, num_heads, seq_length, seq_length)\n",
        "        attention_mask = attention_mask.to(dtype=hidden_states.dtype)\n",
        "\n",
        "        # Create causal mask based on the order\n",
        "        # A token at position i can attend to tokens at positions j where order[j] <= order[i]\n",
        "        # Vectorized causal mask creation\n",
        "        seq_indices = torch.arange(seq_length, device=device)\n",
        "        expanded_seq_indices_i = seq_indices.unsqueeze(1).expand(seq_length, seq_length)\n",
        "        expanded_seq_indices_j = seq_indices.unsqueeze(0).expand(seq_length, seq_length)\n",
        "\n",
        "        causal_mask = torch.zeros((batch_size, seq_length, seq_length), device=device)\n",
        "        for b in range(batch_size):\n",
        "            # Get order for this batch\n",
        "            order_b = order[b]\n",
        "            # Get order values at positions i and j\n",
        "            order_i = order_b[expanded_seq_indices_i]\n",
        "            order_j = order_b[expanded_seq_indices_j]\n",
        "            # Create mask where order_j <= order_i\n",
        "            causal_mask[b] = (order_j <= order_i).float()\n",
        "\n",
        "        # Reshape causal_mask to match attention_mask and combine them\n",
        "        causal_mask = causal_mask.unsqueeze(1)  # [batch_size, 1, seq_length, seq_length]\n",
        "        combined_mask = attention_mask * causal_mask\n",
        "\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            if isinstance(layer, GatedCrossAttentionBlock):\n",
        "                hidden_states = layer(hidden_states, processed_smiles)\n",
        "            else:\n",
        "                hidden_states = layer(hidden_states, attention_mask=combined_mask)[0]\n",
        "\n",
        "        # Get logits\n",
        "        logits = self.protGPT2_model.lm_head(hidden_states)\n",
        "\n",
        "        if targets is None:\n",
        "            if optimize:\n",
        "                # inference-time mini-optimization: only forward the lm_head on the very last position\n",
        "                return logits[:, [-1], :], None\n",
        "            return logits, None\n",
        "\n",
        "        # Compute loss against the targets\n",
        "        # If targets are provided in original order, we need to shuffle them to match our order\n",
        "        if targets is not None:\n",
        "            shuffled_targets = torch.zeros_like(targets)\n",
        "            for b in range(batch_size):\n",
        "                # Reorder the targets according to the order\n",
        "                shuffled_targets[b] = targets[b, order[b]]\n",
        "\n",
        "            loss = F.cross_entropy(\n",
        "                logits.view(-1, logits.size(-1)),\n",
        "                shuffled_targets.view(-1),\n",
        "                ignore_index=-1\n",
        "            )\n",
        "        else:\n",
        "            loss = None\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def custom_generate(self, smiles_string, max_length=200):\n",
        "        device = next(self.parameters()).device\n",
        "\n",
        "        # Get SMILES embeddings\n",
        "        smiles_embeddings = self.polybert_encoder(smiles_string)\n",
        "        processed_smiles = self.smiles_perceiver(smiles_embeddings)\n",
        "\n",
        "        # Initialize with start token\n",
        "        input_ids = torch.tensor([[self.protGPT2_tokenizer.bos_token_id]]).to(device)\n",
        "\n",
        "        # Autoregressive generation\n",
        "        for _ in range(max_length):\n",
        "            inputs_embeds = self.protGPT2_model.transformer.wte(input_ids)\n",
        "            inputs_embeds = self.positional_encoding(inputs_embeds)\n",
        "\n",
        "            hidden_states = inputs_embeds\n",
        "            cross_attn_idx = 0\n",
        "\n",
        "            for i, layer in enumerate(self.layers):\n",
        "                if isinstance(layer, GatedCrossAttentionBlock):\n",
        "                    hidden_states = layer(hidden_states, processed_smiles)\n",
        "                    cross_attn_idx += 1\n",
        "                else:\n",
        "                    hidden_states = layer(hidden_states, attention_mask=None)[0]\n",
        "\n",
        "            next_token_logits = self.protGPT2_model.lm_head(hidden_states[:, -1, :])\n",
        "            next_token = torch.argmax(next_token_logits, dim=-1).unsqueeze(0)\n",
        "\n",
        "            input_ids = torch.cat([input_ids, next_token], dim=-1)\n",
        "\n",
        "            if next_token.item() == self.protGPT2_tokenizer.eos_token_id:\n",
        "                break\n",
        "\n",
        "        return self.protGPT2_tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    def generate(self, smiles_string, max_length=50):\n",
        "        return self.custom_generate(smiles_string, max_length)\n",
        "\n",
        "    def state_dict(self):\n",
        "        state_dict = super().state_dict()\n",
        "        state_dict['smiles_perceiver'] = self.smiles_perceiver.state_dict()\n",
        "        state_dict['cross_attn'] = self.cross_attn.state_dict()\n",
        "        state_dict['polybert_encoder'] = self.polybert_encoder.state_dict()\n",
        "        return state_dict\n",
        "\n",
        "    def load_state_dict(self, state_dict):\n",
        "        smiles_perceiver_state = state_dict.pop('smiles_perceiver')\n",
        "        cross_attn_state = state_dict.pop('cross_attn')\n",
        "        polybert_encoder_state = state_dict.pop('polybert_encoder')\n",
        "\n",
        "        super().load_state_dict(state_dict)\n",
        "\n",
        "        self.smiles_perceiver.load_state_dict(smiles_perceiver_state)\n",
        "        self.cross_attn.load_state_dict(cross_attn_state)\n",
        "        self.polybert_encoder.load_state_dict(polybert_encoder_state)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "_wnL43mTZkIN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### training"
      ],
      "metadata": {
        "id": "6o91I0EXQaF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "wWmS0warQa-n"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_with_random_order(model, train_loader, val_loader, num_epochs, device,\n",
        "                           curriculum_steps=0, l2_reg=1e-5, sample_smiles=None):\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=l2_reg)\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=model.protGPT2_tokenizer.pad_token_id)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "\n",
        "    loss_log = []\n",
        "    checkpoint_path = \"/content/drive/MyDrive/classes+projects/plastic_enzyme_project/2024/codes/sigma_checkpoint_crossattn1.pth\"\n",
        "\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        print(\"Loading checkpoint...\")\n",
        "        model.load_state_dict(torch.load(checkpoint_path))\n",
        "\n",
        "    # Total training steps for curriculum\n",
        "    total_steps = num_epochs * len(train_loader)\n",
        "    step_counter = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        batch_losses = []\n",
        "\n",
        "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "            step_counter += 1\n",
        "\n",
        "            smiles_strings = batch['smiles']\n",
        "            proteins = batch['proteins']\n",
        "            protein_masks = batch['protein_masks'].to(device)\n",
        "\n",
        "            # Determine whether to use random or left-to-right order based on curriculum\n",
        "            if curriculum_steps > 0:\n",
        "                # Current percentage of random ordering\n",
        "                random_prob = min(1.0, step_counter / curriculum_steps)\n",
        "                use_random = random.random() < random_prob\n",
        "            else:\n",
        "                use_random = True\n",
        "\n",
        "            batch_size = len(smiles_strings)\n",
        "            seq_length = model.max_len\n",
        "\n",
        "            # Generate order\n",
        "            if use_random:\n",
        "                # Create random permutation for each batch item\n",
        "                order = torch.stack([torch.randperm(seq_length) for _ in range(batch_size)]).to(device)\n",
        "            else:\n",
        "                # Left-to-right order\n",
        "                order = torch.arange(seq_length).unsqueeze(0).repeat(batch_size, 1).to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Encode the proteins\n",
        "            target_encoding = model.protGPT2_tokenizer(\n",
        "                proteins,\n",
        "                return_tensors=\"pt\",\n",
        "                padding='max_length',\n",
        "                max_length=model.max_len,\n",
        "                truncation=True\n",
        "            ).to(device)\n",
        "\n",
        "            # Forward pass with order - the targets are already in original order\n",
        "            # The model will handle shuffling the targets according to the order\n",
        "            outputs, loss = model(\n",
        "                smiles_strings,\n",
        "                order=order,\n",
        "                targets=target_encoding.input_ids\n",
        "            )\n",
        "\n",
        "            # Print the raw token IDs (before decoding)\n",
        "            # print(f\"Ground Truth Token IDs: {target_encoding.input_ids[0]}\")\n",
        "            # print(f\"Generated Protein Token IDs: {outputs[0]}\")\n",
        "            # print(outputs[0].shape)  # Check the shape of the output tensor\n",
        "            # print(target_encoding.input_ids[0].shape)  # Check the shape of the target tensor\n",
        "\n",
        "\n",
        "            # Get the token IDs from the logits (choose the token with the highest probability)\n",
        "            predicted_token_ids = torch.argmax(outputs, dim=-1)\n",
        "\n",
        "            # Now decode the token IDs to a protein sequence\n",
        "            generated_proteins = model.protGPT2_tokenizer.decode(predicted_token_ids[0], skip_special_tokens=True)\n",
        "            ground_truth_proteins = model.protGPT2_tokenizer.decode(target_encoding.input_ids[0], skip_special_tokens=True)\n",
        "\n",
        "            # Print the ground truth and generated sequences\n",
        "            print(f\"Ground Truth: {ground_truth_proteins}\")\n",
        "            print(f\"Generated Protein: {generated_proteins}\")\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            batch_losses.append(loss.item())\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f\"\\nEpoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}\")\n",
        "        print(f\"Per-batch Losses: {batch_losses[:5]} ...\")\n",
        "\n",
        "        val_loss = validate_with_random_order(model, val_loader, criterion, device)\n",
        "        print(f\"Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "        loss_log.append({\n",
        "            'epoch': epoch+1,\n",
        "            'train_loss': avg_loss,\n",
        "            'val_loss': val_loss\n",
        "        })\n",
        "\n",
        "        scheduler.step()\n",
        "        torch.save(model.state_dict(), checkpoint_path)\n",
        "\n",
        "        # Generate sample proteins after each epoch\n",
        "        if sample_smiles:\n",
        "            print(\"\\nSample Generated Proteins:\")\n",
        "            for smiles in sample_smiles:\n",
        "                # Try both random and left-to-right generation\n",
        "                gen_protein_lr = generate_autoregressively(model, smiles, max_length=100, random_order=False)\n",
        "                gen_protein_random = generate_autoregressively(model, smiles, max_length=100, random_order=True)\n",
        "                print(f\"SMILES: {smiles}\")\n",
        "                print(f\"Generated Protein (L2R): {gen_protein_lr}\")\n",
        "                print(f\"Generated Protein (Random): {gen_protein_random}\\n\")\n",
        "\n",
        "    # Save loss log\n",
        "    loss_df = pd.DataFrame(loss_log)\n",
        "    loss_df.to_csv(\"/content/drive/MyDrive/classes+projects/plastic_enzyme_project/2024/codes/sigma_loss_log.csv\", index=False)\n",
        "\n",
        "    # Plot loss\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(loss_df['epoch'], loss_df['train_loss'], label='Train Loss', marker='o')\n",
        "    plt.plot(loss_df['epoch'], loss_df['val_loss'], label='Validation Loss', marker='s')\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Training and Validation Loss\")\n",
        "    plt.savefig(\"sigma_loss_plot.png\")\n",
        "    plt.show()\n",
        "\n",
        "def validate_with_random_order(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            smiles_strings = batch['smiles']\n",
        "            proteins = batch['proteins']\n",
        "            protein_masks = batch['protein_masks'].to(device)\n",
        "\n",
        "            batch_size = len(smiles_strings)\n",
        "            seq_length = model.max_len\n",
        "\n",
        "            # Create random order for each item in the batch\n",
        "            order = torch.stack([torch.randperm(seq_length) for _ in range(batch_size)]).to(device)\n",
        "\n",
        "            # Encode the proteins\n",
        "            target_encoding = model.protGPT2_tokenizer(\n",
        "                proteins,\n",
        "                return_tensors=\"pt\",\n",
        "                padding='max_length',\n",
        "                max_length=model.max_len,\n",
        "                truncation=True\n",
        "            ).to(device)\n",
        "\n",
        "            # Forward pass with order\n",
        "            outputs, loss = model(\n",
        "                smiles_strings,\n",
        "                order=order,\n",
        "                targets=target_encoding.input_ids\n",
        "            )\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(val_loader)"
      ],
      "metadata": {
        "id": "M6WRIYHEfN6y"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### inference + training"
      ],
      "metadata": {
        "id": "CfYBZUMhfOTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load and preprocess data\n",
        "train_data = preprocess_snp_data('/content/augmented_train.csv')\n",
        "val_data = preprocess_snp_data('/content/augmented_val.csv')\n",
        "test_data = preprocess_snp_data('/content/augmented_test.csv')\n",
        "\n",
        "train_data = filter_datasets(train_data)\n",
        "val_data = filter_datasets(val_data)\n",
        "test_data = filter_datasets(test_data)\n",
        "\n",
        "# Calculate max sequence length\n",
        "max_length = max(\n",
        "    train_data['protein_length'].max(),\n",
        "    val_data['protein_length'].max(),\n",
        "    test_data['protein_length'].max()\n",
        ")\n",
        "max_length = min(max_length, 1024)  # Cap at 1024 or your desired maximum\n",
        "print(f\"Max sequence length: {max_length}\")\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = ProteinGenerationDataset(train_data, max_length)\n",
        "val_dataset = ProteinGenerationDataset(val_data, max_length)\n",
        "test_dataset = ProteinGenerationDataset(test_data, max_length)\n",
        "\n",
        "# Create dataloaders with custom collate function\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=1,  # Adjust based on your GPU memory\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "# Initialize model with sigma-gpt capabilities\n",
        "model = SigmaProtFlamingo(\n",
        "    model_path='nferruz/ProtGPT2',\n",
        "    max_len=max_length,\n",
        "    cross_attn_every=1,\n",
        "    dim_head=64,\n",
        "    heads=8,\n",
        "    perceiver_depth=2,\n",
        "    perceiver_num_latents=64\n",
        ").to(device)\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "# Training loop with curriculum learning\n",
        "# Start with 50% of sequences in left-to-right order and gradually increase to 100% random\n",
        "curriculum_steps = int(0.5 * num_epochs * len(train_loader))  # Curriculum over first half of training\n",
        "print(\"Starting training with sigma-gpt capabilities...\")\n",
        "train_with_random_order(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    num_epochs,\n",
        "    device,\n",
        "    curriculum_steps=curriculum_steps\n",
        ")\n",
        "\n",
        "# # Generate and evaluate\n",
        "# print(\"Generating proteins for test set...\")\n",
        "# test_results = generate_and_evaluate(model, test_loader, device)\n",
        "\n",
        "# # Save results\n",
        "# print(\"Saving results...\")\n",
        "# results_path = '/content/drive/MyDrive/classes+projects/plastic_enzyme_project/2024/codes/test_results.json'\n",
        "# with open(results_path, 'w') as f:\n",
        "#     json.dump(test_results, f, indent=2)\n",
        "\n",
        "# print(f\"Results saved to {results_path}\")\n"
      ],
      "metadata": {
        "id": "e-67RvdafPdi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e12284da-bd94-4d46-ba50-4a039786c002"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Max sequence length: 914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training with sigma-gpt capabilities...\n",
            "Loading checkpoint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-b6a0dd5990d5>:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(checkpoint_path))\n",
            "Epoch 1/10:   0%|          | 0/3111 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MNTRAVDRLTDIDGGIAVDPAPRLAGPAVFGGPGLVDRTLAPVRSTGREMGLFDFPGVSIGWADYEEGPTGATVVHIPAGARTGVDARGGAVGLSGGYDRVHAIVLAGGSAYGLEAAAGVTDALRERGGDPAGFAEIPLVSGAVIYDFSTNDTAVRPDKALGLAALEAAVPGEFPVGRVGAGRGASIGKVDPDRTMRSGPGAAFRELGDVRILAVTVVNPVGVIVDRAGTVVRGAYDPATGVLAPPVYDYVAAFAEPVPPVPEAGNTTIGAIVTNVRMSPGELNQFAKQVHVSMSRAIQPFHTDMDGDTLFAVTTDEIDLPTTPGASRGRLSVTATALGAIAAEVIWDAVLEAGK\n",
            "Generated Protein: MNVHVHVHVGLVGLVGLQERPVHNPNPAHNPVHVHRLMNATPATPVVVGSDALVVGPAGPASAPLRLAHAGRDAPLAPLRVLAPLKSLKSLKSLKSLRPPVTRPPVTAPLRPPVTDLSRSPVTRPNPVLDPVTMQMQNPRAGPASPASPASVPLTQLPLSRLWDWDVHARSVHAPLVHPPAHVHVAAVAGAPLPAGVHVHPPAVPPNAAPVGFGLNPLLGAHPPVGPVGMLDMLDMLDRDMLDVHMLDTGGVYFTSTGGRLSRPALGRPRPWDPLSWDTGLPVTWD\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   0%|          | 1/3111 [00:02<1:47:05,  2.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MKRRRIAGSIAALAISAGAVALPAESASAAPCSDVDVSFARGTGELPGLGITGTPFVNSVKSQLSGRSVSTYAVNYPADFDQASAGPGSRDLVAHLNSVAASCPETKFVIGGYSQGAAVVTNALGLRTPSGATGAVIPAAIADRIAAVVVFGNPFGLTGNSITTQSSTYGSRTNDFCNFGDPVCQIGGNDPFAHLTYGFNGITTQGASFAAAKVRR\n",
            "Generated Protein: MSKVTGRKYDHFAFAFAFGAGGDPAGQAQAQAFGAGGFGAGGDIVFGAGGQAFGAGGTGRKFGAGGTGRKQAFGAGGFAFGAGGFGAGGFAFATGRKFGAGGTGRKFGAGGFGAGGFAFGAGGFGAGGTGRKFGAGGDPAGTGRTTGRTTGRTFGAGGYDHFGAGGFGAGGFGAGGYDHFGAGGFGAGGFGAGGFGAGGFGAGGTGRKTGRKTGRKTGRKFAFGAGGTGRKQAFAWYFKGFGAGGFAQAYDHFATGRKFAQAFGAGGFAQAQAFAFGLLGQAQAQAFGAGGQAQAFGAGGQAFGAGGFGAGGQAFAFATGRKFGAGGFAQAQAFGAGGFGAGGFAFGAGGFGAGGFGAGGFGAGGFGAGGFGAGGFGAGGFGAGGFGAGGFGAGGFGAGGFGAGGFGAGGFGAGGFGAGGFGAGGFGAGGFGAGGFGAGGFGAGGFGAGGFGAGGFGAGGQAQAQAFGAGGQAFGAGGQAFGAGGFGAGGFGAGGFGAGGFGAGGQAFGAGGQAQAFGAGGFGAGGFGAGGFGAGGQAQAQAFGAGGFGAGGFGAGG\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   0%|          | 2/3111 [00:02<1:10:13,  1.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MKKVLFKKWSLQLLVALALVIGTLGFIQPKEVKAASKNPVVFVHGIGGASSNFASISSYLVGQGWDRNQLYAIDFIDLTGDNQNNGVRLSKFVQDVLNKTGAKKVDIVAHSMGGANTYYYIKNLDGGDKIENVVTIGGVNGLKSSLALWRTDPNQKIDYTSVYSSADGIVVPSLSRLIGAKNVEIGGVGHIGLLTSSQVKGYIVNFLNGGGIITY\n",
            "Generated Protein: MKFGDDTDDPAGYDHVVVAVDPAPDPAGDPAPMPTINQLVRVVVAVVVVAVDPAGDPAPYSVVRGNDFYHENDFYHENDYGYSVVRGVVVAVNDYGKFVQKFVQRYIEFCVVVAVGLTAVDIVDPAGDPAGKFVQKFVQDPAGKFVQKFVQYDHDPAGSMGGSMGGIFVLAVLMSGHSKWIFVLAVLVKNRIFVLAVLYDHDPAGMSGHSKWYDHGLACRYIEFCYDHDPAGDPDEDPAGTGRTDPAGRYIEFCRYIEFCDPAGDPAGDPAGDPAGMPTINQLVRGLTAVMGQKVHPDPAGRYIEFCDPAGVVVAVDPAGAAVRRDPAGMPTINQLVRMPTINQLVRVVVAVMPTINQLVRVVVAVIFPDKPDIVIFPDKPYSVVRGEEEPYSVVRGVVVAVVVVAVVVVAVVVVAVVVVAVVVVAVDPAGVVVAVVVVAVDFVDDFVDDPAGDPAGDPAGDFVD\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   0%|          | 3/3111 [00:03<58:24,  1.13s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MDVAEYAAHDATGLAELIREGQVSAAEVATAAATAADAVEPELAAVAGELFDPPLSYDAHGPFAGVPFAVKDLVARAAGVPMRSGSRLFGAGVAAPEDTELVARFRRAGLAIAAKTRVPEFGFNATTEPIAYDGPTRNPWATDRSPGGSSGGSAALVASGALPMAHANDGGGSIRIPAAACGLVGLKPSRGRVPLGPDFADPLLGLGIEFAVTRTVRDSAALLDAVHGAEPGDRYLLPAPVRPYAEHAAAGSRPLRIAVTTTPALAGRAVHPECVAAVRRVAERLAELGHVVEEAAPELDVAAFRRAYLTAWASFLADAVLGASEQLGRQPSRETLEATTLASVERGLTLSAFDIITALRVRSQTTRAVGGFLTRYDVLLTPTTSAPPIPLGHLDAGDASLSAREWLDRIFGYGPFTAIFNVTGQPAISLPLGESAAGLPIGIQFAGRYGDEATLLALAGQLERAMPWADRRPAVPVGR\n",
            "Generated Protein: EETRARSTGTGREAIVLMDLGAIVLDPAPEETREETRERMGMGGEDLERAIVLTGREWNLGTGREVPGEVIYDEETRNDYGAITGMDLGDETYAIVLTCTDTCTDEETREETRTCTDAIVLAIVLAIVLAIVLAIVLAIVLREWLAIVLAIVLWNLGAIVLERMGERMGAIVLAIVLWNLGWNLGWNLGAIVLWNLGWNLGWNLGAALGRVPGEAITGVPGETCTDVPGEADRTADRTMDLGVPGEMDLGMDLGMDLGMDLGMDGDKAYDWNLGWELGELGKWNLGRIFDRIFDAIVTRIFDRGRTDFVDMDKTDLERMDGDMDGDMDGDAIVTMDGDADRDAIVTMDGDAIVTAIVTMDGDDFVDMDGDMDGDIVHSMDLGMDGDMDGDMDGDMDGDMDGDERMGWNLGWNLGMDLG\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   0%|          | 4/3111 [00:04<53:15,  1.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: YDVRGGDAYYINNSARCSIGFSVNGGFLTAGHCGGGTVTGSNRVAQGSFARASFPGNDYGTVRVNSNWVPRGSINNGTRVSGSSEASTGASICKSGSTTGWTCGTVQAKNQTVNYAEGTVYGMTQTNARSQPGDSGGSFISGNQAQGMLSGGNSTVTYFFPVRPALSATGLSLVTG\n",
            "Generated Protein: AAALAIAILLRTAAALGLAAAGAAALAAAAASTGGLATAAGLAAALAAALREAAALGLREREASTGIIAPASTGIIAPAIAIAIAIAKELGLGLGLGLAIARGLAKAKAKAAATASRSASRSASRSAAALAEELARAAALYDAAAAAAALGGTTELARGGTTAAALGLAKGGATADRTAKGLAKAKAKIGATREIEAKAKAKAAALAAALAAALAAATAKELARAAAL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   0%|          | 5/3111 [00:05<50:13,  1.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MGLAIAAAALGSLPGVATATEPTGGVQPLIVGGGNATQAYSFMVSLQSSSGGHSCGGSLISSQWVVTAKHCGTPSQVRVGTTNRTSGGTVATVAQRIAHPSADLQLLRLATAVTYAPVTIADSSGAVGTATRIIGWGQTCAPGGGCSAPTTLQELNTSIVSDSRCSGISGASEICTNNPNGNSGACYGDSGGPQIKQVNGVWQLVGATSRAGNNSSTCATGPSIYTDVPYFRSWIRANTGV\n",
            "Generated Protein: RGVTRGVSRGIGISRGVSVSRGITRGRGRGREREITFEVSAEVSYDITITIGVTFERGREFERGVSYDVSAARGRGVTAEITRTGITKVDRGIREITRGISRGRGITAIRGRGRGRGRMRMADRTVSVSRGRGRGVSITLLRGVDITRGITYDIGITITYDITVSRGRGRGIL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   0%|          | 6/3111 [00:06<48:24,  1.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MRKLKLLLMVCMSMVFIFTLGGMGQSPKASAAGERTPIVFVHGHGGSSSNFALIERKLRKEGWSSEELFAISLPSGTGNPALNSAAISRFVDDVLRQTGHSKVNIVAHSMGGASSLYYILNQGGADKVDRLITLGTANRLPTSRAPDGINVTSIYSTSDLIVSPALSRLDGANNISVPGVSHIGLLSNSAVLSLIKNALTE\n",
            "Generated Protein: PHIPGPHFPGILLLLLGSIQTAVAATTSRTGAPNIRGSFPGFEIPGFPGGSSNGGGGGGIQRTGRTGYYDTTSDSPHGSIPGIPGPEIPGTAVIPGIPGRTGGSKVDTTSDSTTSKVD\n",
            "KVDGGGKVDPHIPGTDGGGYDSSSISGGSYGSPHNSFQYFITGPHPH\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   0%|          | 7/3111 [00:07<47:03,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MSELLWSRDGLDWPHREASRFIEAGGFRWHVQEMGSPKAPAILLIHGTGASSHSWRDLAPLLSRHYHVVAPDLPGHGFTQTPRGSRMSLPGMASDLAALLRVLKVAPALVVGHSAGAAILARMCLDGQIDPKVLFSLNGAFLPFGGPAAKFFSPLAKGLFMNPFVPSLFAWQAGHRGAVERLIGNTGSTIDPAGIELYGRLVSDPAHVAAALSMMANWDLEPLLKALPNLKTDLVLVAAEGDRAIPPSVAAKVAEALPNAVIERLPALGHLAHEERPGEIAALIVRAAEKLEIRE\n",
            "Generated Protein: MRLRTLFYLLARIFRLVSSSSYFLLARKASTTLIQIFCRLRSIARFQRRLRSLLARYLLARLLARFFHYHYSSGYHYTTLHYHYYFYFCFYFTTLTTLTTLTTLTTLQFSLTTLLLARYLASTTLLLTTLRIEYFASFARRIPRIPRIPRIPHIYYHYNSLLARTTLFQRHTTLNIPSNHNSIF\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   0%|          | 8/3111 [00:08<46:19,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MTASTTRQRISARRLGLRRATIGVATAGLVAAGFTAAPAQAATGPVAGSTARSASAAGSGTPQANAVVSEAQFNQMFPNRNPFYTYQGFVDALSAFPGFANTGDDTTDKQEAAAFLANVNHETGGLQYVAEQNSANYPAYCDPSQPYGCPAGQAAYYGRGPIQLSWNFNYKAAGDAIGVDLLNNPQLVANDPAIAWKTALWYWMTQSGGGGMTPHDAMVNHAGFGQTIRSINGGLECDGQNPAQVQSRVDAYKRFTSILGVAPGDNLQC\n",
            "Generated Protein: MTTASTTASTTLLAAPSIPLLSRSSSSSSRLASRLASSSTLTAVNLPAALPSIPRLGSSSTLRLGSASTTTLGTLGTLGPSIPRLASDGINNYELRGELASRLGSSSTLPSIPTTLRLASRLASRLASAALRLASTTLTTLTTLTTLSSTLRLASSSTLTTLELASELASELASELASTTLELASSSTLSSTLVIGMTTELASRLAARIPRIPSSTLRLGSLLNNLLNNPFYQFPSIPELGDELRGTTL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   0%|          | 9/3111 [00:08<45:53,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MANKYERGPDPTESSIEAERGPFPVAQTTVSGLDADGFGGGTIYYPTDTSQGTFGAVAISPGFTARQESIAWLGPRIASQGFVVITIDTITRLDQPDSRGRQLQAALDYLRTNSPVRNRIDPNRLAVMGHSMGGGGALEAAANNPALKAAIPLAPWHTNKNWAAVRTPTLVLGAQLDIIAPVSSHSEPFYNSLPSDLDSAYMELRGASHLIPNWNNTTTAKYSIAWLKRFVDDDTRYEQFLCPAPDDPAISEYRSTCPFLEHHHHHH\n",
            "Generated Protein: MRLSLPSLPAVLAVLAIGAALAVLGLPLNLPNLPELRGHSAVLTLGQTLAVLTLGNLNGAISPKLGLPSMAALSMVIAPAYAAFFPLSMYAVSMAVLMTTDGINSLPSISSSMMAVRSAALHSAALAALAALAALAALHSHSAALAALQIEAALVIGQLIGAIGAALHSVIGSMAALHIGATPFYAVLPFYAYSLPSMELRGSMAALSMAALELRGELRGAALDCDIL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   0%|          | 10/3111 [00:09<45:30,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MTNVLTKIKLALGSIAIAFSLPSFAVDCSDCSNGFERGPDPTVDALSSSYGPYSVKTINVSTLRRGFGGGTIHYPTESSGQRGIIAVVPGYNSFESTISWWGPRLASHGFVVITIDTNTIFDQPDSRALQLSAAIDYVISKGNDRSSPIYGKVDPNRVGVIGWSMGGGGSLIAATDRRIRATIPMAPWYLGLSEFSSITTPTMIIANQADVVAPVSVHASRFYNQIPSTTPKAYFEIAGGSHFCANTGTPSEDILGRLGVSWMKRFIDNDERYTQFLCGQLFDSSNGVSEYRDNCSIY\n",
            "Generated Protein: MEVSGPKLMRGPKLAVNPAVNPASRFFAEPEPTAVNPGGNNPEPTTRTGAVNPAVNPVSGAVNPAVNPPKLDGINDGINAYAAQVNWINVIAPMPGGGISPKLDGINAVNPWINQVNPKLPKLWIDPKLIREGGISAVNPPKLKVDPKLQIEAALAVNPDGINAVAPYLVSKVDVSGVAAGGISMVDPKLAVNPMVDAVLKGKLVSGGGISGGISSSRLGGISKGKLAVAPGGNNAVNPGGISPKLPKLACASRFTNAYLAVNPDGINDGINTDPKLDGINDGINCRYGGISDGINNYGGISARMPSGGISRFYEMPGVAAANGGISWIDNY\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   0%|          | 11/3111 [00:10<45:09,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: AQSVPWGISRVQAPAAHSRGLTGSGVKVAVLDTGISTHPDLNIAGGASFVPGTPSYQDGNGHGTHVAGTIAALNNSIGVLGVAPSAELYAVKVLGADGSGSVSSIAQGLEWAANNGMKVANLSLGSPSPSATLEQAVNYAYSRGVLVVAASGNSGRGSISYPARYANAMAVGATDQNNNRASFSQYGTGLDVVAPGVNVVSTYPGSTYASLNGTSMATPHVAGAAALVKQKNPSWSNAQIRNQLTNTATSLGSTSLYGSGLVNAEAATR\n",
            "Generated Protein: MRLFSHSQQTTFAEFAEFAEFAEFAEFAEVSGKGKLVQEQVNFKEFKESSSNWINWIDQRGLWINQVNQVNVSGMEQVNWINWINKTGGKTGGYAVKTGGKTGGKTGGQVNQVNQVNTQKTGGMGLKGKLMGLKTGGTQKTGGDKIEKTGGWINDGVDTSGLHGHSDKIEQELKGKLQTYSQTKVDCTSMEFQEKTGGKTGGTLEQGGPLQVNGYTIFAEYTIIGATIGATKTGGFQEKTGGKTGGKGKLTQFQEKTGGANFQEFQEWINFQEKTGGWINDGVRFQETQFAIFQEFAEFQEFAEDGVRDGVRKGKLDGVRKGKLTQMEFAEWINDGVRWINVSGNNGWINKGKLKGKLKGKLWINQSKGKLKGKLKGKLKGKLKGKLKGKLKGKLVSGVSGATGMPSWINWIDKGKL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   0%|          | 12/3111 [00:11<44:53,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MQLKHLFLFIVCSFFLSGCEDITNWAYETGLAMEKNRAGLKDQSLTLADGITFHYLTSEPSAEPSAEKPAVLLIHGFSADKSNWVRFANELEQDFFFIVPDLPGHGETTRDTDQTYTMSAQATRLLTLMDALQISHFHVAGNSMGGAISLALAQQAPQRVLSLMLIDSAGLTPQTEAFETILADESSNPLIPHTAEQFQATLQFAMEKPPFLPSFVVDIMGRKAAANAALTEKVWRDLLEDPGVMLELKNVLSSIQAPTLVLWGREDRMLGVDNVGRFEEALPQARAIVLDGIGHVPMMEAPGKSADAFRAFWREVRP\n",
            "Generated Protein: MEYERGQWVGALPGMEFAEFAEIEAVAYEKAYEKDNPVQEDNPIEAVDNPHGELHGELFPVPMEADYDDVEQWHGELFPHGFPHGADYADYADYADYTQAGYWAAADYMSQRPGMEQRPGQRPGRGGQRPGAQVQEDNPRGGRGGFPVPVQEPFGGFPKDVQEMSFPKDQSRAIRAIVQEDNPDNPDNPAVEVQEAEQFAEQFAEQFANNQPLIGATANANQRPGTQANMELQNDNPAPWCRAIRAIANESWCDNPDNPMELTNMSMSMSMSTGDDASIERAIRAITDRAIRAITDANQSQSAPIHGDNPRAIRYMEMELANQSQSTDRAIANAQ\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   0%|          | 13/3111 [00:12<44:47,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MPGWVWRVRTAALMAALLALAATAGVTASPSVEAQSNPYQRGPNPTRSTLTADGPFSVATGTVSPLSVSGFGGGVIYYPTGTSGTFGAIALSPGYTADQSSLAWLGRHLASHGFVVLVINTNSRFDYPDARAKQLSAALNYLRTSSSSAVRNRVDTNRLAVAGHSMGGGGTLRAAEQNPNLKAAVPLTPWATSINFNTSVPVLIIGAEADTVAPVSQHAIPFYQNLPSTTPKVYVELKNASHFAPNSNNAAISRYTISWMKLFVDNDTRYRQFLCNVNDPALSDFKYYNTRCQ\n",
            "Generated Protein: METEWCMLISAIISAIFVVAAAFTGDCTEDCCQYTVSCQDCRYTGWCFPVPTLEDCVSGTWGTQVSGFVVFVVITIDFPVPITIDRYRYWWGIREFVVWWGQEAAFVVFPFVVMGYYFVVIRETNYYGDCRGGYYGYYGTDNDGYYGTDWSFPWCIVAPTIWSAPCNWSIAPACEYTITGCSGIGATYTIVRWYWCYYRYININWCINTNYYINWCWCWCWCPEPDCTDRYTQTDTQQSPEPWCWCTDWCYRSCPY\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   0%|          | 14/3111 [00:13<44:55,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MNTTPVHALHAIDGGIAVDPALRTAGPPVVGGPGNDAFDPAGRRSTERVMLRFDLPGVSIGAAPYEEGPTGATVIHIPAGARVAVDARGGAVGDSGGYDVIHAIVLAGGSSYGLEAGAGVSGALLERLGDRTGFAETPLVSGAVIYDFSAGNTAVYPDEALGRAAVESAVPGEFPRGRAGAGYSASTGKFDGDRTEHGGQGAAFRRLGDTTIAAVTVVNPVGVIMDRAGTVVRGNYDAATGVRRTPRFDYVEMVAEQRPPVTEAGNTTIAAIVTNVRMSPVELNQLAQQVHSSMARAIRPFHTDMDGDTLFAVTTDEIDLPTTPGSSRGRLSVNATALGALASEVIWDALLEAVK\n",
            "Generated Protein: MSFALTTPEATGLATGLAFADGLRRAFADIEAVIEAVIEAVWAFWAFIEAVIEAVAAAFCEEGFVVSIGVSIGQWINAVVVSEVRFFPLAAAFAAAFASDLTTTDASDLHDTTTDTTTDTTTDFVTTTDASDLTTTDMSVPGETTTDAAAFRFPDAAAFIRAGASDLVPELVPELTTTDVPELTTTDTTTDTLETPVVVPGEVPGEVPGEIPASIRAGWRTAAAFRRDGWRTIPAETTTDIRAGASDLAAPETTTDAPPTTTDAAAFASDLMSAAAFAAAFTVAPPIRAGMSQEAAAFAPPITVDAPPITVDAPPIHGITVDAPPMSRYAPPAPPITVDMSTWGVEATVHGAYPEAAAFAAAFVRADAVAREIEFTAFAAAFADAVAAAFTSVVSEAAAFRYIEAVIHGIHGTGIHGFVAAAFAGYDAAAFTTTD\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   0%|          | 15/3111 [00:14<44:44,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MKFFTLTTLLAATASALPTSTPVQELEARQLGGGTTRNDLTNGDSASCKPVIFIYARGSTETGNIGTLGPSIASALESAFGKDKVWVQGVGGAYRATLVDNSLPRGTSSAAIREMRGLFQQANTQCPDATIIAGGYSQGAALGAAAVEDLSSSIRDRIAGVVLFGYTKNLQNQGKIPNFPADRTKVFCNAGDLVCTGSLIIAAPHLTYGPDAEGPAPEFLIEKVRAARGSA\n",
            "Generated Protein: AQSYERGVLLRRSARRLGLRRGLRRVSGLRQRARQLARQLAQAAYERGTNGTNGVHGTYGARSGARGSPSTIYVVSEVVSETIYTIYTIYTIYTIYADGTYGTYGVVSEAISFPKDQEAAFVVQEAAQEAAIREITIDIREQEAARQRVGATNLTLETLETLEYLSDSSSNYSTSFPKDFPKDTLEIITLEVRTPTLEAAGDTLTLEDVTLEYLSDNKSTNGTYGTYGTLTYGIITNGTNGKRKRTLKRRYERYEAYYEPSKRNLNVKRCPY\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   1%|          | 16/3111 [00:15<44:34,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MELNSMWFLLGLIGLLLLIVTGLRRWLLRRLSPQTQAVDKHGDIYQVGSAVIARSRADQPALVVIVCHGFNENFRYFTEHYADPDIDLIALTSADYHLPVDDPRFTVADYAKIPGQRSGTIAYDAAVLAQVLEHLATGTQIRVHGHSRGGAVTLEAARQRPDLFAQSEWILEAPTLPAFNPLLAVSPLARIFAPFYLFANQQAPASRAIAKRFKPLDNPRKRELIDALPFNPRYGRTLVNTIKDLADVMDSYNQDIAQHVGQGQILVPSHDLILNAPAMLQSAQQAESLQIIEVPGASHLITHDRPDLIWPLPG\n",
            "Generated Protein: MSVHGVLLALEVLLAFADIFTTAVEAVETTVHGVHGDLVHGTTTTALEALEADGAMEDLDLVHGPSRVLRVLDLRGGDLHSRVLHLPDLDLDLPGRVLRVLRGGDLTTTTTTHSALETLETLEVRRGGALDLALTLEALALVRALDLTLEAVEAVEAVEAVEAVEQLLLSIIAGLLSILEDLALTLRVLALTTPSALALEDLALAVEINNLAPPVHGIFVLLVDRAI\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   1%|          | 17/3111 [00:15<44:30,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MRSLRLLGAASAAAVALTLAGGAVASAGPSPNIVGGSTAPTGSYPAQVYVNKKGRDYQGFNCSGTVIASRWVLTAAHCVAGGSSGATVRVGSNTLGSGTKIAVDRAYESPNGDIALLHLASATSASPISLGSSDPATGSTNQLYGWGRTTPTGPPATSLKTANVQVTGRSTDAYGNRAIQSVGINGSAWGGDSGGPLVANGVQVGVASTVSNESGSNTPGTNRYASVAASRSWIRTVSGV\n",
            "Generated Protein: MGLQVYSVLLVLLALSLPGVGLAQASAAAQSPTNSINRTPAQGQGSSSNSSSNNNSSSSSNQWQSALSVNSNVLLVLLVAPSVAPSVAPSVAPSPGDLVADADLTTQSYIAGKQNSNSQLVAPSPSPSAQGAQGPSPSVGATCPPVLLAQGFISGAQGVGATTTSSAHGPGEVAPSAQG\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   1%|          | 18/3111 [00:16<44:22,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MTKQALPQGPAPQRLKRFFTAALCSLLVLLLWPTTVLAGQTFSYTSPDAAASGSRERSYKVYVPDGLSTPAPMVMALHGCRQTNDDVLNDWGWKDAADREGFILVAPSITSADGLRNANCWGYWLSQHIHQGGGEVADLHNIAQHVEANYNIDAKRRFITGLSSGGAMAVVAAVAYPSVWAAAAVAAGLPYRGTASSVSLSGQCRGSATKRSVSQVAADMRSLGNAAYPIPLMIYQNANDCTVLPTAANNIRDAHLQVFGSADAATPVTTKASDTGCSPYHLNSYGCRHEAYTQGGTTATRPRVETVIYDGPPATPNPDPTNHGHTWPGGANGNNGKWSRQDGPSYPDIIWDFFSRYSRDGPQPQGPPVITLQGDNPLSVPLGSTFNDPGASASDAEDGSLPVSIDCSAVNPSVVGSYSCTYSATDSDGNTSTVTRTVEVQDPNAPVFTCQVGSASNSAHIGAGRAYAGYLSALTAYTKDDGVWIVGSFRTSINVWLYEGEDGTLYAQRYAACGGSVQAFTCQEVAASNSSDVGAGRAYAGGYTVGGNQYAGSLSGTRTIVRETAPGQFQAGPCSN\n",
            "Generated Protein: AQSTTTTTTATTTVTAQAAAATPTPAAVTKHVATGATATVNDNVNDNVNDNAANSANIIQTRGPVNSNQGVATGYSVATGVATGAGARRGGQGPGVADNVVATGNYVATGAGAAAAAANTNSAGAAPSPSPSPSAQAGAAQTHGGQNRGGAQGPSPNYQTAGAAVATGNPSLNPSLNPSLNPSLVTAWNPSLALQLNSANTPTPAAPEVATGRGGHGGATATVNDNNPVATGPSTTAQQIVATGQILLSPSPSTTQAGAPYSVATGNSANVATGPTALSDQSPQAPPTTVATGALSDQSPQRFVATGTTQTVATGTTTTTTVATGQGATTTVNDN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   1%|          | 19/3111 [00:17<44:49,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MKFFALTTLLAATASALPTSNPVQELEARQLFGGTTRNDLTNGNSAPCAPVIFIYARGSTETGNLGTLGPSIASGLESALGRDGVWIQGVGGAYRATLADNSLPRGTSSAAIREMKGLFQQANTNCPDATLIAGGYSQGAALAAASVEDLDSAIRDKIAGAVLFGYTKNLQNGGRIPNFPADRTKVFCNTGDLVCTGSLIIAAPHLTYGGDAEGPAPEFLIEKVRAAKGSA\n",
            "Generated Protein: MKFVRTPKDTSAASAAPALPVATVATAAPVATGGDAQNPPGPGNDQRARGSNGHGGARGSQGQGDDDYPNYPASQGASQGASQGYPDDDPGRFDDDQFLQLNAAYSQGYSQGAGYSYSQGDDDPSPSYPQLNQNQLNASQGNAQAAASPSPNAQYTKAVRNAARPDLVRTPNGVRTPYLSDVRTPRPDLNPSLVRTPRPDLNKSAAPPSTSIALVRTPVRTPPSTTAQQIPSTTAYYEQTIRPSTTEDEDKDTS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   1%|          | 20/3111 [00:18<44:39,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MADDSTGTDPARYPGAAAGEPTLDSWQQAPHNRWAFAHLGELLPTAVVSRRAPATPAEPVVRLDALAGRLPDLEARLEETFTDALLVLRGSEVLAEYYRAGFAPDDRHLLFSVSKSLVGLVVGALIDEGRIDPARPVTEYVPELAGSVYDGPSVADVLDMQVSIDYSEDYVDPASHVSRLERSAGWRPRRDGDPADLYEFLTTLRGDGATGEFQYISANTDVLAWIVERVTGLSYVEALSTLLWAPLDAEHDATITVDETGFGIAAGGVSATARDLARVGRMMLDGGVAPGGRVVSQGWVESVLAGGSREAFATGGFVSAFPEGSYRRQWWVTGNERGAVSGIGIHGQNLWLDPRTDTVIVKLSSWPDPLTRAWHGLTSGALLDVVRALDAV\n",
            "Generated Protein: MDQSNVRAYPEAYPEVGLVGLATVIATVIATVIHNRIARYQRGHNRQGRTPALGSIARRFDAGGSCSGATVIATVIATVIATVIATVIATVIVSGRADGIPGRGGSGEGDATVIEGDSGAGGSAYATVIAGGSAGAAALIDALIDYPGALIDAVTQIRIYDIYDHGGAYPEPFGGGGSGAGGSVPGEAARAGATVIATVIATVIAAQGAANYDQGAAAWPGDPPGDFATVIPGDPPGDPRAGATVIRAGNVRAAAAAAAYPEPGDPEKADRDEKALIGADRDTTPLGGAIVTNVRAIVTAIVTNQFPGDPFDEPGDPHGGHGGAYPEAGKAAPYHDAGGSAGGSAGGSAFADDLPAYPEHGGAYPEATVI\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   1%|          | 21/3111 [00:19<44:44,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: SPVDLQERQATGNDELRDGPCKPITFIFARASTEPGNLGISTGPAVCNDLKAARSGDVACQGVGPLYTADLPSNALPEGTSQAAIKEAQTLFEQAVSKCPDTQIVAGGYSQGTAVMNGAIKSLSADVQDKIKGVVLFGYTRNAQNRGQIPNFPKDKVKVYCAVGDLVCLGTLIVAPPHFSYLLDTGDASDFLLSKLG\n",
            "Generated Protein: MKFGGDLLSFLYPAIGAFADTVALGGDGGDGGDDKTTVQRTPFIYVIFIYFIYFIYADGFNFNTIYTIYFNVLIYNGPYPTNQGVIFANFANQLQTGDDDYIVAHSGFVVIIIADFNRFQQIADTCFNAAASTQIRNRIPLDYDYMGGPDYTLRDYGGKVFFNTLRINGSQFQFNSGKTALIIVQVGFLNGAERDAMVNFLIERGSIIAMVNFYDRFYNCANQTIRNYTCHFQFLADRDFNRYSTCYTQYTQFNFNFLCGSGQFLQFL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   1%|          | 22/3111 [00:20<44:51,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MVRVFGSTLLALLVPALAAPVAEDLEARQSGCADVIVVYARGTTQDSPIGDPASVGPLFRDNIKSLLGSRTVSFQGVNYAANVIGFLQGGDPAGSRQMTTLLTNVANSCPNAKIVSSGYSQGGQLVHNSAAQLTAAVRNRISAVVIFGDPDLDQAVTGIPSSNVKIICHDGDNICTGGLIVTAGHLSYQQDAPAAAQFVASKV\n",
            "Generated Protein: MVRHLNSLLFLLFLLFIIVLIYNWGGDCSSYVIRTPSNTQVQNGPSNGLGGLGRFQQGLNYLVGRTLLLGSFNTCFNNGPNRTNNGPIADYTSCPSADLCPNCPNIVAHIVAHTQVQIADIADNYNVVKLIADNVVFNIADSSIADFGLSSIIIADIINFGNFGNFGNFGQIGGTQLQIGGVCVCGLNGLNIADGLNGLN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   1%|          | 23/3111 [00:21<44:46,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MKFFALTTLLAATASALPTSNPVADLEARQLGGGTTRNDLENGNSAECRKVIFIYARGSTETGNLGTVGPSIASALESAFGRDNVWIQGVGGAYRATLADNSLPRGTSSAAIREMKNLFTQANTRCPDAAIIAGGYSQGAALAAASVEDLDSASKDKIAGTVLFGYTKNLQNGGRIPNFPADRTKVFCNGGDLVCTGSLIIAAPHLTYGPDARGPAPEFLIEKVRAKRGSA\n",
            "Generated Protein: MRALWLLFLLFSGTGLGGGGELEARYQRGSDARTIYNSASCAPFIYVIFALGGLLGSAWLAWLWDRSTIYGGAWLTPSGTIYIAWSGSGSGSGAWLAWLAWLFVVMRGLFVVTRLFTIDGGGGGGSGTQIRTQIRIPLKAAASQPADLGGWHLPDYGGTLRTLRTLRGGGGTLRTGDLSLPSSKTALAPGGDSGAGTCAMVNTCKVRAWLAPIGGPAPTGLILGARGGKLTCFLCGGGTC\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   1%|          | 24/3111 [00:21<44:31,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MKRSALSLAVLSAASLVMAAPTPASAEAHELEARATSSACPSYVLINTRGTGEPQGQSAGFRTMNSQITAALSGGTVYNTVYAADSSQNSAAGTADIIRRINSALAANPNQCYILEGYSQGAAATVDALQQLSTSSAAFNAVKGVFLIGNPYHKSGLACNVDSNGGTTTRNVNGLSVAYQGSVPSGWVSKTLDVCAYGDGVCDTSGGFGINAQHLSYPSDPGVQTMGAKFAVSQLGGSA\n",
            "Generated Protein: MRDLVLYRILKLDRMVCMVCTLDNVLIYTLDSTLDSDLVLSTAPTVTGDSRGTSAGTSAGTSAGNFYNFYTLKSVLIYKDLVLVLIYVLIYVLIYVLIYTSAGVLIYTSAGTSAGDSRGKSGKLVRIVAHAVPQAVPQTSAGMKVYGHSWGLYGHSSSAGEYSSAGSSAGYIYDGLVSTSAGCGTPSSAGKLDRTSAGSNDRVMRLDGISGIINGSTQIRINGSCANSGSYSGSYVQVGVQVGVLIYSGSYVQVGMKYSYRILSGSTIFLCGFLCG\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   1%|          | 25/3111 [00:22<44:22,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: YDVRGGDAYYINNSPRCSIGFSVNGGFLTAGHCGSGTVTGSNRVAQGSFARASFPGNDYGHVRVNSNWTPRGSINNTTRVSGSAEAPVGASICKSGSTTGWTCGTVGAKNATVRYAEGAVYGMTRTNARSQPGDSGGSFIAGNQAQGMLSGGNSTVTYFFPVRPALSATGTSLVLG\n",
            "Generated Protein: MKYSSLRVLMVCRVQSLPGTLPGTLDSELEELEHNRDLVLAPAVPQNIRTVTGRDPVIFPGEEGEEGGLEVLVLVLSLDQSVALADKSSLDQPDVEFANFANFANYEFLIVAHNGDIGLENGDIMRGLMRGLKLAVGTGLVSATLEYEYGLVSAAASAWSGGSNARPNISGANVQDRVMDRVMRAIVQVGCANTQLTLDSSGSYTLIF\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   1%|          | 26/3111 [00:23<44:09,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MGRRAWRGALFSAAWLIAFGIVVHAVGAVAETAPQSREAVPAAKLDGEALYKARCAACHDGAERRTPSREVLSKRPASFIVAAMRNGAMSPMAAGLTLEEMDAIAAYVGKGDAKTDDGIDLRRIPGNSVAGTPLRASQCSSAPTPDDLSAANQWNGWATEKDNGRFQPNTALAVADIPKLKLKWAFGYPGSKIGQATVAGDRLFITSNSGAVYALNAKTGCVYWRYKYEGATRTSPVIAAWPNGKPAKTALFFSDFTKNAYALDAETGKQLWKTKVDDKPAAQMTGSITYAGGKIYVPISSGETAFAADPTYECCKFRGALVALDAKTGKILWKRYTTEEEPRPSKTNKAGSQMWGPSGGGIWNTPTVDPARRLIYVGTSDSYTDPPYDNSDAVMAFDADTGAVRWTHQLLAGDTNNDGCWQIGKEHANCPNPDGLDFDIGAAPILRKSADGKEVLLVGQKSGMIWALDPANKGAKIWQRQLSRGSALGGIEWGTAADDGKVYAGISDIASQAKDRGKPGLWALDVRTGEVAWNVEPAPDSACRWNNPDCHGAFSAAISVIPGAIFAGSSDGHLRAHDTATGKIIWDVDTGTKSVTTLSGAKARGGSMDGAGPSIAGGMVYVHSGYAGFSLFSGGRALRGTGGNILMAFSVDGK\n",
            "Generated Protein: MTGVPRAVARAACAACEPATAERKRAPTTGGAVAACSNADTTADADAESNAEADFSADADADGGAVADGGAVADAEADAEADADLFSDAGADADAEGMTGTTADMTGADADAGAGAGAGSNAGADAARAGTDPATGAEATGRKRRKRVDAGAENEDFADVPATGAGRAGAGRKRADRKRRKRRKRADRKRAPTTADAGVDAERDAERDVDADVSADADTRTTADADAEADAETTADAD\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   1%|          | 27/3111 [00:24<44:44,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MANAYERGPKPTFALLAARSGPFSVSTLRASGFGVDGFGGGTIYYPRENGTFGAVAISPGYTATQASVAWLGPRIASHGFVVITIDTNTLLDQPDSRARQLNAALDYLRNDASSAVRSRIDSSRLAVMGHSMGGGGTLELATQRPDLKAAIPLTPWHLNKAWSSVRVPTLIIGGEKDTIAPVDTHARPFYNSLPTSISKAYLELRGATHFAPNQPNTIIGKYSVSWLKRFVDNDTRYAQFLCPGPRDGGGGLVERYRSTCPK\n",
            "Generated Protein: MTGTTNSAASTRAASATASSAEAASAQAAAQAASDPDPATGASSAISAVAISAISAISAISTTAWLTARAISAISAISAISAISADAEAESNFSDAWLTSSAISASSADADRARATHSAVASSNSAGKAATTKAAASSKAAAARMGGKAAKAAKVFKAAKAAKAAHSEKAAKAANKSNKSAEGAASAS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   1%|          | 28/3111 [00:25<44:33,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MSIVDPWQDATAQAELVRSGEISATELLEATIARVQAVNPEINAVIIPLFEKARRRSELASGPFAGVPYLLKDLYVVMQGDIVTSGFKGMREIGYRADHDAYFVQRMRAAGFVLLGKTNTPEFGMQTTTEPYAYGATRNPWNLKRSAGGSSGGSGAAVAAGLSPVAHGNDAAGSVRIPASVCGVVGLKPTRGRISPGPLVTDSENVAGFATEGLLARSVRDIAALLDVVQGARPGDTFVAPAALRPYAQAISEQPGALRVGVLTENPVGDEALDPEAEAAADAAAAALAALGHDVTEAYPEALGDRSFLDNYSTIVAVAIAREIERLGELLGRPLTEDDVEITSWAMVKRADQVTGRAFAAAVDELRSYAGKVARWFEAGLDLLMTPVMTRPTPEIGELMLAKGTDLEGRKSALISGSWGMLAFTVPFNVTGQPAISLPIGQSSDGMPIGVQIVAAYGREDLLLQVAAQLEGAQPWAARRPQLLNPSRKEPAA\n",
            "Generated Protein: MSARSTTGGAVVSGGAVATAGAGHNRGGPGHNRGGAVGGAVGGAVGGAVGGAVGGAVSTEEGHNRGGAVHNRARLGGAVAEAGGGAVGGAVGGAVAGSGGAVGGAVAEAERDPGGAVGGAVAEGARSVSATATIDPEPAGSGGSAGSSGGAVAGSTDPAARYSETDPSSATGGSATGAKAWAWGGAVAYGVDARSARSARSAEARSAEAGTDVLRGSRKRARSEPAEAGATITASVSVGRMVSTRVGRMAARATATAS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   1%|          | 29/3111 [00:26<44:40,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MNKSILKKLMFGLSLLLVSLNALSVTPYPTPTPDPIPDPTPTPDSCDFTRGPNPTPSSLTASDGPYSVATTSVASSVSGFGGGTLYYPTNTTGTFGAIAIVPGFLASESSISFWGPKLASHGFVVITINTNSLFDQPASRASQLGRALDYVINQSNNSSSPISGKVDTTRLGVVGWSMGGGGALQVASGDNLSAAIPIAPWNSGGNRFDQISTPTLVIACENDTVASVNSHAIPFYNRIPSTTDKAYLEINGGGHFCATDGGSQGGSLGKAGVSWMKRFLDDDLRYDQFFCGPDEAANTSNSEYRDTCNY\n",
            "Generated Protein: SPARSNSNSNSNSTRCEDVSNSSDSDFGGGSEPNETRSTRSNSAISSDSDFGGGGGSRGSVSFGGGVSNSRDAISAISNENSATGFSDAKAPDNSNSRTRARARSMGGGGSMGGMGGGGSGGSAAASMGGMGGGGSGGSVSWSMGGMGGGGTLMGGMGGKVFVSVSMGGVSGGERTRDARSPNSNNSNSRKRRGSNSTRTR\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   1%|          | 30/3111 [00:27<44:35,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MNARSTGQHPQRAPGAAAGEPTLDNWQEAPHNRWAFARLGELLPTAAVSRRDPATPAEPVVRVDALAERLPDLEKRLEETGTDALLVLRGTEVVAEVYRNGFAPDTRHLLMSVSKSLAGLVVGALVDEGRIDPARPVTEYVPELAGSAYDGASVQQLLDMQISIDYSEDYVDPASEVHVFGRSAGWRPRRPGDPADVYEFLTTLRGDGSTGEFAYCSANTDVLAWVVERVTGLRYVEALSTLLWAPLGAERDATITVDTTGFGRADGGVSATARDLARFGQMMLDGGVGPGGRVVSEDWVRDVLAGGSPEAFRASGFTNTFPDGSYTAQWWITGAERGAVSGAGVHGQNLWLDPATDSVIVKLSSWPQPDTEGNHLLTPGILLDMSRALDAV\n",
            "Generated Protein: MSARSFSAARDPAALLFAREPEPPAAHNRHNRSEPHNRSEPGGAVRDPFPGFPGFPGSLHNRVGPSHNRHLHIPHIPHIPGGAVRLFGGGAVGGAVNEAGSFSAAGLEAGGAGGTVPATGRTGARSIDPSSIDPATGDGPPGGFGRYTRAPDPGTSSYSEYSEYSERDPRDPCTTDPAWVCGVCGHSETRGHLARSSEPARSARSARSAWTDVLVFGLLDTDVLRGSTDVLTVPPSATATITNTTATITATITATITATITATITATITNVRAKTRTRDLPVGRMTDPTDPTRAWRDPHLDLPFPGPEGSDLPDLPPEGSPEGSRAFPEGSPEGSALGRAFRAFPEGSTPSSSS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   1%|          | 31/3111 [00:28<44:33,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MKKISFKKRVLTILAALALVIGAFAFIQPKEVKAANHNPVVMVHGYGGSSYNFNSIKSYLVGQGWDRNQLYAIDFGDRTGNNRNNGPSLSKFVQDVLDKTGAKKVDIVAHSMGGLNTLYYIKNLGGGGKIENVVTIGGANFLMSSRAPNGMPPNGEIHYTSVYSSADLIVVPSLSRLSGAKNVEISGVGHIGLLTSSTVKGYILEFLNGRGYNTN\n",
            "Generated Protein: MVRVPFKKFKKNLFLPNVFGVFGFAFVFGINFRDFVHGFVHGFVHGFVHGFVHGFRDFRDFRDFRDRNQLFRDINFQGYNRNNRNVLGVNFRDFRDVPWTNQVNVFGYSQGVNTNAKFTGVNFTGVFGVFGVFGVFGNVDVFGVFGYTSAMKNNVKVYSSYGSNVDVFGNRVCYGSVFGASDFYSVFGFNGIGSQVFGIGSQHL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   1%|          | 32/3111 [00:28<44:20,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MTSLRLLGAASAAAVALTLAGGAVASAGVQPNIVGGSTASTVSWAAQVYVTTPGSDGQGFGCSGSLIASDWVLTAHHCLDGPGSGMYVRVGSNTLTSGTKIAVDKEYESPNADIALLHLASAASATPIRLGSSDPATGSTNTIYGWGRTTLTGPTATSLKTANVRVTGRSTDAYGGPVIQTVPINGGAWSGDSGGPLVANGVQVGVASTVDNQSGSNTPGTNNYASVAAYRSWIRTVSGV\n",
            "Generated Protein: MNTTPRVANWGLLPLFLHLPQFSVNFSVNPQPGNSQVYSRVANQVYSRVANNGEIQVYSFGRDDGNGQVYSDGNGVNSNQVYSNVWCTKHCGDGSGFGATTYKSGQVYSKSGQVYSWGSVSSQVYSQVYSQVYSHLKTQRATQPDSASPIMGCVYAVKGQIYGQIYGQIYGQIYGPGTRPGTPGTPGTRQIYGDGNGDGNGDGNGQGTLRGSDQVYSQVYSRVNGPGSKPQNLFLHLKTNSSGQVYSNLFLFSVNWGQVYSQVYSAFFSQIYGWSNVVAVDNWSNVNTTTAWYGSDSDNGTS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   1%|          | 33/3111 [00:29<44:17,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MKRINFKKRLLAILVALLLVIGSFAFIQPKEVKAAEHNPVVMVHGLGGSSYNFDSIKSYLVGQGWDRNQLYAIDFNDTTGNNRNNAPRLSSFVQDVLDKTGAKKVDIVAHSMGGANTLYYIKNLGGADKVENVVTIGSANGGSSSFGLPGTDPNPKIDYTSVYSSADLIVVNSLGRLSGAKNVLIGGVGHIGLLTSSQVLGYILEGLNNGGQLTN\n",
            "Generated Protein: MVRKEFLFKKASLLAALLIGPCFSVNDLETPTPCPKTRGNPNPQDSTGASVGAVKGYLVGITGFRDPSTGNIKSKERSVSNALDGSGNVLGTYGQGGNQNQNQDVLAKNQAKNQKEFLAAVVMKVAVKGAVKGAVKGAAVVAAVVAAVVVIFGAAVVAAVVNQNVDVYSSNVKNIKSDGDNQGTLDGDNDGDNHIGQQDTRGHIGDGDNPQASDFAAVVQGASQGASTMGTMG\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   1%|          | 34/3111 [00:30<44:06,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MLLVTRYRCTPIRVRNRGMHAFDFVVVGAGSAGCTVASRLSENGKYQVALLEAGGSNNNPLISIPFGFAFILPKGPHDWSFETVPQKGLNGRRGYQPRGKVLGGSSSINAMVYIRGAKEDYDHWAALGNEGWSYEAVLPFFKKSENHVKPANEYHANGGPLTISPPRSPNPLNDMFIKAGEDAGLPYNEDFNGETQEGIGPYELTQKRGKRCSTALAYVTPAEKRKNLTIFSDAMVEKVLVENGQATGVMVKLNGQTQTIKARREVILSAGAFQSPQLLLLSGIGAKDHLAPLKIKVVHELPGVGSNLQDHVDFELLYQSDKEGVLGANARSFFEVAWNAFKYFAKRRGILTTNFNESGGFYRTNPDERYPDIQLHFAPTLVDEHGLKRKGRHGFSCHVCVLRPKSRGNLRLASANPAAPPLIDPAFLKDERDVATLLAGVKRAQQILSAPAFDSIAGKPISATASNSEDELIEAIRNRADTIYHPVGTCKMGPDSDPMAVVDSRLRVRGIRNLRVIDASIMPSIVSGNTNAPTIMIGEKGAQMILDEAESAR\n",
            "Generated Protein: MTGVPAYAALLAYAALLEPWVGAPWPQTGVDTPLNLTGYVPAYAYPWTPAPTPAPWTPAPAYFPSYAYWKSWKSAYVDAYAYSKKSTDTVPTPLVGWIHIDPIDPAYWAYAYNPYVPKKSEVDAWMGPCTVAYVDAWWAWVDWWVDWWTGSEAYYVPYVPPQAYAYAWAYAEKRAEKRAYAYAYVAEKRAVLAYVDAYRKRVDPAYVDLLLLAWVMAWAYAWAYWAYWAYATLAYAYTPLAYWIGGVALDWAWWWWWAYIGTPLAYIDPMGTPPDAYSYTPLVGWAYATLAYVGAYAYAYVGSYSYMGAYAYAYVDIGAFLWTVPSLPIDPWLLLIDPAYAYSYAYAYDVLIDPAYVGVGWIDPVGAWAYIDPVGSYAWAWAYMGAYDILWAYWAYVDSYWSYAWAYAWVDSY\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   1%|          | 35/3111 [00:31<44:30,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MFLLAFTLLVPTATASASEKNIQPNINTEPIQNSEKNEYPIILVHGFGGFGRDELGGVIKYWGGIKDIEKKLEEKGYKVYTAAVGPVSSNWDRAVELYYQIKGGTVDYGEAHAKKFGHSRYGRTYPGFYPEWGEINPTTGKPNKVHLIGHSMGGQTIRMLAQLLYEGDPEEQKASGGDISPLLKGGKKPWIHSVTSIASPHNGSTLADNVNDVIPIIQELVIGAAIFAGNIDQNLYDFKLDHWGIKKQPGESFPDYIDRVRNSPLWKTKDTAAWDLTIEGAEELNRWVKAQPDIYYFSVSGTASRRSLITGHYVPDLFMNPFLHPTSYLIGSYTVKKSNFVLDKTWWENDGLVSVKSMKFPNIGSEDVIVEYDATPRKGVWNHLGTMENFDHMDFIGFGVRDVTGFYEDVARFLYSLPE\n",
            "Generated Protein: MSRSLLRVQDVLAALLATLCEDELENPIIGGIIGGAPRVANSLFKEFLRFPFPKISGSLIGSGVGPSVIASTIAALVNSNNSLGNALDVLITIDDVLDVLDVLSTTGDVLDVLIVDVLANLIGIEIGIEIVIVASPIATLATLAVNSIVDVLDVLKSGLGGNSGGNSPRSTDPDVLDVLRIKNNRIKIVIVIVIVIVSYSYPQPLLVGSTIIGGIVIVIIAVIPSGVDILPVIVPSTGTVGDVLDVLDVLDVLDVLSYDVL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   1%|          | 36/3111 [00:32<44:33,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MSAVDLWQDATAQAELVRSGEISATELLEATIARVEAVNPELNAVIIPLYEKARRESELASGPFAGVPMLLKDLTVVSQGDVTTSSIPAMLESGYRADHDAYYVQRMRAAGFVLLGKTNTPEFGFTATTEPSAWGATRNPWNLGRSPGGSSGGSGAAVAAALSPVAHGNDAGGSVRIPASCCGVVGLKPTRGRISTGPYVGDSDNVAGAAHEGVLARSVRDIAALLDVVQGPRPGDAYGAPPASRPYAQSISENPGSLRVGVLTHSPVGDFPLDPECEAAARVAAAALSALGHDVEDAYPEALGDRSFLVAYSTIAMVAIAAEIERLGELIGRPLTEDDVEPTTWAMSKRASQVTGRDFVAAVDELRYYARKVARWFEAGLDLLISPTLTRPTPEIGELDEAKGGDLEGDMSAFISGSLQHLAFTVPFNVSGQPAISLPTGLSSDGMPIGVQFVAAYGREDLLLQVAAQLEQALPWAHRRPQLLEASLEIPAA\n",
            "Generated Protein: MNRLTDRLTDALDAVRLTDIAVLLTTLRLAGLLEATLLEATAGPPAPALDAVRLSERLSEGGGEGGGEIDPATPWRHIPHIPHIPHIPRLEERLEEHIPRLEEHIPHIPDTELYLLLAGGDTELGLEHLLIGIEIGIEIGIEIDPIDPEGRIDPIDPRLTDEYAVVPELEYGGSGGGSGQIAALRLTDRLTDRLTDVDPVDPGGSGRLTDWRPIDPWRPIKAGRISRISIVENPVGRADGILAVNPVGRSANIVETDVLIVEIVEIVEIVEIVEIVEIVEIVEVEALVEALIGELVTEAGRLQEQATGIGELHIPRLTDFLVGRMFLVGRMIGELRLSEVAPIGELDPAVLEHIPIGELNLQDPGSSPGSSVALDIGELVALDSYWIGGWIGGIGELVMIGELAVLEAVLEIGIEAVLEIGELKVARIGELIGELPDLLALDAVIGELALDAVALDAVIGELIGELIGELIGELIGELIGELALDAVIGELIGELALDAVIGELSLIGELIGELIDPIGELIDPIDPSLPIDPEYIGELIDPIGELALDAVPWIDPIGELIDPIGELPWIGELIGEL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   1%|          | 37/3111 [00:33<44:39,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MRKLKLLLMVAMSMVFIFTLPGMGQSLKASAATERLPIVFVHGLLGSGSNFALISRYLRTEGWSSNELFAIDLPSKAGNQLLNSAAISRFVDDVLRQTGASKVHIVAHSMGGADSLYYYLNQGGIDKVDKYITLGTANRLITSRAPDGIRVTSIYSTSDTIVSPALSRLDGANNISVPGVTHIGLLYNSRTLALIKAALNE\n",
            "Generated Protein: MNKLKFKKMQTSSLPGSSESGECSWLLIQPGGGKLAGIIGGMNVNSNKSGSLSLPGIKKVISSVIASVIASNNSVNSNVNSNFPNNNNNNKVLGKSGKSGSTTGSTTGAKKKIEGLENNGMKGLNNAKKIKNLAKKRLLIPGQPSGPSRAPKKSEDSYFFYFFNNNNMGGWGNNNNNNNNNNGGDSGGNSLLGGPCGCGILESGFGNRFDNGTSNNMNILEGGGRKRMQTSQKNWSNNNIKKNNPMMNNNNIKKIKKIKKFLNNLLLLCGCGNNSLPDNNNGTSNNENGTSVALDNNPHMASSSPGGGNSLGNNNNKTWWENNNNNNNNNN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   1%|          | 38/3111 [00:34<44:22,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MKRRLIAASIAALAISATAVALPTGVAQAAPCSDVDVSFARGTGELPGLGGIGTPFVNSLKSQLGGRSVSTYAVNYAADFTQDSAGPGSRDTVAHLNSVAASCPSTKFVIGGYSQGATVVDNAVGLRTPSSFTGSVIPAAYADRIAAVVVFGNPFGLTGRKITTLSSTYGSRTRSFCNFGDPVCQIGGFNIFAHLTYFFNGSTTQGASFAAAKVRS\n",
            "Generated Protein: MKKFKKFKKMKKLLALGLALPVIGSELEKENPNPNPSNNPGGSENPIKSIKSIKSRNRSVSRNQLRNQLDFQNSNNMNRNQGNDRLSRLSMKKMKKMKKAKKAKQLQLYYYYRLLYYDPAKKDPILERNVIRNKIAGTGRNKIAGLLMKKILENNAKAKAKSLDPAPLLLLLLILELLNPILE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   1%|▏         | 39/3111 [00:34<44:12,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: YDVRGGDAYYINNSPRCSIGFSVNGGFLTAGHCGPGTVTGSNSVAQGSFARSSFPGNDYGWVRVNSNWVPRGWVANGTRVSGSSEAATGASICKSGSTTGWTCGTVQAKNQTVRYAEGTVYGMTRTNARSEPGDSGGSFISGNTAQGMLSGGNSTTTYFFPVRPALSATGTSLVTG\n",
            "Generated Protein: YDVRARTPGLPRVQVSMNSLPGNSPGGLPGWQEFWQQPAKVQPTVIASIIGGQGPSSGPSLGLPGMNKEVIASVNSNVNSNPSTIAALNSPGSSEASICNSPGASICASICRIAHKSGGLAASMGGSMGGSMGGSMGGHLASNNGHLASFWQFWQDSKTKDDSCGFWQGGNSWGSLYFFMGGYFFYFFCGGLSSNKQNGSNGSNGSHIGDSGGGGPIIGGSGFGGGPSGFGNGTSPGSFLIETNNASPYASKIPGPHNGSNGSFWQMQTSKNQPGWGNGPHPHSSP\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   1%|▏         | 40/3111 [00:35<43:58,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: SPVDLVKRQLTSNDELRDGPCKPITFIFARASTEPGNLGISTGPAVCNRLKSARSGDVACQGVGPRYTADLASNALPEGTSQAAIAEAQRLFEQAASKCPDTQIVAGGYSQGTAVMNGAIKDLSADVQDKIKGVVLFGYTRNAQDRGQIANFPKDKVKVYCAVGDLVCAGTLIVLPPHFSYLSDTGDASDFLLSQLG\n",
            "Generated Protein: MKFVSTERRSTSHPTASGLSSTSHPVSTETVALFIFVSTEPSAPVSTETSHPCNTASASVSTEVSTETIYVSTEVSTERDVSTERDTIYRDRDTGVSTEVSTEDSRGSKTKQPAAHLASANTRHLASFWQTILDTIDSDSQIANKIAGKIAGAIRDKIAGKTANKIAGGLSPEEANTRTLMGGYKNFPCNAPPSDPVANAPVSTEFLIEVSTEQLTNFLIEFLIEFLIEPAPEFLIEPSPSPSPSVSTEEDKRPECN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   1%|▏         | 41/3111 [00:36<43:51,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MQALQQQTIDLLRTHQDTLVAQWLDQLAGSGQGQGGRLSHGELDLQAREFIRLFQTAVSTNGTGVAGQEWQDTRQSLEQLSRDRVLQGFSPSETASFIFSLKRPLFELVQQAFADDPKAVGDAMSALSELLDGLGLHVVEVYQTTREDVIQRQQEEMLELSTPVVKLWEGVLALPMIGTLDSQRTQVVMESLLQRIVDTGSEIAIIDITGVPTVDTLVAQHLLKTITAVRLMGAEAIISGVRPQIAQTIVHLGIDLQGIVTKANLADALALALKRTGQTVTKAGR\n",
            "Generated Protein: MNWKHGLSSWKHGLSSPTWKHFAFYQPTPSPKAPRGAPRAGLWKHTGWKHAFDSCAAARREVISSWKHVISSVIASHIPQLPNCVQQLPNKGPADKSGLSGGSEYQPRIAHTKGLAASKNGYQPWKHTKFWQGGADFWQNGVGTKPENGVGWKHWKHVFNLWKHWKHGLSPYFFGLSSWKHGLSSWKHWKHWKHGLPYGLPYWKHGLPYGLPYGLPYGLPYFTTSWKHWKHWKHWKHWRHWKHWKHWKHATRWKHQPAPDPEWKHWKHAAASSWKHEEWKHWKHWKHWKHARREARREQLPNWKHWKHWKHEECGGDDEFNNTVHFAVDTLQLPNWKHDEIWKHWKHWKHWKHRRGWKHWKHYTTPEANTKWKHWKHANVNVQPTWKHWKHPDFPDFPDFSESGPDFPDFPDFGD\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   1%|▏         | 42/3111 [00:37<43:48,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MNTTPVVALPLALGGIAVEPAPRLAGPPVFGGPMPDAFDLAPVESTVREVLRFDLPGVSIGQAQYVEGPTGATVIHLPAGARPAVDIRGGAVSLSGGNDFNHAIVLAGGASYGLEAGAGVQGALYERGGGRTGFVKRPLVSQAVIFDFSARGTALYPDTALGRAALEAAVPGAFPKGRVGAGLGASAGKVFGLRTSFTGIGAAYRRLGDVRIAAVVVVNPVGVIMDRAGDVVRGIYDARTGVRRAPVYDYQEAFAELVPAPAEAGNTTIGAIVTNVRMSPVELRQFAKQVHSSMARGIRPFHTMMDGDTLFAVSTDEIDLPTTPGSSTGRLSVNATALGAIASELMWDAVLEATA\n",
            "Generated Protein: YDVRPETEPTAAIAVPTTGFAFWQEARRGAPWAFEPTGRAGLDPERRDPAVGLSGGAAPYGLAPTESEVFRGAGARAGARTGGLSGGGLSGGFEYRADYRADYRADRHRHYGLRHNTPENTPESEEGREGREGRVTAVAVTVQQTEYGLVTTGAVAALEPVGAVRSPVGPVGPVGVVGLVVGLVVGLVVGLVFDYPEDPESYPVGTVVTGEFTGEFDIAADTLDIAADIAADIAAIYRRAAIFAAIFVAADTLPEDTLDTL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   1%|▏         | 43/3111 [00:38<43:53,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MKVSSLALAVLSAASLGRAAPTPESAEAAELEARQTSSACPQYVLINTRGTGEPQGVSAGFRTMNSQILAAMSGGTAYNTVYPANLSQNSAAGTADIINRVNSDLAANPNQCYILQGYSQGAAATVNALQQLTTSGAAFNAVKGVFLIGNPYHKSGLACNVDSNGGSTTRNVNGLSQATQGSVPSQWVSKTLDVCAYGDGVCDTAGGTGINANHLSYPSDQFVQTMGANFAVNKLGGSA\n",
            "Generated Protein: MSVAGKAGYAVSVSSSMGGSMGGSMGGSMGG\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   1%|▏         | 44/3111 [00:39<43:49,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MSKVDLWQDATAQAELVRSGEISRTELLEATIAHVQAVNPEINAVIIPLFEKARRESELASGPFAGVPYLLKDLTVVSQGDINTSSIKGMKESGYRADHDAYFVQRMRAAGFVLLGKVNTPEMGTQVTTEPEAWGATRNPWNLGRSVGGSSGGSGAAVAAALSPVAHGNDAAGSVRIPASVCGVVGLKPTRGRISPGPLVTDSDNVAGAAHEGLFARSVRDIAALLDVVSGHRPGDTFCAPTASRPYAQGISENPGSLRVGVLTHNPVGDFALDPECAAAARGAAAALAALGHDVNDAYPEALGDRSFLKDYLTICDVAIAREIERNGELIGRPLTEDDVEWTSWEMVKRADQVTGRAFAACVDELRYYAGKVERWWEAGWDLLILPTVTRQTPEIGELMLAKGTDLEGRHTALISGSLRMLAFTVPFNVSGQPAISLPIGMSSDGMPIGVQIVAAYGREDLLLQVAAQLEGALPWVARRPQLLNPSRKIPAA\n",
            "Generated Protein: MSVRISARLLGIAVIGFDAAARVTVIVIVITVFEQGELAVPVVAATEYVIYIGAAVLRGTEVRVIVARVARYVARTVQAVLLGVVGVVGVVGVVGYYYTIFDFHIGAVVFRGAVVVGAVAVTVVTVVYTVVTVVYIGYTVVYTESYYAATVVVRAATVVVAAELVEALAAGIGY\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   1%|▏         | 45/3111 [00:40<44:08,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MPFLCSLPRRLAAAALLASATLVPLSAAAQTNPYQRGPDPTVRSLESSRGPFRYASTNVRSGSGYGGGTIYYPTDVSGSVGAVAVVPGYLARQSSISWWGPRLASHGFVVITLDTNSTLDQPASRSAQLNAALRQVVALNENRSSPIYGKVDPNRLAVMGWSMGGGGTLIAARDNPSLKAAVPFAPWNNTANFSGVQVPTLVIACENDTVAPPSRHALSFYNSLSSSTAKAYVEINNGSHYCAWTGNRNQALIAKYGVAWLKRFVDGDTRYSQFLCGAPGQADPRSSRLSEYRSSCPR\n",
            "Generated Protein: SPLLGTILLGISIAVVIVIVIVIVIVITIYTIYVIVIVIVIAAVIAATIRVIVIVIVITIYTIYYTTTGTITTVYLSLLGLLGFVVASHGTVRLLGASHGTYDYALQALQVIVIVIVIVISPVIVITVRVIYTVIVVGTIALQAAALQIGTVVITITVQLGVANLLGIGAA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   1%|▏         | 46/3111 [00:40<44:16,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MDGVLWRVRTACLRAALLALAAVALVAASPSVEAQSNPYQRGPAPTRSNLTADGPFSVATATVSGLSVSGFGGGVIYYPTGTSGTFGGIAISPGYTADQSSMAWLGRKLASHGFVVLVINTNSRFDYPDARASQLSAALNYLRTSSPSAVRARLDANRLAVAGHSMGGGGTLRAAEQNPSLKAAVPLTPWHTDSTINVSVPVLIMGAQGDTVAPVSSHAIPFYQALPSSTPKAYRELDNASHFVPTSNNAAIATYVLSWMKLFVDNDRRYRQFLCNVNNPALSDFRYNNRLCQ\n",
            "Generated Protein: MSSLSPTTAALALLLLLLLITCSFTQSGTAQTAQPTTIYSLSQRGPNPQRGQPDSQPTINNLGYTYYPVSGVSGQGVSGYTIQGTVVAQVAASYLSYLSASHGVSGASHGTVRFVVFVVVFVFQLSTAAALQALQRVDIGRVDPIRGMGGSLSALQVAGSNLQNIVVALQALQALQALQALQCNALQFTALQQLGQADQADIALTVCSAEADIGAAHFHFPNP\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   2%|▏         | 47/3111 [00:41<44:14,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MKLVCLYRCTPILVRNRGMDEFDFVVVGAGSAGCVVASRLSENGKFQVALLEAGGSENNPLISIPGGFFFTVTKGPHNWSFETVPQEGLNGRRLYQPRGKVLGGSSSINAMVYIRGNKEDYEHWAALGNEGWSYEDVLPFFKKAENRNWGANEYHARGGPLTVSEPRYVNPLNDMFIKAGMDAELPYNEDFNGETQEGVGYYELTQDRGKRISTARAYITPARKRKNLTIFTDAFVEKVLIENGQATGVMVKENGNLYLIKATREVILSAGAIQSPQLLLLSGIGPKDDLASLGIPVVHELPGVGENLRDHVDVCLMYQSESEHVLGVNARSLFKLAWNGFKYFLRRRGILTTNFNESGAFYKTNPDERSPDIQLHFAATHLDNNGLPRSGRAGFSVHVCVLRPKSRGTLTLADANPATPPLIDPGFLKDERDVATLLAGVKRAQQILQAPAFDEIRGKPVGATASNNDDELLEWIRNRADTIYHPVGTCKMGPDSDPMAVVDSRLRVRGIKNLRVIDASIMPSIVSGNTNAPTIMIGEKGAAMILDEAESYA\n",
            "Generated Protein: MSASFLDWFSLIAVIAVFAFVRASFLAGSGVTAGKAPQGVAQNLGQGKARQPATASQGPVVPVVFAFKAGHGKAGHGQGQGAIALQGVAQVAQASFLIAQINAMINAMVRVRLSVRLSAYDAALGMVAMAALGHWRAPVRFFKKSEKKSEAISLYTSAALEKARPMVRKARVRTAAQGIASFLQEGPMELVFNLQEGQEGFAGQEGVAQQEGQADQEGADAIADAIADAIADAIVAQVEALQGVEALELAEADKSAQELKQLQESGKVAQPMQTMARGVDSAALGDEQGARAIELELDEQGMARGASFLASFLASFLYMATASQPRDYMRRGFAGYTTDEQGPKDSFAGFAGAVSGVSLSVSLSVSLSFAGVSLSRYIQLATASATASATATIQLQSDYTIQLADDHLDATASRDYTYTYTVSLSVSGFAGQPFAGQPFAGFAGFAGATASFAGFAGDEQGFAGPAVFAGFAG\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   2%|▏         | 48/3111 [00:42<44:31,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MRIRRSAGHGARASGYRAIGVAVTALAVLVGAVGGVAGAEPSTAQDNPYERGPDPTEDSIEAERGPFSVATERVSSGASGFGGGTIYYPTETDEGTFGAVAVAPGFTASQDSMSWYGPRVASQGFIVITIDTNTRLDQPGQRGRQLLAALDYLVERSDDPVRGRLDPNRLAVMGHSMGGGGSLEATLGRPSLKAAIPLTPWNLDKTWGQVQVPTMIIGAERDTIASVRTHAQPFYESLPSSLPKAYLELNGATHFAPNWPNTTIAKYSISWLKRFVDEDTRYSQFLCPDPTDSAIEEYRSTCPY\n",
            "Generated Protein: MANRLDPTGARRVRRTESSREASREASREASAVGGAVGGAGFERAGLRAGLRAGLRAGLELPELPARGSDSASARGSRAFRVRVSSRVSSSSFAVLLRVSSTSEGRAGLRAGLAYRRVSSAALDSSFADYRHRVSSRVSSYSQGRVASILARILARAALDIAGGDQPGRVSSYSQGAALDPDLPDLRLDPRLDPALAQRLDPPDLRLDPRIPRIPRVRLDPPDLVRAPRPSLNPLARAISSFGGFVASARAIASHLQADARAIGRAERGASVRKPRLYSIKRFGRYSIARAIARAIARAIDGSKSAQQFLDTTLVLARAIARAIARAIGRAHEEHLDARAIARAIARAIARAIARAI\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   2%|▏         | 49/3111 [00:43<44:20,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MANPYERGPSPTDAEESARSGPFSVSSERTSRFGADGFGGGTIYYPRGNGTYGAVAISPGYTGTQTSMAWLGERIASHGFVVITIDTNTRLDQPDSRARQLSAALDYLKNDADSAVRSRIDVSRLAVMGHSMGGGGTLELASDRPDLKAAIPLTPWHLNKNWSSVRVPTLIIGAEQDTIAPVNTHARPFYNSLPTSISKAYVELRGATHFAPNAPNDIIGKYSVAWLKRFVDNDTRYAQFLCPGPRDGTFGEVEDYRSTCPL\n",
            "Generated Protein: MRLSYLTKTESSTESSTESSTESSAERGPCFSVSPCTESSGGFGGGYPCNYPCNCNFTAPARGSTERYYYPNDTADLHGYPHGPGITIDITIDAYRAYRQLNGRYSQGGRNHLYSQGITIDITIDTESSQLNYLTQYSQGQLNGGTLNYLCNQLNPDLIPLGGGGTLPDLVRVPVRVPCNGGTLVRVPIPLIPLIPLIPLQLNTESSCNYPVPVLHFTPIPLHFTPYSIYSINRIYSIYSIYSIYSIHFNDIENDIEHFKLQQKLQQKLQQGGGKHFYTQGRGKTESSCNRYRDGGKCNRDYRSNHL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   2%|▏         | 50/3111 [00:44<44:07,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MAAPYERGPEPTTALLDADSGPFEVSVERASRSGADGFGGGTIYYPTENGTFGAVAISPGYTGTQASVAWLGPRIASHGFVVITIDTNSVLDQPDSRARQLNAALDYMINDASSAVRSRIDSSRLAVMGHSMGGGGTLRAASDRPDLKAAIPLTPWNLNKNWSSVRVPTLIIGAESDTIAPVETHARPFYNSLPPSTSKAYLELRGATHFAPTKPNAIIGKYSVAWLKRFVDNDTRYGQFLCPGPRTGLFGNVEEYRSNCPF\n",
            "Generated Protein: MANPVDLTESSNDELNDELNDELNDELPGFSGGPGTTYPYPRGPYPYPRYPFPGRGPRGPKNGNDYPYYPYPITIDYPPGITIDAYRQLNPGNGNYLHGNYLHGITIDITIDPGHSYLTQGGYLTQNYLFSIPLIPLIPLIPLIPLNDNKNHSGGTLVRVPNDGGTLIPLIPLIPLIPLNDIPLIPLFLNSLHFNDNDNDHFNDRDARPNDRDNDHFNDRYKDEHFNDNDNDNDKDEYPFLFLNDFLRDFLNDFLFLPFYRSYPRDPFPFPFFLFLFL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   2%|▏         | 51/3111 [00:45<43:59,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MKSLAWGGAVFSAATLIALGSVVHASGAVAEDAPQSVEAVPAAQLDGETLYKARCAACHDNPEGRTPSREVLAKRPASKILARMRTGAMRPMAEGLTDEEMTAIARYVGGADAKTDDGADLDRILGNSVEGTPLEAPQCVSAPIVVDLSAANGWNGWSYDADNGRFQAKPALAVADVPKLKLKWAFQYPGGKNGQATVIGDRVFVTSTSGAVYALNAKTGCVYWRHKAEGATRTSPVAAALPKGRPAKTSLFFSNFTKAAVALDAETGKQLWKTVVDDHPTTRNTGSPTYFDGKLYVPISSQEWAFAAIPDYECCKFRGGLVALDAATGKILWKRYTTEQEPRPEKLNKAGTQMWGPSGAAIWNTPTVDEARRLIYVGTSNSYTDVPGDNSDSVMAIDADTGAVRWTRQLLADDVYITGCWATPKEHANCPAPGGPDFDIGAAPILRKGADGKELLLVGQKSGMIYALDPANKGAKIWERRLSRGGAIGGIGFGIAADDQKVYAGVSDIASQAKGRGKPGLHALDIRTGEVAWNVQSAPDTKCRWNNDWCHGAFSQAPSVIPGAVFAGSVDGHFRAFDTATGKIIWDVDTGTKAVTTLSGAKAFGGAMDGAGPTIAGGMVYVSSGYAGFSTESGGRDAGGTDGNILWAFSVDGK\n",
            "Generated Protein: MFKVLKLFFIDLFFTLDSFEFEKLTGSKAPRLSEFEFETDTDKARFSFEFEFEKDLMVMNGRYIDLNEIDLFEFEFEIRVRFEFEFEYMNWFEIDLFEFEKLIDLKLIYDNGNPNDNVVFFDNFFAVAGYPDKVKNGKVKGGPMKVLTDTDKVLTLDSMFNGMFMFFEFFNGETMFFEELATTVVFFKPKLIDLNDDGSNQLNQLFLFSKLYMKQLKVLIDLKQLFLKDEKLFLGGIRPKLGGAELGIDLTDTDAGGSIDLIDLIDLAVLGAVLGAVLGAVLGAVLGFLFFFLAVLGAVSGAVSGRYFETVNIDLACIDLFETVNFENPNDFECMAVLGVLRPMVRLSFNVLRPFSRWVLRPFSAVLGYMFNVLRPFNFDFEFEFLKLFEKDEELNAPPGGGKLIDLVLRPVLRPDGSAVLGGGKVLQKSGELAGVSPMPDKVLKPVLRPVLRPIVSGAVSGIVSGAVLGAVSGELFGIVSGPGFNDTAFLTLSGGGSMGGSMTKDGTKDGDTAVSGMVYFNMVYVNSGMVYVNSGVNSGVNSGDGSTKDGVNSGKTLFNTKDGVMDG\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   2%|▏         | 52/3111 [00:46<44:28,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MLVNNLAVAVLSAAALARAAPTPESAEAHELEARATSSACPQYVIINTRGTGEPQGQSAGFRTMNSQVTAALSGGTTYNTVYTADFSQNSAAGTADIISRINSALAANPNQCYILQGYSQGAAATVDALQQLGTSSAAFNAVKGVFLIGNPDHKSGLACNVDSNGGTTTRNVNGLSAALNGSVPSGWVSKTLDVCAQGDGVCDTAGGAGINAQHLAYPSDAGVQTMGAKFAVGKLGASA\n",
            "Generated Protein: MRTTTTYINMVFSGEVFIFPESGGFLPPARRTPTGSSNRLSEPVSSARYPNGRYLRYLATSGATVFRGNQLTLDETLDEPEGVRVGVRVGASICPVSSASICADGVAASTVDALAQALAQTVDVRLSPSPSPSPSPSPSPSPSATATPGDSPGDSIYDIYDFIAGNPNDARYPARYPYFFARYPNGATKTLTTKTLAGNDISATVANGATTYTYATATTYPSDTPYASARYPASPSDANQLDGSVNSNQLNQLNQLNQLNADNADYGSPVELVRLSYGSPVELYDLYDRRYDRRVRPNVVVRPTYPSDYDGTVNNHLVMLETTAVLGMGLGTSVRPTSRYTVNMGLGTVNTVNTVNTVNTVNTVNTVNTVNTVNTVN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   2%|▏         | 53/3111 [00:47<44:15,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MQFKSTFAALVLAAAGLVQAAPLEERAGCSSYHIISTRGTSEPQGPSFGFRTMNDRILSAVSGGQEYDTVYPAGIDQNSAQGTADIVAQVKAELAANPNQCFLLEGYSQGAAATVNALPQLTGAAFDAVKGVILIGNPEHKPGLACNTDANGGKTTASARGISAAFTNGVPSNWVSKTLDICIQGDGVCDSVSGFGITPQHLTYGYSTNVQTMGANFGIKALQG\n",
            "Generated Protein: MQFVPSITTRIVFIFKEVKSDCSSKEVKKEVKVKAAKEVKMVHGQDSMVHGQDSARSLKSGGFGSLKSSLKSSLKSTYAVMVHGAQGTAQGTAQGTAQGTTDTDRIVIEVNVAASCPSCPNYSQGYSQGYSQGYSQGYSQGYSQGYSQGTIGGVIEVNYSQGARGNVVRIYTSTDKGYTSYFFTPTPVYSSNWVCVCKTLVCVCTPTDKTTPFVASVCVCTPFVAS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   2%|▏         | 54/3111 [00:47<44:02,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MKFGKFVLAAASTALAVVGLGGVAAADSTPQAQPSIIGGSNATSYPWAVALFVNGSQNCTASIIAPQYILTARHCVSSSGTYTFRIGSLDRTSGGTMATGQTITRYPGSADLAIVRLSTSVNATYSPLGSVGDVSVGTNVSAYGWGATSQCGSEINDQSRYLKVATVRVNSISCSDYTGTPAVCAQRVNGGTAGGDSGGPMFYSGVLVGVASTSDGVNNTSYTNISAYRSWISQVAGV\n",
            "Generated Protein: MGLAGWGWPDVFIFALSLATAGVQAGVQKQFDADGRTPTVAQLAATGAATGAATGSSGDSGPSGPAKPDVGPSVGPSMAWLTADLWLGPTLDEPEGTLDETGAMMAWLASICMAWLMAWLMAWLALAQMAWLTGLDAGTVMAWLSNSSGDTGLDSSGDSSGDSSGDFIAGSSGDRQYLIGNPPPATSNYFFGGTTAGVQGGTTSSGDGGTLAGATSSGDGGDSAGVANGANSFMAWLALIKQAEIGVYANSFSNASKKPNSSGD\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   2%|▏         | 55/3111 [00:48<43:57,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MKEYTNLYIGGQWVSPHSDNMSDVINPSTEEVIAKIASGTKADVDAAVRAAREAFDSFRQTSRESRVKLLRDVAAGIQSRADEFAELIVQEMGAPLWLARQAQVPAGIAHFAAAADMLEKFELVEAKGTTHLRREAIGVCGMITPWNWPLNQVANKIAPALAAGCTVVLKPAEQTPLDSILLAEVIDAAGAPPGVFNLVTGSGSVVGSALSAHPDVDMVSFTGSTRAGAQVAAAAASSIKRVSLELGGKSVNIVLPDADLHESVVRAVRSIFSNAGQVCSAGSRLLVPADRLEEAIAIAKQTAESIPVALPADADAPAIGPIITQRQYEKVHKYIQVGIDEGATLVTGGVEAPSPYEKGFFVQPTIFANVNNAMAIAQEEIFGPVLVIIGYEDVDQAVQIANDSPYGLSGAVVGPHEQAVEVASRIRTGQVFINGAGIDFTAPFGGFKQSGNGREMGPTGVDFFLEY\n",
            "Generated Protein: MCLVPWGVDAAAAAAAALLLLSGEEPVDAGSAGKAPAGSAGQYGLAGSAGKAPRLSEPLAGSAGAVPLISAGVPAATGQYGLKGPIGKGPKGPTGAMTGAMTGAMTGAMASGWLAQVDWGVDRHAVVDEGMCLMCLANAEDDRQYLAEDDFGYPDQYGLQYGLWNGAVAGALAQQYGLATGCHCHANAGIGVDPLNDAGIGPLSPAGIGADGLQADAPDQNGETAPVSAEDDAPDQAPVSEPAPDQAATGAATGAATGEPANEGAPDQVDEPVDQYGLQATGVDVDVDPLVDVDQAEQAEVDQAEQAEQAEHVDQAEIGPHVDEGHVDCCIGHVDATGAATGAATGAATGEHKTKTATDDDTAFDAPPDADDWPDWSAPWSAPWSAPQYGLSGAFPLSVNLDDQYGLPLIDVDAEDGAEDGPLSVEHAPASEHFNAPATGAPASAPEPFNAPFGSLPSLPRYGLLAGAGVKFNAPAGQAEQAEVGIGAGQKSGAKPDQYGLRQAEDEAAQYGLQAEVDDTEGAPDMIGESGAF\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   2%|▏         | 56/3111 [00:49<44:03,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MRGVLLRARTAALSIALLALAAGALVAASPSVAAQSNPYQRGPNPTRSSLTAQGPFSVGTSTVSSLSVSGFGGGVIYYPTGASGTFGGIAISPGYTASASSLAWLGPHLASHGFVVLVINTNSRFDYPDSRASQLSAALNYLRTSSPSAVRARLDTNRLAVAGHSMGGGGTLRAASQNPSLKAAVPLTPWDTDKTWRTSVPVLIFGAESDTVAPVSQHAIPFYNSLPSTTPKAYVELRNASHFAPNSGNAAISRYTISWMKLFVDNDTRYRQFLCPVNDPALSDFRRLNNPCQ\n",
            "Generated Protein: MANPSLPRGPRAAARLAPASGVATVATASFGGGFGGGASGFGGGARGASTSAVTSASFGGGFGGGVGGFGGGFGGGFGGGFGGGFGGGVGGVGGDQPDQPASGSLPRHRHRSHSDQPDQPDQPAALHSDQPDQPMGGRSMGGRTHSMGGMGGAVAGMGGMGGMGGMGGMGGRAAMGGKAAKAAARPKTSLPSSSLPVGAPVSANQADAPVSANRSASRSANAPRSANQAEFVDFYRSRSMGGRSASVGRSRSRSRRRSRSRSRSRS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   2%|▏         | 57/3111 [00:50<43:57,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MINRTLPASLLSGLAAGALLLSTSVMADNPPVSDPTDTDPSYARGPDPTVAALEASSGPYSTRTSRVSGLVLGFGGGTIYYPTGTTGTFAAIVVAPGFVSRESSIAWWGPRLASHGFVVMTIDTNTIFDQPVARARQINNALDYLVAQNSRRGSPVNGRIDTDRLGVIGWSMGGGGTLRVASQGRIKAAIPLAPWDTTIARSVQAPTLILACQADIIAPVGVHASPFYNQLPNDIEKAYVEISGGSHFCANGGGLNNDVLSRLGVSWMKRFLDNDTRYSQFLCGPNTTDDRRVSEYRGNCPY\n",
            "Generated Protein: MNRRAALAAAAARLAVAVAGGTSASGASGADGARGSLSTSCNSLSAVAISFSADGRHRHFGGGFGGGTSTSAISTSHSASGTSYLSAALSLPRHRHAVANTNTNANHSRTAVANRTAALRTWNMGGWSHSMGGAVAGMGGWNWNVLGRAAASAPWNRGWNSLPAYLWNSLPVATRGANFYFYANFYAVAVAPASASFLEFLEVSVGILGANCNC\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   2%|▏         | 58/3111 [00:51<43:55,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MSNVQGSADPRFERVRELFAEQLQDEQALGAALCVTVGGETVLDLWGGSTDKEQQQVWEQDTLVNVFSCTKPLGAVALLQQVAAGRIALDAPLAEVWPEFAQAGKQAITLRQVLSHRSGLSAIDKALPPDALFDWDAMSAALAEQAPFWEPGTAHGYHPVTYAWLLGEVLRRTTNTSPGNYIQQHICAPLGMDFHVGVPDKDLARIAHMSRLRNQSGDEGARRLFAAMGEPEGLTAQAFGNPVSIMTSTNRREWQQAEIPSANGHGNARSLARFYQLLAHGGELDGVRLLDSELVSLMQQEHSQGTDRVLLQPTRFGLGVMLEQDVPGGRFGAGPQAFGHPGAGGSLGFADPEAKVGFGYVTNTMGPYMLMDPRALALSQAVHDCLRELD\n",
            "Generated Protein: MRSLRAVALLALAAALLALLAVAMVKVKVKAHPEGAHAVAVAVAVAVIIAPWDKIVNAVVLGVLGAIAVALLAVQERALLAVWLRCALLALLALLADANAVAVAVAVAVWGANNAVPAVAVGATGAVGVLGKW\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   2%|▏         | 59/3111 [00:52<43:59,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MTAEITQGRYQGLSSEGVTTFRGIPFAKAPLGELRFKAPQPLPDSEDCVNADRYGAASLQPRNTIMGTQESSEDCLYLNIWAPEGEGPFPVMVWIHGGGYMAGSTSQALYNGAELARAQGVVVVNANYRLGAMGFADLSAVAPELDASANLGLRDQLAALQWVQENIAAFGGDPKQVTVFGESAGGFSVCSLLACPQADGLFQAAIVQSGGADFVLAPDQVRKVTEAFVAALNEDESAVEKLLSADNKGLIEAQNAALKVLGDRGLRRTTPQFALTFLPIVDGDVLPQLPVDAIAAGAAANKRVMAGVTRDEFSFFQIAGMLAGTTTMDALREISDEEIVSRFERALPGEGRRAFDAYQQAVERDAPRSRLDVLAAMASDRLFRVPTRRLLDAQSQHADTWGYVFTWATEVLGVPLGACHVVDVPFVFGNLDTPAGMLFTGGGSEARALSRQVQAAWGGFARGDAPGWNAWQSDRQVRVLGPNTTMGSLPDASDLQLWRDTPPVV\n",
            "Generated Protein: IPIRILRCDWLLLLLLAGCEDCEDVKVKNPATAGCIRGEIAAVSSLTAAREIARYFYLLARAGVPLLRDSILLRDIMVLGAFLVLGVKVKRRLDRQILLLARIMIRGIRGIRGIRGILARILARILARILARILARWGEIYDILIRGVHGWNGWNGEILLARYITWEGCHAMVRCICIPLARAATAACIIPVRCICIWNIRGPIVTWDLCVYRLVSWDLWDLEIWDLWDLWDLVKVKLLEDLLEDLLEDLLEDLLEDNTTLLEDEIILVKLLEDIRGVKVPADLLEDLLEDIRGAMLEIILILVEGVKISAYALIHVDEIQILPHEIWDLIHGIHGEIIHGIHGIHGIHGWDLIRGIRGVKLQILVKIHGDIIRGWDLIRGIRGLLAGCHLLAGQILQILLLAGEILLAGEINFDIRGLLAGILNFDQILLLAGLLAGQILLLAGLLAGIRGPDSIRGIRGPDSLLAGVKILIRGIRGLLEDILIRGPDSRVIDRVIDPDSRVID\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   2%|▏         | 60/3111 [00:53<44:14,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MKSLRLLGAASAAAVALSLAGGAVASAGVQPNIVGGSTAPTVAWVAQVYNNTPGTDLQNFNCSGSVIASRWVLTANHCLDQDGSGMYVRVGSSTLTSGTKIAVDRFYESPNGDIALLHLASASSASPISLGSSDPATGSTEQIYGWGRTSPTGPPATTLKTANVQVTGRSTDAAGGPAIQSVGKNGSAWGGDSGGPYVANGQQVGVASTSGNQSGSATAGTNNYASVAASRSWIRTTSGV\n",
            "Generated Protein: MKFSLRSLRAATALYINALSLPTGGPTGGPTGGELENATCVTIIAPAIKFRTFRTALTFQTYLVGYLVGIIAPQLYQLYIIAPNNSHCLPEGIIAPHCLGGIQLYQLLAVVTAANPTRYYAHYYAIKVRYAIKAIKPAAQLTKPTGGIYDRQYLVFLPSQPNTSNTSNTSVVVVNTSVYCNTSCSDAVGHICQIGGQIGGFGVKALIKVVVVAMVN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   2%|▏         | 61/3111 [00:53<44:02,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MTTVKRSRLAIAALLFLFVLFGNADAAEKQVDLVLVHGLTNKHNWSDSFLRALVKEIGSGNVYVWEENQSMKVSKRTIDGKQITRDGKNDFGAGDDSVKKQAEIMAEKIEVLKRDHGLSGQFYIIAHSMGGLVSRQYIHDHPDTVAGLVTLGTPHHGSVLASIVDPLGFFIGGEAARDDLRPEWVEDFNRRFPVENAPLYNGVKIYTIRGISDRIIWEWGATGELYVGWHILKYKVGTDSDGLVPLASAVIEGAVHLADLPNYHHLDLVTREEVAKVIAEVLR\n",
            "Generated Protein: AQSSLRAAAAAAAAIQILPHATEKPITPSVEPSVEPSVENATFRVSTRNIRIILCAPTYGYLVGYLVGIIAPTWPTGNNSNNSHCLNNSAAMRHTIEAISAVVTAVVTAPLAANPDQARALLQRITTNNTNNNNYDAPVTAEGRTALGGTLVFLCAPSGGTLCGAPRGVLCPAGNTSGLACNLQNNTSVYCAVGVTGVTGAYGGGTLTQVVHIGVLDDTMTYGAESDAPVGTRMDVIWIRYFRSYFRSAAARLAAARLTRYSAAIV\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   2%|▏         | 62/3111 [00:54<43:55,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: SPVDLQDRQLTTNDELRDGPCKPITFIFARASTEPGLLGLSTGPAVCNRLKLARSGDVACQGVGPAYTADLASNALPEGTSQAAIAEAQGLFEQAASKCPDSQIVAGGYSQGTAVMNGAIKNLSADVQDKIKGVVLFGYTRNAQERGQIPNFPKDKVKVYCGVGDLVCQGTLIVAPPHFTYLPNTGAAAAFLLSQLG\n",
            "Generated Protein: MFNNFALAALARRLAAAATAVKPITKPITELEELEASTEPCPCTGPAVCAPFIYTASRLGSVSACQGVSEVSETAVAFGRGETGSLTGSLQAAADNTADFANQAVAGGTQIVCPDTAVTAVTAVTAVTAVRLAVRLAVDSVVLGGTLVVLVVLRPDLNLQNTGSLTGSLGGTLNLQNNLQNVYCTGSLTGSLADRTTGSLTGSLTGDLTGSLTGSLTGSLTGSLTGSLTGSLTYGTYGAESDTYGTAVVTVVELRRKPITELRRCDGTRTGSLNTTKPITNTTNTTTRTRTRYSTRYSTGSL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   2%|▏         | 63/3111 [00:55<43:48,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MQSVPWGITRVQAPAAHNRGLTGSGVKVAVLDTGISPHPDLNIRGGVSFVPGETSYQDGNGHGTHVAGTIAALNNSIGVLGVAPSAELYAVKVLDADGSGSVSSIAAGLNWAGNNGMKVANLSLGSPSPSATLESAVNSAWSRGVLVVAASGNSGAGSIEYPARYANAMAVGATDQNNNRASFSNYGTGLDLVAPGVNVLSTYPGSTYATLNGTSMATPHVAGAAALVRQKNPSWSNVQIRNQLKNTATSLGSTSNYGSGLVNAEAAVR\n",
            "Generated Protein: MKFGKFKQKQWLAGLIFATEELEKQKQKQVWTTEPTGEDSNFKQYTGCSGSWDKQVWVAVVLGNFVWVWVWRQQDNQDDIMVWYYNQYYYYTTETNARWGDQNEGNQAPVTWGWGNQISVKQWDSDSVTGVTGDQGGTLVTGAGLNGSKQTHPQSGSTMSGSVASTMAQHLQDWDLVASPHNQVWWIRRVTKQKQIMNQKQNADTRTGGLHP\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   2%|▏         | 64/3111 [00:56<43:46,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MKTYKKVVVAIAALLVLFVLPGNADASEEQPDLVLVHGIGNKNRWWDSFLKALVNEFGSGNVYVIDTNQSMQPSKRTIDGKTITSIGKNDFSAGNASVKDAAEILAEKIETLKRDHGLSPQFYIIAHSMGGLVSRQYIYNHPNTVAGLVTLGTPHHGSQLASIFDVLGFFIGASAAMQNLRPEWVEDFNRRFPVENAPLYNGGKIYTIRGDSDGKIPESGAEGIMYFGEHILNKKFGTDSDGLVPHASAAIEGAVHLADFPNYHHLDLVTNEEVAKKAAEILR\n",
            "Generated Protein: MSGGDWGRRLISAAEATEATEASEKQAQVLVHQSNPVLVHDSDSGESGSPTQDCSGSRWGLVSEVWAGGVSKRVWTGRAHTSGGQDDSDSGLVWWGWGFVAEGTNARWGTNARSSDPWGSSDPNEGWGRSSPDSDSDSGGNSDSVTGQRYANDQNGSVTGDSGGVPLKWFGVKDSGGDSGGFGVKGGDNANLWDSGSVSSADFGIKWIRWIRWIRWIRTRYSASE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   2%|▏         | 65/3111 [00:57<43:42,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MANPYERGPAPTRASLAAPSGDFSVSTERASTFGADGFGGGTIYYPRGNGTYGAVAISPGYTATQASVAWLGPHIASHGFVVITIDTNTLLDQPDSRADQLNAALDYMINDASSPVRSRIDSSRLAVMGHSMGGGGTLEAAQQRPSLKAAIPLAPWHLNKNWSSVRVPTLIIGADLDTIAPVSTHARPFYNSLPTSIDKAYLELDGATHFAPTRPNPSIGKYSVAWLKRFVDNDTRYTQFLCPTPSDGLRGVAEEYRSNCPF\n",
            "Generated Protein: MANPITARITARITARSPTRNTRNVPLSVAVSVERSSPITARGLNNITARITARITARFYNFYNITRRFYNVSGLTQASSVSGVARIASRIASHGGGIGGIGGIGGIGLEQRGRQITARITARAALDFYNNTNSNTNSFYNNTNSNTNSNTNSIDTNRARRSSPRGRQFYNRVDITARQSNFYNFYNGGTLRLAVNLQNNLQNGGTLGGTLGGTLFYNFYNFYNFYNFYNFYNFYNFYNVPVLFYNAPVGFYNITARFYNKAYLFYNVEISFYNFYNVNDPVEISFYNFYNVEISVNDPVEISVSFVDVNDPVNDPVNDPVNDPITARVNDPVNDPVNDPVNDPVNDPVNDPVSEY\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   2%|▏         | 66/3111 [00:58<43:54,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MSDLVWSRDGLDWPHREASRFVEAGGFRWHVQTMGSPAAPAILLIHGTGAASHSWRGLAPLLSRHYHVIAPDLPGHGFTQTPRGSDMSLPGMASDLAALLRQLEVAPQLVVGHSAGAAILAQMALDGSLEPKILFSLNGAFLPFGGPAAWLFGPLAKLLGLNPFVPSLFAWQASRRAAVERLIGATGSAIDPAGIELYGKLARDPNHVAAALRMMAEWDLEPLLKALPHLAPPLVLVAAEGDRTIPPSVAEKVREILPKAVIEFIPALGHLAHEESPALIAALILRYAEKLENRV\n",
            "Generated Protein: MSRRRRAALLAALLDGVTGLRWVQRLRVTPRGQAQGLVRTPRGDSEDTPRGTPRGTEDSTEDSTEDSTPRGTPRGGLRWVATETPRGIGTPRGTPRGTPRGTPRGTPRGFANTPRGGLFANSKGLHGHGHGTPRGAAVLAAVLAAVLAAVLFGTPIRIQKFAAANRQLLIQKFTPRGSLFTPRGSLFSLFSLFSLFKTKQVTTPRGPLARTPRGPLARPLARDSDNNEDFIGKTTPRGAMVEKTRNASIQKFFGPNLPNLAEKRRNASDLADANAPDLADDLADRNASNPAHEENPRLTPRNASIGAHEERPAEQSPQQSAQRRQSAQAAANHLAAANVEGRAFLVEGRAFLRAFLRAFLRAFLRR\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   2%|▏         | 67/3111 [00:59<43:48,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MNTTPVHATTIILGGIAVDPAPRLAGSPVFGGPGAAAFDLATGRSTGREVLRFDLPGVSIGAASYEEGPTGVTVIHIPAGARTAVDARGGAVGLTGAGRFVHAILLAGGSGYGLAAGAGVSDALLERGGEPDGIAELPLVPGAVIYDFSARSTALRPDAALGRAALEAARPGEFPVGRAGAGMGASAGKFDPERTLRGGQGAAFRRLGDVRISAVVVVNPVGVIVDRAGTVVRGWYDAAAGVRVLPVFDAQAAFAEQVPPPTPAGNTTIGAIVTNVRLSPVELNQFARQVHSSMARGIRPFHTGFDGDTLFAVTTDEIDLPTEPGSSPARLSVNATALGAIASEVMWDAVLAAGK\n",
            "Generated Protein: MNRRQHPAAAVAALLAAAVTLDNAGVPTLDSVEAVPGWAFDLAPGLTGVHGFPGFPGVSIGAGVPAGVPAGVPAGVPAGVPRIGVLRGVLRGRSGSVLRGRVRVARRAGVPRFVKSLVRALVDATTEEGRALVDYPDFSARVPELRYPDVPELAAVAARISIDISIDISIDISIDVAHGISIDISIDAGKAHLRRQGAANQFQGAAAGVPQGAAVRRNPVGVTENPVGVRDIAADIAARDIAADIAAVEALVEALNQFRLLWRVGHLYAQDHRVGNQFNQFNQFNQFQVHQVHSGIGHLNQFSGIGRNQFIGPYTDAGSGIGPEGSELIGDEIPEGSVERPLAVLEIGSGIGAVLEVEIGSGIGRWLDPRSGIGRDHDHDHRVVRRDHRSGIGDLEGDHREDIGVQSGIGVERRRR\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   2%|▏         | 68/3111 [01:00<43:47,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MNKSIFKKLVFLTSVLLVSMNALSQTPSPTPDPDPTPDPTPTQDDCNFTRGPSPTTSSLEASTGTLSVATDSVPSSVSGFGGGTLYYPTNTTGTLGAIAIVPGFLANESSIDWWGPKLASHGFVVITIDTNSGFDQPASRATQLGYALDYVINQSNGSNSPISGMVDTTRLGAVGWSMGGGGALQAASGDRLSAAIPIAPWNQGGNRFDQITTPTLVIACENDTVASVNSHATDFYNRIPSGTDKAYLEINGGSHFCANDGGSGGGILGKYGVSWMKRFIDNDSRYDQFLCGPDHAANPSVSEYRDTCNY\n",
            "Generated Protein: MINPGPGLLAAALAAAALLALAAVAFIFTGPGPGPGRRNPRFDFVRFDQPPGPFSVSGYYPVAHGHGHGVPGTVPGPGPGPGAALLSKAALLHGDHHGDHDHRFDMGMGSPPGSPMGSPMGHLMGFITFITMGMGMGAPMGHLAPPDLPGHLIIPGIINPAPHLIGNPAIPNPNPAIPDHPKDHYAQDHDHYAQDHNPDHWMHLWMWMVAHLHLHLPY\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   2%|▏         | 69/3111 [01:00<43:42,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MNKSLLKKLVFLLSLLLVSINALSQTPNPTPNPDPSPDPTPCEDDCDFGRGPAPTLSSLAASTGPYSVATSSVASSVSGFGGGTIYYPTNTTGTFGAIAVVPGFLNPESSMDFWGPKLASHGFVVITISTNSVFDQPASRATQLGRALDYLINQSNNSNSPISGLVDTTRLGVVGWSMGGGGALQAASDDRLQAAIPIAPWNQDGNSFDQIETPTLIIACENDSTASVNSHALPFYNRIPSTMDKAYLEINGGSHFCANDGSSGGGLIGKYAVSWMKRFIDNDLRYDQFLCGPDHAANTSVSEYRDTCNY\n",
            "Generated Protein: MINFALWLDAALLALLLAALLALLLIIGGFIFFIFNPPAQSGLTNPSYYPVLDLRFDASTNFSVSFSVSNLGTYTGYYPYYPYYPYYPYYPTGAELAAISPRLYYPPRLPRLPRLPRLWWGPRLMNGIDTNRFDIDTNITIGITIGAPYYPSSPSFISGRLAVYPDVFDSPPSYAVAGRLGRLGTLMGIIGTLKLKLTLSVSRAVAAAQPGLTLVIIIIITLIFTLIFNHPTLIFPSTTKYSKYSKYSKYSKYSAIPYAQYAQYAQKYSKYSKYSKYSWM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   2%|▏         | 70/3111 [01:01<43:37,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MSNVQGYCDSRFERVRELFAEQQQDEQERGAALCVTVGGDTVLDLWGGWADKEKQQVWEQDTLVNVFSCTKPLGAVALLQQVAAGRIELDAPLAEVWPEFAQAGKQDITLRQVLSHRSGLSAIDEALPPEALFDWSTMSAALAEQAPWWEPGTAHGYHAVTYAWLLGEVLKRLTNESPGEYIQQHICAPLGMDFHIGVPDQDLARIAHVSVLENQSGDEGARKLFAAMGEPEGLTAKAFGAPPSMMTSPNTREWRQAEIASANGHGNARSLARFYSLLANGGELDGVKLLDSELVSLMQQEHSQGVDRVLLVPTRFGLGVMLEQPAPGGAFGMGPQAFGHPGAGGSLGFADPEAKVGFGYVTNTMGPYVLDDPRALALSQAVHDCLGELD\n",
            "Generated Protein: MKFKLAVLSTLAELAELAAHAAHIIGGIIGGPSPSPSVLDLVLDLVLDLFRTVLDLFKLDGNGPSPSPSPSPSPSTIDGAELAELPSAELSTTGPSSTTGPSSSAGKQAELVLSHAHSAHSAHSAHSNEGGLVSGLVSPSFISGHPDLMLSNSGANGGYPARYANYANHSHSVLGIIGGAIQSKLKLKLKLPSPSPSAELSG\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   2%|▏         | 71/3111 [01:02<43:40,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MCLVTLRRCTPINMRNRGDSEFDFVVVGAGSAGCVVASRLSENGKYSVALLEAGGSDRNPLISIPFGFAFAVPKSPYDWSFDTVPQEGLNGRRIYQPRGKVLGGSSSINAMVYIRGNKEDYDHWAALGNEGWSYEEVLPFFKKSENRVKGANEYHGQGGPLTVSRPRSPNLLSDMFIKAGIECGLPYNEDFNGETQEGIGVYQVTQDGGKRTSAALAYVRPAEKRKNLTIFKQAFVEKVLVENGQATGVRVKENGNLQEIEARREVILSSGAFQSPQLLLLSGIGPKDHLDRLGIKTVHELPGVGENLRDHVDFYLTYQLDSEHTLGFNARSVFRVAWNLFKYFAGRGGILTTNFNDSGAFYRTNPDEKSPDIQLHFAFMLVDQHGLKRHGRPGFSIHVCVLRPKSRGRVTLADSNPATPPLIDPAFLSDESDVATLLAGVKRAQQILSAPAFDEIRGEPVYQTASLNDDELIEDIRNRADTIYHPVGTCKMGPDSDPMAVVDQQLRVRGIRNLRVIDASIMPSIVSGNTNAPTIMIGEKGAQMILDEAGSLT\n",
            "Generated Protein: MKEFKLRSRLAESGEAELSGERSEELRFELRFELRFELRFELRFAHLAFDSDGEAFDSGLNGFKLAFDSFSFKLPSFAFAFGAIDHGAELFKLGLNGAELSGNEGGLNGADLGLNGAGKQAGKQNEGQPAPAHSSSNEGNEGNEGNEGNEGGLNGNEGNEGNEGHSKLKLNEGKLKLSSKLKLNEGKLKLKLKLAELKLKLQATNEDFKLKLQEGQEGVQSVQSVQSRGKRVQSVQSRGKRFVLFKLFKLSTFKLFKLFKLFKLFKLFKLFKLFKLFKLAEFKLNAGNAGVILSWKTVILSVDSVDSEEVESAESVDSAESFKLTLCCFKLAESFKLFKLFKLTTEFKLFKLFKLFKLFKLFKLFKLFKLFKLFKLPDPDAMVWWDFELRFRSRLRSRLFKLTLAMDGPDPDAQSFVFGAFDEFKLFKLALNPDVDSFKLKMGAMDGAMDGAMDG\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   2%|▏         | 72/3111 [01:03<44:01,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MANPYERGPQPTRANLNAPSGPFSVSTETDSRFGADGFGGGTIYYPRQNGTYGAVAISPGFTAQQASVAWLGPRIASHGFVVITIDTNTVLDQPDSRARQLNAALDYMINDASSAVRSRIDSSRLAVMGHSMGGGGTLRLAQQRPDLKAAIPLAPWHLNKSWSSVRVPTLIIGADDDTIAPVATHARPFYNSLPASIDKAYLELRGATHFAPNIPNGIISKYSVAWLKRFVDNDTRYSQFLCPGPRDAEFGIVAEYRSTCPF\n",
            "Generated Protein: MANPTLKRRPDLSSIEALPSGEHSIIGGPCPAPPDPPDTLTFGSSTFGTFGTFGAISDGNGSISITIYTNAISTNTNTFGTNTNHSTFGSSHSAALDNSPTNMNGTNTNTNTNHSHSAALDAALDHSHSHSSSHSHSHSNKNHSTLHSHSIIGRPDLRPDLHSSSHSHSSSTLHSHSHSHFACEYEHFHSHFHFYEHFHFHFTNHFHFHFHFHFFVDHFVIS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   2%|▏         | 73/3111 [01:04<43:50,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: YDVRGGDAYYINNSVRCSIGFSVNGGFVTAGHCGNGTVTGSNNQAQGTFAGASFPGNDYGHVRVNSNWVPRGVINNGTRVSGSSEAPVGASICKSGSTTGWTCGTVQAKNQTVRYAEGTVYGMTQTNARSQPGDSGGSFISGNQAQGMLSGGNSTVTYFFPVRPALSATGGSLVTG\n",
            "Generated Protein: MRMSVLRNFFIGLLSRALPVATFFIGASRLGFFIGTTRNACPDLVLDLMVHGRVAQVLDLDGNGSGDGNGHGTHHGTHHGTHHGTHVLVLSGDGNGVLRFVDFFIGATYSVAQAGKQAGKQAGKQNNGAGKQNNGFFIGVLSHVLSHATYSAHSFDAWSFFIGCGAPVHGNAQFFIGFFIGFFIGFFIGFFIGHGTHHGTHFFIGFFIGFFIGFFIGHGTHAIQSRRFPSGFFIGSGSYIKIENGTSKNMATNGTSMATMATVNSQKNQKNQKNQKNCQMIEGSLGSAPPIKGLVNVLTHDLVTAVHLADFPVLTHLLSRFFIGCQMVPDLCQMCQMCQMCQMCCVPDLMATMATMATFGLGFGLGALSQ\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   2%|▏         | 74/3111 [01:05<43:38,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MRLSVLLSLLPLALAAPAVVQRSEAAPLIQARGETVANKYIVKFKDGSALSGLDAAMGRISGKIDHVYKNVFKGFAATLDSDMVEVLRAHPDVEYIEQDAVVTINAAQTNAPWGLARISSRSRGTSTYYYDESAGQGSCVYVIDTGIEASHPEFEGRAQMVKTYSSSSADGNGHGTHCAGTVGSRTYGVAKKTQLFGVKVLDDNGSGYYSGIIAGMDFVASDKNRRNCPKGAVASLSLGGGYSSSVNSAAARLVSSGVFVAVAAGNNNADARNYSPASEPSVCTVGASDRYDRRSSFSNYGSVLDIFAPGTSILSTYIGGGTRSISGTSMATPHVAGLAAYLMGLDKTTAAQACNYITDTATKGKLSNIPSGTVNLLAYNNNQA\n",
            "Generated Protein: MRMSVLGGLLALLIAASGAFNRGLVAAGIVGGVAVLDTAGTTRNDLVLIVFRVAQIVFRRFPNVYACQGHGTHVAGVNSNVAGTSVLGSGTYSGTYKVASRLGSGTYMTTIAAAGKQAGKQAGKQAGKQAGKQVLSHGLSPVLSHPSPSRQAVTYINAYATGSNGCGAPSGGGASRLGVAGGGDGNGLLGEHGTHHGTHGGAIQSAALDGASFSTPVAPSAIQSNGAPPVAGIEFAGSKGAAMATMATMATMATVAGMATAQKNQKNAPPPEGLSLGSKNAIQSNADSLGSDLVTVLTHDLVTDLVTCQMCQMMATLLAY\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   2%|▏         | 75/3111 [01:06<43:44,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MRLRVVALTAALSLTLSLGATSAAAAANPHERGPDPSSSTIAQARGSYSVSTRSFSRAGSDGFRGGTIYYPTSTADGRFGVVAISPGYTASESSIAWLGPRLASFGFVVVTINTDSRYDQPAARATQLLAALDHAIKDSQVGPRIDTSRFAVMGHSMGGGGALWAAEERDELRAAVPLTPWNTSKSWSGVDAATLVIGAENDAIAPVRSHSIPFYESLTNAPRRAYLELRGAGHFAPNSSNDVIAKYSVSWLKRYVDNDLRYDQFICPGPRTGITTGVSDYRKG\n",
            "Generated Protein: MTTASTTRGPTDTSALPALPALPPCPCASTETTRNTTRNASDLCNTYGASNDFGGGRGPASTVYIASASTIYMNGNGTSNDMNGQAATSMTTTGDDTGDDTGDDMNGMNGMNGDLMNGKIKGNDKIKGTGDDKNTTRNAALCDIDASQAANGTSNDTPADRTNGNGADRTTSADRTCNNGTYGTPTPTYGTYGWYNDNDWYRGSRGSRGSRGSKRKNDLYDVAWLVAWLKRVAWLNDEDED\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   2%|▏         | 76/3111 [01:06<43:37,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MNKSILKKLIFAISVLLLSMNLLSQTTTPTPNPDPNPDPTPCDDDCDTTRGPNPTLSSLNAQTGPYSVATGSVASSASGFGGGTLHYPTNTTGTFGAIAIVPGFLSSESIIDFWGPKLASHGFVVITISANSPFDQPASRATQLGRALDYLINQSNNSNSPISGTVDTTRLGVVGWSMGGGGALQAASEDRLKAAIPIAPWNQGGNRFDQVETPTLVIACENDVVASVNSHAIPFYNRIPSSTDKAYLEINGGNHFCPNGGGSFGGLLGKYAVSWMKRFIDNDLRYDQFLCGPDDAENRDVSEYRDRCPY\n",
            "Generated Protein: MNKSVYRGPTTNDPAPGGASPSASPSASPSVGASPSFGGGFGGGFGGGRRGRGPRGPRGPFGGGFGGGIAPFGGGFGGGFGGGVPGVPGTSGVPGVPGWWGYTADASHGYTADASHGCGIAWVYFWGASHGFVVFVVQPASNALDAALDAALDQPASAALQLGRGGALDYVPGTPAALGRRLGRLGANDGGGGGGGGTPWYLGGAFYNACEWNQAPPSPDVSAPVSVSAPVSAYLERRGAYLEAYLEVNSHCANAYLEAYLEAYLEGKCANNDADAAVSCGEDVSNDAYLEALLGKPNCGQDCGYRDEYRSSCGQDCCCCNCP\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   2%|▏         | 77/3111 [01:07<43:41,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MINTTLPTSLLSALAAGALLLSTSVLAQPPPVDQPTDLGNSYARGPDPTVAGLEAQSGPYSTRTSRVSGLVSGFGGGTIHYPTRTTGTHAAIVVAPGFVSAQSSISWWGPKLASHGFVVMTIGTNTLFDQPPARARQINNALDYLVAQNSRRTSPVNGMIDTDRLGVVGWSMGGGGTLRVASNGRIDAAIPLAPWDTTNSASVQAPTLIFACQNDIIAPVGRHAPTFYNQLPNDVEKAYVEISGGSHYCANGGGLNNDVLSRLGVSWMKRFLDNDTRYSQFLCGPNSTSDRRVSEYRDNCPY\n",
            "Generated Protein: MNKSTPPDPTTNDAAGTPTPTPPDPDPPDPPAPWIIPLFGRGPDPRRGIYTVSIAPIAPVMADVMADVPGFGGGTSGFVVTSGVPGQPAPRLDYTADYIAPFVVFVVFVVFVVFVVFVVQPASFVVQPASASSASTPQPASQPASAALAEAALGRGGKITPAALGRAALGRGGKITPMGGTPTPMGGDPTPWTPTPTPTPTPSYSYSYTPTPTPAYLEAIPVNSHVNSHAYLEFDGGSAIPYDAYLECANVENGFIDNRYGKYKYYRQYGVSCGFIDYRQTPCGQDCGYRSSQDNDQRQDKYSYVNSHSYSYCSAV\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   3%|▎         | 78/3111 [01:08<43:37,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MAAGYERGPDPTESSIEAERGPFAVATTTVSVVQADGFGGGTIYYPTDTSQGTFGAVAISPGFTARQRSIAWLGPRIASQGFVVITIDTNTRLDQPDSRGRQLQAALDYLRTNSPVRNRIDPNRMAVMGHSMGGGGALSAAANNTSLKAAIPLAPWHTDKNWSSVRTPTLVVGAQLDTIAPVSSHSTPFYNSLPSDLDKAYMELRGASHLVSNYPSTSVAKYSIAWLKRFVDNDSRYEQFLCPAPDDTAITEYRSNCPFLEHHHHHH\n",
            "Generated Protein: MINAILLPSILLSRCAISCASSASRLDNPDPDPAPTIYSNPDPKRKRWRTIYAIKRTIYWLGPGPKRTIYITIDITIDITIDAIGPRAETIYQLNDYFVVYLRTITIDFVVITIDGRQLNQLNAALDQLNQLNRVDQLNRVDRLAVWHLRIDWHLWHLWHLTIAPTIAPTIAPTIAPTIAPWTIAPWARPISKAIIDKTIAPTIYTIAPTIAPTIAPAPRRDYVIFVDKRFVDFVDPGPPGPKRQFLFVDFIDFIDKRCKRFIDFLCKRCFIDKRDVEE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   3%|▎         | 79/3111 [01:09<43:31,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MANPYERGPDPTESSIEAVRGPFAVATTTVSRLQADGFGGGTIYYPTDTSQGTFGAVAISPGFTAGQNSLAWLGPRIASQGFVVITIDTITRLDQPDSRGRQLSAALDHLRTNSSVRNRIDPNRLAVMGHSMGGGGALSAAANNTSLKAAIPLAPWHTDNNWSSVRTPTLIMGAQNDTIAPVSLHSEPFYNSLPSNLDKAYMELRGASHLVPNTPDTTLAKYSIAWLKRFVDDDTRYEQFLCPAPDDPEISEYRSECPFLDHHHHHH\n",
            "Generated Protein: MKRNSLLPDPLLAALLSRGPSLPSGPAEPSASKGAQAAPDEPDPYPYSVSYEGPPLGPGPWRDYVIWRGPGPRIASEEITIDITIDGPGPGPGPGPWLGPGPGPWLGPASHLAPFVVTVLDRRAAYLTQAALDAALDRVDKIKGIDKPDLIPLIPLAIWHLRLGAIRLAVRMAPRRTIAPWIPLWPEISKISKAPISKPFYASHLASHLASHLASHLASHLASHLPFYPGEGKRRYEQFLWLKRQFLQFLWLKRPGPWLKRYRSWLKRQFLWLKRWLKRWLKRWLKRQFL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   3%|▎         | 80/3111 [01:10<43:25,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MRMSRAVGAIGAAAAALTLVSAGVANAQPGIIGGTTVSSAPWMASIVSTNVGSGGGFTCSGTVIAPQWVLTARHCLNRPGMTVKVGNASLGQGASAKVDQQVASPNGDIALLHLTTAVSTTPVKLGTTNPPVGATNQIYGWGVTTTSSPPSSTLKTANVRVTGQSTDAFAGRAIASQPINGTAWHGDSGGPQLYNGAQVGVTSTGSNSYSNTQGTVNYASVASSRDWIRSTAGV\n",
            "Generated Protein: MRLSLRLLSRLLGRVQSSENRGLNRGLSLFSVNRQRQVIVEYSRVAQQLSLRQAVSEENRQSLFNFNNASGYSPLGMYYYPDVERQRQVIVERQSVSSADLRQAAATMTYSYSSSAAYGHSRQRQFNRQTSGLSSTLHPEALAQRQALSALSAIGGPLFNFNFNFGTSSTLNSGQLYSQLYGVEDGGELMDRQSRAGFGTQGVQNNSSFGTPEGLVIVEPEGLPEGLRQVMDSDGGELNADAAISTRQSQGLLSRKGLKGL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   3%|▎         | 81/3111 [01:11<43:17,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MRASVLLSLLPLALAAPAVEKRSEAAPLIQARGQVVANKYIVKFKEGSALSALDAVVEAIWGKPDHVYKNVFRGFAATLDENAVEELRAHPFVEYIEQDAVVTINATQTNAPWGLARISHTSRGTSTYTYDSSAGSGTCVYVIDTGINASHPEFEGRAQMFKSFAGSSRDGNGHGTHCAGTVGSRTYGVAKKTQLFGVKVLDDNGSGSYSGIIAGMDFVASDKNNRNCPKGVVASLSLGGGYSSSVNSAAARLVSSGVFVAVAAGNDNADARNYSPASEPSVCTVGASDRDDSRSSFSNYGSVLDIFGPGTSILSTWIGGSTRSISGTSMATPHVAGLAAYLMSLGKTTASEACRYIAGTANKGKLSNIPSGTVNLLAYNNNQA\n",
            "Generated Protein: MSVPALSHDRVQALAQAPAQAPYSYSYSQLYSATSRQNARRDSLYSRDAQVGRDRDQQVGAIDEAPAIAESVSSSVSSYYAAATYYAAATAAATAPMTATATLFDRQYSHPEAQMLSVRSSTLSSTLAPSSTLALSAQAQQLVRNGSAQVPNSGNSGYGMDRDMDAQASLSLPLPHDSDSLDSDAPFDRDRD\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   3%|▎         | 82/3111 [01:12<43:33,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MKFGKPAALAASTALAVVGLTGPAAADDTPQAQPSIIGGSNATSAPAAAALFVNGRQNCTATLIAPRYILTAKHCVSSSGTYTFRIGSTDRTSGGTVATGSTITRYPGSADLAIVRTTTAVNATYAPLGSSGDVSVGQNASVYGWGATSQCGSGLNCQSRYLKYATVRVNSSSTSDYTGGPAVCANRVNGGPAGGDSGGPMFASGRQVGVASTSDGVNNTAYTNVARYRSWISQVAGV\n",
            "Generated Protein: MTATTTPAASTAASTMGLVSAGVSAGFSVNFSVNAPAPNPDVVGSSSATSATSFDAVSAVSAVSAVSAVSTVGHCLVVGHCLPLGVVGTYPDVEQGGTSSTVGAVYIAAATTSDAAATAAATMTATMTATSLGSATTNARRGVLHPERGVLHPEALMLSVRSSTLSSTLSSTLSSTLALSSSTLAVGVFASFSNSGASFSAPRRFPIGATMDASLHPEQGVQHPEASLIGATASLDSDDSDVRDSDDSD\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   3%|▎         | 83/3111 [01:12<43:23,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MRTVKRVKLAIAALLFLLVLPGNAAASEKPFDLVLVHGLNNKHRWSDSFLRALVNEWGAKNVYVIYTGQSGRVSKRTIDGKTQTLIGFNDFSAGDRSVKDQAEILAEKIEKLKRDHGLSPGFWIIAHSMGGLVSRQYIYDRPNDVRGLVTLGTPHHGSPLASVFDVLAFIIGAEAAMDNLRPEWVEDFNRRFPVENAPLPNGTKIYTIRGDYDYKIWAYGALGGLMVGYKILNKKTGVDSDGLVPHASAVIEGAVHLADFPGYNHLDLVTREEVAKKIAELLR\n",
            "Generated Protein: MGLTTALSAASLGVSAGAAAGPHVSAGFSVNIVGGNPDIVGGVAQVAQVAQQDSWGGWGGRFPSVCTLVNPTVVSTLVNHCLHCHCLNSPGTYQTQGAAISTVGAGPDVEPSVCTDYLRTVVGAAATYGHSYGHSVGATANVKVSVGVSVGMGGTNARHPEHPERFKTNTSPMGGWSMGGPSVCPTNARHVGRTYGVVGNSSGASDFTYQQVGQQVGPGSDGVCIGATIGATNNSSVAASVAASTTSGAAIFPSVCETVINVRPSVCPSVCPSVCPSVC\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   3%|▎         | 84/3111 [01:13<43:20,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MDVRGGDAYYINGSPRCSIGFSVNGGFLTAGHCGAGTVTGSNNVAIGSFVRASFPGNDYGVVRVNSNWVPRGLINNGTRVSGSSEAATGASICKSGSTTGWTCGTVQAKNQTVRYAEGTVYGMTQTNARSQAGDSGGSFISGNQAQGMLSGGSSTTTYFFPVRPALSATGSSLVTG\n",
            "Generated Protein: MGLKSILNDNNAASLGMVCALVSAGIVGGIVGGIVGGIVGGENIEIVGGFERGTDTSWGGWGGARSGWGGARSGWGGVVGVNSNHCHCHCLVVGDGSGPHIQGGRFQGGNNILAETDILAEVVGKTYGHSYGHSGGQDQGGMCLMGGMGGAWGRGVLRGVLWGRRFPFEGRMGGTPHSNMGGMGGVVGVVGRTYGIPLLTQLVANGDGVCDGVCVANGTYKTYGTYWGGQQVGIGATENIETYPRKGVTDSDAPTYPGESENIEENIEIPSG\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   3%|▎         | 85/3111 [01:14<43:08,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MQLKHLFLFILLSFFLSGCEAITNWAYEKGLAMEKNRAGLKDQQLTTADGITLHYLTSETSAEPSAEKEAVLLIHGFSADSSNWVRFAGELEGDFFFIVPDLPGHGESSRPLDLTYTMSAQATRLLTLADALQIDRFHVAGNSMGGAISLALAQQAPERVLSLGLIDSAGLAAQTSGFKTILASSNSNPLIPHTAEQFQATLQWAMAKPPYLPSFVVDIMAEKAAANAQVAEKVWRDLLADPGADLELKNVLPSIQAPTLVLWGAEDRILGVDNVDAFLKALPQSRAIVLDGIGHVPMMEAPGKSASAYRAFLREVRK\n",
            "Generated Protein: MCLMCLVLWGVLWGTDVAAIGMCLMCLPDAYEKTTSNIIPLIDSELTQTDTTEEPFPFPFIPIDPHIDLPGTTKTFTARSNMCLMCLAVAVDLPGWGDLPGMCLAGAAMCLMCLMCLMCLMCLNALDMCLMCLRFIPLIPLPLAKIPLIPLTDEEMCLMCLVVGVVGMCLIPLIPLTLVIMCLMCLTTTLVIKTKTTLVIENIEIPLTTAENDKTENIEENIEINTDVENGTTVENGVENGTTIAKTLVIVLWGPYENIETTENIE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   3%|▎         | 86/3111 [01:15<43:14,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MRIQRRDGTGARARGARAIGVVATALAVAVGAVGGPAGAEPSTAQDNPYERGPDPTQDSIEAERGPFSVATERVSSLASGFGGGTIYYPRRTDDGTFGAVALAPGFTASQASMSWLGPRVASHGFIVFTIDTNSRLDQPGARGRQLLAALDYLTERSTRSVRGRLDPNRLAVMGHSMGGGGSLEATMQRPSLKASIPLAPWNLDKTWGQVQVPTMIIGAENDTIATVQTHAKPFYESLPPSLPSAYMELAGATHFAPTSPNTTIAKYVISWLKRFVDEDTRYEQFLCPNPTDRAIEEYRSTCPY\n",
            "Generated Protein: MRIYERGWGPDPALAAGTRLPFYERGYERGYERGPDPPDTPYERGSNPFTDTSPFTFGFSPFPFPFQASAWLAVAVAVAVFSTDTRLTDTRLTRLQPDSAWLAWLQSSNPQSSAGAAAGAATRLAGAADGSYPDSRARNALDAVAGIPLAVAGIPLIPLIPLIPLAVMGAVMGTDIPLEEIPLIPLIPLIPLSTIDSTIDIPLIPLIPPFIPLTLVINSLCEELDGQHAGAAPGRPPFTDPGESTCPPRKG\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   3%|▎         | 87/3111 [01:16<43:13,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MTASTSRQRSSARRLGLRRATLGVATATLVAAGFGAAPAQAATGPVAGSTHVSASAAGSVTTVANSPVSEAQFNQMFPNRNPFYTYQGLVDAASAFPGFANTGDDTTKRQEAAAFLAQVAHETGGLQYVVEQNKANYPAYCDASQPYGAPAGQQAYYGRGPIQLSWNFNYKAAGDAIGVDLLNNPWLVNQDPAIAWKTALWYWNTQSGPGTGTPHDAMVNGAGFGQTILSINGALECDGSNPAQVQSRIDAYKRFTSILGVVPGDNLYC\n",
            "Generated Protein: MTKKSFKVKRTSRVRAPALFSTSGGGPSKVKYARGKHKHKHQGAISTSKVKARSGRYWVPAWLININRGRETGTSRGADGAWLRARRARRGYLRTRGINDINDAEGKVKMGRARMGQLSRARATDARASVEDLKVKKAAKVKKVKKVKKVKKVKKVKKVKKVKASDFKVKKVKKGASDFKVKINDAIAWELRGKVRKVRKVR\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   3%|▎         | 88/3111 [01:17<43:12,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MFKPLVKSRSSRSFCTLAGALAMAAATLSSTAQAKSEPPCPEGFTPKAGLNTTFTSDGKKRAFVVVPPKDYAVGAPVWVEMHGTVGATNPNLNVPRSGFYEKLAQSGYMVIEPVRQCAERDPNLGAGACNGVGKDGWTWNWWNDGRAPDASGTKYKTDARDDYRTLKAMVECVGTKLKLDRKRLFLGGWSAGGTMTNRMLLARSEFWAGGMPISGEWYSTGDDGSTVPFATTAKMVAANPAKLWGGRVGPIPLPSKLPPMVPTTGSGGEPDDWDCGPPLGGCSDIRPTAQASANYFKSISNASRVACSAEYGHAWPQVNTDAFNLWALETMASHPKGSSLKDFKLTAPPEGGSCKNARRTDPLK\n",
            "Generated Protein: AQSAQTRLLRTALALLLRTALRLAGNGKYNGKYNPSINASVPAQNGKYALALNGKYVKEADGALAFAYADGSEWVPAEAIAVEKAEAIAEAIAEAITTGTTGADGSEAIAIAIARAIARFVINDIRGASALALATDQLSASINQTYQTNGKYFVRGVTSIATDATDNGKYTTGATGWEGATDAFAYAFAYWRPVRILTREQATAIAKYVGGRALLATDPGSAKTGAKTGVNDAGQATGASINQATGQATGINTREAIAKINQATGINKNTREALALALALALALALALAIAKALALAIAKAIAKAIAKAIAKAIAKNNYAIAKAIAKAQCCTTGTSTTGYYALALINALALYINNNALALRYNKARRLIQADINALALINNKNNTTGYADGKINFNININRGKPY\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   3%|▎         | 89/3111 [01:18<43:22,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MLPAILDAAALEARQLGGSSSRNDLENGAKGSCPKVIFIYARGSTESGNLGTLGPAVASILEAAYGKNGVWIQGVGGAYSATLTENALPRGTSSAAIREMRGYFNLANSKCPDAVIVAGGYSQGAALAAASVTAVDAGIREKIAGAVLFGYTKNLQNRGKIGSYPEDRTKVFCNTGDLVCTGSLIVRAPHLAYQSDASGAAPEFLIQRADAAGAAAAASEHHHHHH\n",
            "Generated Protein: AQSAQTRTTGYLATAQALLLTTGALLLARASNPSARASADGARGTTGARGTRSTFGALLVTTRTSAISTRTSTRTSFTAYTRTSTTGAVALLTTGVPGTTGTTGTTGTTGFTAYAIAVINDAWLTTGWWGTTGTTGQPASTTGALDYQPASQPASQPASRQLLNQSNQSCPWSRGKITTGTTGGGTTGTTGTTGTTGTTGAAGRQAYTTGFNTSQNDFNTSTTGTTGARGINDAKAYAPVSNTAYNSLNRIAKAYNRINRINRIAKAYNRINRIPCPVTTGAPDDWMWVANTTGWMWMWMCPNCSCPY\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   3%|▎         | 90/3111 [01:18<43:18,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MANPYERGPAPTSASLTASSGPFSVSEENVSGLSASGFGGGTIYYPTESGTYGAVAISPGYTGTEASIAWFGPHIASHGFVVITIDTNTTLDQPDSRAEQLDAALNYMTNRASSTVRNRIDSSRLAVMGHSMGGGGTLEAAQQRPDLKAAIPLTPWHLDKNWSSVTVPTLIIGADLDTIAPVATHAKPFYNSLPSSIESAYLELDGATHFAPASGNDVIGKYSVAWLKRFVDNDTRYSQFLCPGPTDGLGGEVEEYRSNCPF\n",
            "Generated Protein: MANPYLVRTPASARASASALAAGGSASADGVDEPCPNPSNYPYPVRTPASAISRQAYYTGWSSYRIRIRIYPTIDGFTAYPSPGQPDSYTGADGFTAYFGQYLRTCPDAEQRRLAVCPDASQPDSTHRQLLVRTPRQLLVRTPVRVPRLAVVRVPGGVRTPWSSVRTPGGVRTPVRTPGGVRTPVRTPHSEFNVRTPVRTPDKWNPQATLAESDTHHSEWVANGGASFGTFGTFGT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   3%|▎         | 91/3111 [01:19<43:18,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MANEYERGPNPTDASLQARSGPFRVSTERDSRGGADGFGGGTIYYPREEGTYGAVAISPGYTGTQASVAWLGPRIASHGFVVITIDTNTTLDQPDSRAAQLNAALDYMIDDASSPVRSRIDSSRLAVMGHSMGGGGTLELASQRPSLKAAIPLTPWHLNKAWSSVRVPTLIIGGERDTIAPVTTHARPFYNSLPTSISKAYLELDGATHFTHTRPNSIIGKYSVAWLKRFLDNDTRYTQFLCPGPSDGLSGNGEEYRSNCPE\n",
            "Generated Protein: MANPQLSAYLLSPGFFALAAGPGELDGFGGVDDPSLECPKFGGGYPYPCAPFGCAPSLPSSSQWSSNGWVANFGGGFNTIDGNGAISNGYTGNGPGPGNPAIAVCPDFGAVRSINDSQVRYSSQLSSQNPNPSSRQLLFGSSNPNPTLEWSSWSSWSSTGDLWSSTLEFAPTGDLTGDLNLDTGDLFNSLPSSSLPSSSLPSSELDG\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   3%|▎         | 92/3111 [01:20<43:16,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MPVDLQERQLTGNDELADGPCKPITFIFARGSTEPGNLGISTGPAVCNRLKSARNGDVACQGVGPRYTADLPTNALPEGTSQAAIAEAQSLFEQAVSKCPDTQIVAGGYSQGTAVMNGAIKRLSADVQDKIKGVVLFGYTRNAQDRGQIANFPKDKVKVYCAVGDLVCLGTLIVLPPHFSYGSDTGDASDFLLSQLR\n",
            "Generated Protein: MFVDLTAAHDVTAFPGCAPGGFLTGNPAFPGAFPGTGISTGSNNTGSNNTGSNNFVCAPFGADGIAGGYTGFGGGTADLTADLQMTADLTGRGHYNRPGAFPGAFPGAFPGAFPGAFPGFVVTVRYTLRQTNTNVTEAGMGTAATAAQLSCAPAYVTSIATSQNRQIANVTATVRQLSQLSQLSHINFPHFSTGDLTGDLQLGTGDLQLGHLTYADGITMHLTYVTEAGWI\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   3%|▎         | 93/3111 [01:21<43:09,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MSELDLWTDATAQAELVRSGEVSPTELLEATIARVEAVNPEINAVISPLFEKARRESELASGPFAGVPFLLKDLTVVSAGDLVTNSNKFMARSGYRADHDAAFVERLRAAGFVLLGKTNTPEMGLTVTTEPLAFGATRNPWNLERVPGGSSGGSGAAVAAALSPVAHGNDGAGSVRIPASYCGVVGLKPTRGRISHGPRMTDSDNVALFAHEGPLARSVRDIAALLDVVSGPRPGDTFCAPTASRPYAQAISENPGSLRVGVLTHNPVGDFAVDPECAAAAEGAAAALAALGHDVHDGAPEFLGDPSFLKNYLTIQAVAIAWEIERLEELIGRPLTLDDVEWLSWEMVKRAGAVTGAEFAAAVDELDYAAGKVSRWFEAGYDLLLTPTVTRQTPEIGELNLAKTTDLTGDYGALISNALPGLAFTVPFNVSGQPAISLPIGMSSDGMPIGVQVVAAYGREDLLLQVAAQLEQALPWAARRPQLLNPSRLIPAE\n",
            "Generated Protein: MNTLERPDPATAQAELVRAELVRTLDSTLDSTLDSVTEAGPPVTEAGVTEAGVTEAGLLPTHAIVAERLFVTGFGHAWVTEAGVTEAGVTEAGKDLDLEQDLEQTLDSTFPFAELADYHDVAERLHAIHDHAIAGGFVADAAGVTEAGVRYVRYVTEAGHDVTEAGVAERLRNPIYDVAERLVTEAGTLDSTFPASEVTEAGVAERLAAVAAVAERLTLERALDAVTLDSRSAGVTEAGHAWAEVTEAGVTEAGVTEAGVTEAGVTEAGVTEAGVTEAGVTEAGVTEAGVTEAGVTEAGPGDPPGDPVTEAGVTEAGVTEAGVTEAGVTEAGVTEAGVTEAGVTEAGVTEAGVTEAGVTEAGVAERLTGFGVAERLGGRVGRMVAERLVAERLVAERLGGRGGRGGRVAERLGGRVAERLGGRDEIDEIVAERLDEIVTEAGTEDDVTEAGVTEAGVTEAGALDAVALDAVALDAVVTEAG\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   3%|▎         | 94/3111 [01:22<43:21,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MFRPVVKSRSSRSSCALAGCLAMVAATGSSTAQAGSEPACPEGFTPKAGLNTDIFVDGKKRNFVVVPPKAYAKGAPVWVHMHGTGPATNWNLNDPLSGMFAKLAEHGYAVISPFRQCNEQDPNDGAGACNGVGKDGWLWNWWNDGRAPDASGVKIKTDRSDDVRFLEAMVRCVGTKWKLDRKRAFLGGISAGGYMTNRALLSDSERWAGGMPISGEWYSVKQDGSTVPFTERRKNNDVAPAKIWQGKVGPYPLPSKLDPMVVITVDGGEKDLWDCGLPYGLCTDYRPTTQASSNIFASISNKVQVACSATLGHMGPQENTDAFNLWAASTMAAHPKGSSPKDFKLTAPPEGYSCKIGRFTDPSK\n",
            "Generated Protein: SEDVPKDQDVVPPPAATLDSTLDSAEPPPDPVVVVTVGSAETDEENLNLVVKDLHAWTIEEEPHYIMHYNSDGTNQDHAITLEEIMQPIWIWVRYVRYRTIWHEIFDVVPPDGATSQQTRTVFSGDPPQRGGPDGVTNRAEIVRPPPPAWPPGGPVVHAWVVHAWVPVVVPAWPPIWQLPIWHAAAKTTIDTTIDAENLTNARREAWNLAKPPTCNLIWTAAQTRYIWVVGGRVVTCHAWHAWHAWHAWTSRTLRTLHYHYNLTSKDITYTSVVKEDL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   3%|▎         | 95/3111 [01:23<43:21,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MSVTTPRRRTSLLSRALRATAAAATAVVATLALAAPAQAAEGYERGPAPTESALEARSGPFSVSWESASRIIADGFGGGTIYYPTEPGTYGAIAISPGYTGKQSSIAWLGPMIASHGFVVIAIDTNTRLDQPDSRARQLSAALDYMLTDASSAVRNRVDASRLAVMGHSMGGGGTLRLAHQRPDLKAAIPLTPWNLNKSWPDIRVPTLIIGAENDTVASVTLHSKPFYNSIPSSLDKAYLELRGASHFAPNGTNSTIGQYSVAWLKRFVDEDTRYTQFLCPEARTGLESNVNEYRSTCPQ\n",
            "Generated Protein: MRRTLPDPNSPDPRDGSRFSAAAAFIFDGKDSRTNSRNSFIYTNGSSRSRKDVWKDTNTNSRNRMGTNTNNSAYQDTNAGGTNTNSRTNSRTNTNSRDQPMGGMGGMGGDGMGYTKNRNRKTDYNRSRDYQRMGGHISRKTNRDYTNTSKTALYGATTHTSTNKDSRNSNSAYRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   3%|▎         | 96/3111 [01:24<43:20,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MNTTRSIALTDAPGLIAVDPAPLLAGPRVFGGPGNDAADLAADRSTGREVLRFDFPGVSIGAAPYEEGLTGATVIHIPAGARTAVDARGGAVGLSGGYDFIHAILLAGGSGYGLAAGAGVRDALRERGGWRTGFAELPLVSSAVIYDFSASSTAVYPDPALGRAALEAAVPGDFPCGRRGAGTGASAGKVILARTTRGGQGGAFRRIGDVRILAVVVVNPVGAIVDRAGTVVRGNYDAETGVRRHPVLDPRPDRAEQVPPLTEAGNTTIAAIVTNVRMSPVELNQFAHQVHDAMVRGIRPFHTDGDGDTLFAVTTDEITLPGTPGCSADRLSVVATALGAIASEVVWDAILNATK\n",
            "Generated Protein: MRRRRVHIDGGATAQPAAEPEPASEATGGPGPDPEPKDPDPAGGPAVPAVPVVTSAEPVVPTGPTGKDLKDLKDLKDLDSFEKTPAAADYADYPDYRRRRRRDYARVRYVRYDYQPTEPEDYDYRSRSAGGRSDYRVHAAVAADYAAVAARAVRAVDYPAARAIEPKDLKPSKPSFRELGDFRATATFRTTVDAKFAAEPRVTRREPRVTPGDPDDPRRVTEPATMVHEPTTVDPAAEIDRRRARARRVHRRGGRRVHGGRGGRGGREIRAIDLPRAVDEIDLPSSDLPRRRTAVSGTEDDTEDDMDRSAVSGTEDDQPTVIAIGITEDDARDYPDPPDPDDSSASEPDPAKWDQPQPQPMSSARREDPAVDE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   3%|▎         | 97/3111 [01:24<43:23,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MRSLRLLGAASAAAVALTLAGSASASAGPQPLIVGGSTAPTVSWIAQVYVTTPGSGGGGFNCSGSVISSRWVLTAAHCLDQDGSGMTVRVGSNTLNSGTKIAVDQHYISPGGDIALLHLASATSASPISLGSSDPAVGSTGQIYGWGRTTPTGGPSTSLKVANVRVTGRSTDPYGGRAIQSVGVNGSAWHGDSGGPEVANGVQVGVASTVQNQCGSNTRGTNNYASVAARRSWIRSTSGV\n",
            "Generated Protein: MRGGDYINRYILAIGVFIFASECGSEVSEEPSVEGGPHCGVIINFKEFKEFKEGGDSFRTFKETLVNTLVNHVYHCGTLSVTLVNKTITKTITKTITKTITYAVYAVIISYIVNYAVATLVRYVRYTLRQYAVVRYAVGTAVGTIKNLMGYIYDMGGYIYDCGSEYIYDYIYDCGSECGSEDIITLVNTLSVGGDSRAIRAIRAIDIIGGDSGGDSRVNGGDSGGDSGGDSAGGGGPILSGYTITLPNDAPYASTLVNYASYVGAAIFGGDSTLVNDAPKEYETRYS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   3%|▎         | 98/3111 [01:25<43:16,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MTSKRLLGAASAAAVALTLAGGGVASAGVQPNIVGGSTAPTTSWIAQVYVNTPGYDSQSFSCSGTVISSRWVLTAKHCLDDDGSGMTVRVGSNTLTSGTQIAVDGEYESPNGDVALLHLASAASAAPISLGSSDPATGSTVQIYGWGRTTPTGPPATTLKTANVKVTGRSTDANGGRAIQTVGTNGGAWKGDSGGPEVRNGVQVGVASTVDGQSGSNTGGTNTYASVAASRSWIRQTAGV\n",
            "Generated Protein: MTNVLLSAVLSVFIFVLSLMLVFVPASEFSVNFIFARGEASGHCGFKETIYFKEASGAGFVNGILSYTGHVYREPGTLVNCTKCTKDLPSTSGGYAVATLYAVMGATLAALAALYAVLLGILQGILNLAVGTFVVAVGTMGATLIFDYTRYTKFISGACCAPYHPMGGMGGMGGAVGVRPAVGMGGVNGSVNGSVAPGRPEAYGVANGFYNILSVVSILSGILSGYTITLFAAWIWISWISYGS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   3%|▎         | 99/3111 [01:26<43:23,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MTASTTRARPSARRLGLRHATVGVATAGLVAASFTAGSASAATGPVAGSTGVSASAAASDGTGANSPVSEAQFNQMFPNANPFYTYQGLVDALSAFPGFANTGDDTTKKQEVAAFLAQVNHETGGLQYVVEQNRANGPAYCQWSQPYGCPAGQAAYYGRGPIQLSWNFNYKAAGDAIGVDLLNNPALVANDPAIAWKTSLWYWNTQSGGGTATPHDVMVNHAGFGQTIRSINGSLECDGSNPAQVQSRVDAYLRFTSILGVTPGDNLYC\n",
            "Generated Protein: YDVRTAALAAAATAALTLIIVQAAAAAAAAAAARTLIIDQPARTNGFRGGFRGGFRGGCRPPEARGSFIYVGPFRGGFRGGYPRSFRGGYPRSHGFVVQAADQPDQPDQPATLGDSRGTQIVTQIVAAAADQPAGTLIIDQPAGDQPDQPDQPAALDQPDQPPVRPVRMGGPVRMGGYTKYTKDLVMGGIIGRPDLNFPRPDLWNLLLGTLIITLIIAPHLTLIITYGTYGPAPEFYETLASGIPSSIPSSPE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   3%|▎         | 100/3111 [01:27<43:24,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MTKSSLPQGMANSRLLRHYTAALCSLLLLLLLPGAVTAGQWFSYTSPQQAYSGSRQRSYKVYVPDGLSTPAPMVMALHGCRQTNDDVLNDLGLKAAADRYGFILVAPTITSQDNLRNENCWGFWEEQHIHRGGGEVADLHGIIQDVEADFNIDANRRFVTGLSSGGAMALVAAVAYPEFFAAAAPAAGLPYRETASSVSGSGSCAGDRNSRSVSQVAADMRSEVNDAYPMPLMILQNRNDCTVLPTAANNMRDAHLQVFGSASRNTVVTTNASDSRCSPYGQNLYGCRHEAYTQDGTTATGSLVETVFYDGPLATPNPAPPGTGHTWPGGAQGNNGGFTLGLGPSYPDIIWDFFSRFSRDGSQAQGTPVIVLQGDNPLSVPLGSTFNDPGASASDAEDGSLPVSADCSAVNPSVVGSYSCQYSATDSDGNRSTATRTVQVTDPNAPVPSCQVVSASNSSHIMAGRAYFGGTSNLRAYAKDDGVWIGQSFDTASNVPLYETPPGRWYAQRPAACGGAGQAFTCQAVNASALSDVGAGRAYYGYYTVGGNQYLGSLSGLSVPVRETAQGHWQAYRCSN\n",
            "Generated Protein: MNVPTAALTAALTAALMTTSAGAGAVGGQAQAVGGAVGGVPVHGAAVSVNGGTAALAGPEPEFPNGIPVMAPVSSLALHGAGHGQQAGAGAGPEAGPEVPPEPEHGAGPEAGQPNGPEAGAGTQVTNSAALGSGSSFPNGVTNSAGAGVPAGFPNGAGPEVNGSAGAGTAALAGVFNLVFNLVFNLYPVFVPVPMTKQVPVPVPVPVPPEVPAGIPHGAGPEAPDQVPFPNGVPFPNGPEPEPEAAAAPEVDPELLGAGIGPTASVPAGAGQPNGYPVFKSRGAGKSRGQPNGKSRGPEAGAGKSRGKSRGSGIHGAGFPNGAGGLSGQPNGHGPEFPNGGLSGGLSGPEAGAGKSRGNGLSGGLSGGLSGAGPEGLSGVGSPEAGKSRGPEPEPEGLSGPEAFDENAPAFDEAFDEPESKPEAGAFDEAFDEPEAGAG\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   3%|▎         | 101/3111 [01:28<43:48,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MSDAVWSRDGLDWPHREASRFIEAGGFRWHVQTMGSPAAPAILLIHGTGASSHSWRGLAPLLSRHYHVVAPDLPGHGFTQTPRGADMAMPGMASDLAALLRVLEVAPQLVVGHSAGAAILARMCLDGSIAPKALISLNGAFLPFGGPAASFFSPLAKMLAMNPFVPSLFAWQAGGRGAVERLIGGTGSTIDPQGIALYRRLLSSPNHVAAALSMMANWDLEPLLKALPNLKPRLHLVAAEADRAIPLSVADKVREAIPAAEIERIPALGHLAHEEDPALIAALIETYAEKLGTIE\n",
            "Generated Protein: MSDLMNLLGLLGVQVQTGVQVQVKVQQQVHGVHGVHGVHGVQFSVQVDVDQSAQVNAVLLDLPGAQHGHGAQVMHGAQVQVDVDHGVDVDHGHSDGSVNLLGADHSHSVHGVHGVHGQSAQDGADVQVHGVPFVPVQVQAWVQVQVDVDVDFLVQWVQVHGVQVQKSVQMPRSRSWDLQLPQSAQVQTQQSAQVQAEILAPTLVDVDDRLLGQSAQTQFLVDQSAQRSQSAQVLDGVQRSVQFL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   3%|▎         | 102/3111 [01:29<43:42,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MMVGAFGGAVFAAATLIAFGAVVHASGAVAETAPASGAAVPADQLDGETLYKARCAACHDNAEGRTPSREVLSKRPASGILASMRTGAMVPIAEGLTLEELRAIARYVGVADAKTDDGIDLRRIWGNPVEGTPLPAPQCSSAKTPVDLGAAGQWNGWSTERDNGRFQPKPALARADVPKLKLKWAFAYPGSKNGQATVIGDRLFTTSFSGAVYALNAKTGCVYWRHAAEGALRTSPVIAALPSGAPAKTALFFGDFKKAAYALDAETGKQLWKTKVDDHPAVQMTGSIRYYDGKIYVPISSGEEAFATDPTYECCKFRGALVALDAATGKILWKRYTTEQEPRPIKLNKAGTQMWGPSGGAIWNTPTVDEARRLIYVGTSNAYTDTPYENSDSVMAMDLDTGATRWTSQLLANDNYISGCKQLGKEHANCPEPLGPDFDIGAAPVYRKGADGKEVLLVGQKSGMIYALDPDNKGAKVWERRLSHGSALGGIEFGTAADDGKVYAAVSDHASQAKDPGKPGLWALDIRTGKVAWNFLTAPDTKCRAGNWMCDGASSQAISVIPGAIFAGSYDGHFRAFDTATGKIIYDYDTSTKPVTTVSGAKAKGGSMDGAGPTIAGGMVYVNSGYAGRSSLSGGRDLRGTDGNVLMAFSVDGK\n",
            "Generated Protein: MNTAALRSSIDGGTAALANGGMNGSGSCSGANGGARGEANGGKAGLKAGLANGGTGSPGLTGGLIGCSGSCSGAPTGTLQQCRQANGGVDARVDARNKAGLANGGANGGQAVSKVEHGPNGANGGANGGNTNSANGGANGGNTNSDGSANGGANGGANGGANGGANGGNANGGAGSNANGGANGGANGGANGGANGGANGGANGGANGGANGGDSGGDSGGDSGGDSGGTGSEDSGGANGGANGGANGGSTCSGSTGSANGGTVASANGGPKSTANGGANGGDGSTANGGANGGANGGANGGANGGGLTGANGGANGGKRANGGTGSPTGSPANGGANGGNANGGANGGTGSPANGGANGGANGGANGGANGGANGGANGGQSDSYPVFANGGSTANGGANGGNANGGRSNGTSAGNRSNGANGGANGGSTANGGGLWANGGANGGANGG\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   3%|▎         | 103/3111 [01:30<44:15,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MQFKSTFAALVLAAAGLVQAAPLQERASCSSYVIINTRGTLEPQGPSVGFVTMNTRILSAVSGGSEYDTVYPAGIDQNSAQGTADIVAAVKAALAQNPNQCFLLQGYSQGAAATVNALPQLTGAAFNAVKGVILIGNPEHKPNLSCNVDSNGGKTTKSARGLSAAFTQGVPSNWVSKTLDICIKGDGVCDVSGGLGITPQHLTYGQNTQVQTMGANFAIKALQG\n",
            "Generated Protein: MVRNVQGTAALRSSALVIALVIALVITGCSSAQPNTTQGSTAPTSEPAQVYAQVYMVHGGLIGNFASSSSNCSGTGQLGGQLGSRSVSRNNVANSRNNTGRNNAGSNGLSNVAASVANSVANSVANSASSVANSRNNNTNSANGGNTNSSSDPTIGGSSDPHKPNNKTTNQNNPLASLVYSSVYSSVYSSNFGNFGNFGNVLNWDSGGDSGGHNQDSGGTGVASTGSSDPSSDPVAASNQ\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   3%|▎         | 104/3111 [01:31<43:49,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MSKVDLSQDATAQAELVRSGEISATELLEATIAAVEAVNPEINAVITPLFEKARREPELASGPFAGVPYLLKDLTVSSKGDPLTSSNPWMFESGYRADHDAYLVSRMRAAGFVLLGKTNTPEYGLRVTTESVAWGATRNPWNLDRSVGGSSGGSGAAVAAGLSPVAHGNDAAGSVRIPASVCGVVGLKPTRGRISRGPLVTDWFNYAQHATEGPLARSVRDTAALLDVVSGHRPGDTFMAPEPSRPYAQAISENPGRLRVGVLTENPVGDFALDPECAEAAEEAAAALADLGHDVNDAYPEALGDRSFLDTYLTISDVAIARDLERNGELIGRPLTEDDVEWTSWEMVKRADGVTGRDFAAAVDKLQYYAGKVARWWEAGWDLLILPTVSRQVPEIGELDLSKGTDLEDDMEANISGSLRRLAFTVPFNVSGQPAISLPAGMSSDGLPIGVQLVAAYGREDLLLQVAAQLEHALPWADRRPQLPNPSRRIPAA\n",
            "Generated Protein: MNTTPAAAALAAAALAAAALRAALPMPMARPMDLVLSTAPSTAAVSAAVSDSASAAVSAAVSAAVSSTVSIGAPLGDLVLPTGSTTVASRGGRGGARCRGGRGGAGSSTRPDMSVSHLASPMMSVSAGAGHLASMSVSALPPRGGIYDAGSIYDAALGIYDPMFSARAAVAACPAGAALEFPVGPMRSTDRAGPMFNRGGALPPPMAALGPMPMPMPMPMVVVVNPVGDGSRAGAATGPMPMTVVELARALPPPMAAAALSTSTAAAALAIVTAIVTNTTPVELNTTPVELPVELAAAALAAAALAALGAAAALAALGPMAAAALPMAAAALAALGAATGRAWSTTLPRHEAFFNAATGAATGRAWAATGVVSGPMAAAALFNRAWWLDPPRAAVSAAVSFN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   3%|▎         | 105/3111 [01:31<43:52,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MKEYPNLYIGGQWVSAHSDNTSTVINPSTEEPIAKIASGDVADVDAAVRAAREAFDSFSQSSRESRVKLLRDVAAGIQSRADEFAEAIAQEMGAPLWMAQQAQVPAGIAHFATAADVLEKFKSVEAKGTTVLRREAVGVCALITPWNWPLHLVACKIAAALAVGCTVVLKPAEQTPLSSILLAEVIDAAGAPKGVFNLVTGSGSVVGSALSSHPEVDMVSFTGSTRAGAAVAKAAAPSIKRVSLELGGKSPNLVLPDADLQESVRRAVRSAFSNAGQACSAGSRLLVPADILEEAIAIAKQTAESIPVGLPADADAPAIGPIITQRQYEQVKKYIGKGIDEGATLVTGGVEVPSGFPKGFFVKPTIFANVTNAMAIAQEEIFGPVLAIIAYETVDQAVQIANDSDYGLSGYVLGPAEQAVEVASRIRTGQVFINGAGADFNAPFGGFKQSGNGRELGEFGFEEFLEF\n",
            "Generated Protein: MPVITPQGDWMAAIAVCSSPVAAQQTAPTVASTAQTVASADVDADVDAAVSVVVGTVASVSIGFNTPAPTPAPTPAPQQAPEGQQQQAPEGTVASTVASAPLIVVDSVPAGDSQALQALDSPKLTPQGITLDGSDGSDGSDSWNQVEDSKKSEQVESPQVEELSIVVQVEWNVLPVLPWNKNLAWIVDIVDIVDWNWNDGSVIAMTVASVLPTVASWDLWDLKNLTVASFYKNLKNLTRKNLMMKNLKNLIFDGSCSTRFYKRTRTRTVASDIVLPIGPQSPQIGPALSDCSPPYTRPYNLQDTTPGTIPHAATGTRRAWFYTTPGASSDSTVASAADTRASSTRWNWNTRIFRAWDGTTWNTRRALAFDECPEVSADRLTRMMTVASFTFNFTEVASTVASCPEFTFTFTPYFTAFDEDSNAPQKADSKDSAFDEQKADFTHPAFDEGLWIGPPYDIIGAGTRIGPRWTRPYGLWIGPTRHPAAVSGLWEVASTRWNMIGEMIGEAFDEMIGEMIGEMIGEMIGE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   3%|▎         | 106/3111 [01:32<43:50,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MINVLTKCKLALGIIAIFFSLPSFAVKCSSCSNGFERGPDPSVDQLESSRGPYSVKTINVSRGARGFGGGTIYYSTESGSQQGVIAVVPGYVSSESSISWWGPRLASWGFVVITIDTNTIYDQPDSRASQLSAAIDYVVSKGNDRSSPIYGLVDRNRVGVIGWSMGGGGSLLAATDRTIDAVIPLAPWYLGLSRFSSLSSPTLIIAGQADVVAPVSVHANRFYNQIPDTTPKAYYEIAGGSHFCANTGGPSRDILGRIGVAWMKRFIDNDERYTQFLCGQNFDSSYRVSEYRNNCSYR\n",
            "Generated Protein: YDVRSLRKKLNPTDLLASLLASAAVAAPSVEVIIPDPIPDPIPDPYPYPYPRGALEALEALEALEAARVSKVDTPAPAVLLFTQTVASFTQIVVIVVYTADRLGITLPKLAYQSPKLPKLPKLHLASPKLVLVIRASITLITLALEALEALEAVRALEALECPAGWHLWHLYTADIVVCPAGRLAAIAPWNLIAPKASAYQSIVDIVDIAPIAPIAPFYFYDGFSFYASSRYDWDLFYKRVAAFYKRVELCPKLVELRLWLKLKRVAWLKRKRYGVSRSSKRVNDPIAALQFLALSDCGCGRYDCGCGCQNC\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   3%|▎         | 107/3111 [01:33<43:35,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MTSLRLLAAASAAAVALTLAGGATASAGVQPNIVGGSTAPSTSWIAQVYVNDPGRDYDGFSCSGTVIASRWVLTAAHCLDRDGSGMYVRVGSNSLGSGTKIAVDREYEHPNGDIALLHLASATSATPITLGSSDPAVGSTVQIYGWGRTTPTGPPATSLKTANVQVTGRSTDAYGGRVIQSKGTNGSAWLGDSGGPYVAGGVQVGVASTVQNQSGSACRGTNTYASVAANRSWIRSVAGV\n",
            "Generated Protein: YDVRSLRGGPLVAKKIERDGRDGTQVQPSASEPSSTAPYQISTGDLDSIPQGDGPSPSCSGNDYGLLSPSIEYNDGSGVRVGDGSGVRVGVRVGPSDLQGVAKKIEPSPSAVDHLASSLGSPSDGSGPSVSVGVSVGPSVIDLPSPSIEIEADLRYLVAKKVAKKPSASEVAKKVAKKVAKKVAKKPGSKIEDIVQVGPGSKTYIEQGTQVQPSIYYASYASDLIEVPSIYVPSVPSVAKKPSYGSQKIDREEVAKKVAKKVAKKVMLELLVPVMLEVMLE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   3%|▎         | 108/3111 [01:34<43:20,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MRMSRVVGAIGAAAAALSLVSAPVASAQPDIIGGTTVSSAPWAAQIYWDNGTTYGGFECSGTLIAPQWVLTARHCLNSPPMNVKVGNVALDGGTSAQVDYWVASPTGDIALLHLTTAVDTPYIKLGTGNPTIGATNQIYGWGRTQPSGPPSSTLKTANVRVTGLSTDADGGRAIASQVINGSAWHGDSGGPQLYNGAQVGVNSTGSDSGSNTQGTQNYASVASSRDWIRSTAGV\n",
            "Generated Protein: MSPLKKSFKKSKQDHDASEREEAEAHFSVNKEGGPLPGSKISPITPLPEGIGARSLGEQGKLARRESRNDYGYKVYCLYLGIKDLSYKVYDGSGDGSGVRVGVRVGDGSGDLQGDGLLTNYESPQKIDYSQGYESPYSQGQFYQFYSSDPPSQVSVGTYQIYGDLQGDGQGASAALYPARYPARYTSSSYEYPARGGPLGGPLGIGGPLGGPLFGVKFGVKGGPLKDVQPGSKQGDGNGSGTYTYTYYASDSIPKDVQYASFFQSFGSIPSIYYGAMSLG\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   4%|▎         | 109/3111 [01:35<43:11,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MMNVLTKCKLILGIIAIFLSLPSIADPASDCSNGFERGGDPSVDSLESSRGPYSVKTINVSLLDRGFGGGTIYYSTESRTTRGVIAIVPGYVSWEPSIAWWGPRLASWGFVVITIDTNTIYDQPDSRASQLSAAIDEVIDEGNDRSSPIYGLVDPNRVGVSGWSMGGGGSLIVARDRRIDAAIPMAPWYLGLSSFSSITVPTMIIACQADTVANVSTHASRFYSSIPGTTPKAYFEVANGSHFCANTGYPSRDIIGRAGVAWMKRFIDNDERYTQFLCGQNFDSSLRVSEYRDNCSDF\n",
            "Generated Protein: MNYPNLRESRRESRLLSASRFSGNGSLPSYQRGVIYQRGFGGGFGGGTIYFGGGYKVDGLFNRESRVITINYSNNSGPSEFGGGFGGGTIYTIYTIYYKVYYTADYTADYTADYTADYTADWWGFESSTSSYSFESSTIYDIDTNTIFDTIYDTIYDNGTIYDYTRSSPSSSPSAYSSPSSSPSPSYSLERLGSLERLRLGYTADYTADSLPSFNTSSEVDLLSSGNGAEADSGNGSGNGHLQSDTIYDAYAEADYQRGNPQSDTIYDDSDYSLPSSLPSCANYLHFYSSEVDYSYGVSSDKIDVIYTQSSPSGGQFL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   4%|▎         | 110/3111 [01:36<43:10,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MRMSRAVVAIGAAAAALSLVSAGVADAQPGIIGGTTVPSAPWAAQIYWDNGDGGGGFMCSGTLIAPQWVLTARHCLGSPPMTVKVGNVQLQGGQSADVDYYKLSPTGDIALLHLTTAVSTTPMKLGTGNPPVGATNQIYGWGRTQESSPPSSTLKTANVRVTGTSTDAAGGRVIASQGINGSAWHGDSGGPQMYNGAVVGVTSTGSSSGSNTQGTQNYASVASYRDWIRSTAGV\n",
            "Generated Protein: MNAYAILLSSLGSLGRGCLTTSPTTTTNGYQSLGREFVSLGRLQGLLSRGEGLLSVLVLAVDADADAIRLSSLGANAQAQANFVAVDRGRSAVDADSLGSLGSLGWGQRWGAYWGANHLTTANRGAVGRGANRGANSLGHLRGAQAYHLADHLHLTYHLANANRSANANRGRS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   4%|▎         | 111/3111 [01:37<43:00,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MSVETPRRAASLLSLAVAVAAAAAATVALAAPAQAANPYERGPAPTESSLGASSGPFSVSLERASRLGADGFGGGTIYYPRRRGTWGAIAISPGYTATQSSIAWFGPHIASHGFVVITIDTNTGLDQPDSRAVQLEAALDYLLTDASSSVRNRVDASRLAVMGHSMGGGGTLRAASDRPDLKAAIPLTPWNANKSWTDITTPTMVIGADGDTIAPVSSHSEPFYNSIPSSTDKAYLELRNATHFAPNQTNRTIGMYSIAWLKRFVDEDTRYEQFLCPEPRTGLLSTVDEYRSTCPF\n",
            "Generated Protein: AAPCADAQQRAIFGGGDYTTTTAQAQTTTTISTGRLSAISRGVAGTNAAPAIGYKQNHSAQTTTTVAGHSTTTTAQTTITVPQLSVAGSLGTTTSSAVGTTSDAPAAPQLSHSAQAPSGPAVGRGLLAATTTTVAAGTTAAPRGTTAQISTGAWLTTVGGTTTTEEMFSGPRGAITT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   4%|▎         | 112/3111 [01:38<43:11,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MTKLSLPFRMADQNLPRFFTAALLSLSMLLLVPSTVTAGQTFSYTSPQQAYSGSRERSYKVYVPDGLSTPAPMVMALHGCRQTNDDVLNDWGLKAAADRYGFILVAPFITSYLGQRNNNCWGWWKEQHIHQGSGEVADLHNIADQVEANFVIDANRRYYTGLSSGGAMALAAAVAYPEYWAAAASAAGLPYRSTASSVSTMGQCLGGATFRSVSQVTADMRSTGNDAYPIPLMIAQNRNDCTVLPTAANNLRDASLQVHNSASAATPATTKASDTGCSPLSQNDYGCRRIAYTQQGTTATRSVVETVIYDGPLQTPNPQPTNHGHYWPGGAQGNNGKWSRQVGPSYPDIIWDFFSRHSRDGSQPGGAPVISLQGNNPLSVPLGSTFNDPGASASDAEDGSLPVSADCSAVNPSVVGSYSILYSATDSDGNRSTATRTVHVTDPNAPVPTCQVVSISNLAHILAGRAYAGSTSPLRAYAKDDGVFIGGSFWLASNVWLYEGENGRWYAQRPAACGGSGQAGTCQEINASQGSHVGAGRAYAGPTTVGGNQYLGSTSGGGTWVRETAQGHWQAGTCSN\n",
            "Generated Protein: MKEYIGGYIGGCLYLCLYLCLYLREASCLYLCLYLCLYLCLYLAKIAKIAKICLYLINAMCLYLCLYLCLYLCLYLISIPCLYLCLYLCLYLCLYLCLYLCLYLINAMINAMINAMINAMCLYLTNDDINAMCLYLINAMINAMINAMINAMINAMINAMINAMTQTTINAMINAMCLYLINAMCLYLCLYLEEINAMCLYLCLYLCLYLCLYLCLYLCLYLADVPCLYLTQTQINAMINAMINAMINAMTQTTCLYLCLYLCLYLSGSNVEVPCLYLCLYLCLYLINAMCLYLCLYLINAMINAMINAMTQTQVDANINAMCLYLINAMINAMINAMCLYLINAMCLYLAGSRTQTTAGSRWFCAGSRAGSRVEVPAGSRINAMTQTTEEVLAGINAMVMAGTQTQCLYLADAFTQTQWPQWPQWPQTSTATTQTTWFCCLYLSGAFKGFFTQTQKGFFKGFFKGAQWDFWDFWFCKGAQINAMWFCKGAQWFCDSDYSGAFDSDYWFCKGAQVEVPVLRPVLRPVLRPVLRPWFCVLRPWPQVLRPSGNGWFCTSTATSGNGREITAYLLAGKGAQTQTQKGAQKGAQKGAQITAYKGAQKGAQTQTQWFCKGAQKGAQKGAQKGAQSGAFKGAQKGAQKGAQKGAQKGAQKGAQ\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   4%|▎         | 113/3111 [01:38<43:34,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MKNQLTNSKLALGIVAIFFSLPSFAVPCSDCSNGYERGPVPTLDQLESSDGPYSVKTINVSTGARGFGGGTIHYPTSSGGEKGIIAVVPGYVGRESSIKWWGPRLASYGFVVITIDTNTIYDQPDSRASQLSDAIDYVIDKANDRSSPIYGKVDPNRVGVSGWSMGGGGSLKAATDPRIDAVIPLAPYQPGLSNFSSITSPTMIIACQNDVVAPVSVHARRFYNDIPGTTPKAYYEIALGSHFCANTGNPSQDILGRIGVAWMKRFLDKDERYTQFLCGQNFDSSLPVSEYRDNCSYY\n",
            "Generated Protein: MINTTTPYIGGLLPLAELVRDNIIAIVAAGASRFVSGSVGGGSAPWAPWAPWAILLCQTYSVKIIACWSPFAVVSGSAIAIVSGSAPVWVSGSTQTSITIDITIDKMAGIIAVITIDWWGATLGEMAWLASWGASWGVDANFWGASWGVDANIDPNITIDQPDSAAIDAVMGVDANFWGPIYGAPWAVAGVGGGSVGGGSAPWWSVDANIDAVGGAPWIDAVVGGGSAPWAPWVDANFNIFVSAPVDANVEVPAAAAAGIIACITIDVEVPIIACASRFVAGVAGVAWLVAWLNDIEVDANCANCANVEISAEADVGGGSTTTPASWGVAWLVAWLNCFLCGNCFLCG\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   4%|▎         | 114/3111 [01:39<43:28,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MQFKSTFAATVLAAAGLVQAAPLEERQGCSSYVIISTRGTGEPQGPSVGFRTMNTRILSAVSGGSSYDTVYPAGIDQNSAQGTADIVAQVNAQLAANPNQCFVLEGYSQGAAATTNALPQLTGAAFNAVKGVILIGNPEHKPNLACNVDKNGGKTTFSARGISALFTQGVPSNWVSKTLDICIYGDGVCDVSGGFGITPQHLTYGKNTNVQTMGANFGIKALQG\n",
            "Generated Protein: MKKMSRVSAAAVVSDWDWITPQCSSTAGVSNPEIGGTRGMVHGGSVSVSVSVSDWWDGTGGSTPAGAQGTAQGTAQGTNWTNNWNWNWNWVSVIGGVIGGVSVSVSQNIPVSQNIPQNIPIADIPAAITPQKTTVSQPKTTKTTITPQVSKTTTGGVSVSNWVSQIGGQNIPVSITPQITPQITPQITPQGGITPQ\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   4%|▎         | 115/3111 [01:40<43:13,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: AQSVPWGISRVQAPAAHARGLTGSGVKVAVLDTGISTHPDLNIRGGASFVPGENSYQDGNGHGTHVAGTIAAKNNSIGVVGVAPSADLYAVKVLGADGSGAISSIAQGLEWAADNGMHVANLSLGSPSPSSTLEQAVNYAWSRGVLVVAASGNSGASSISYPARYANALAVGATDQNNNRASFSQYGAGLDIVAPGVSVLSTYPGSTYASLNGTSMATPHVAGVAALVKQKNPSWSNVQIRNQLRNTATSLGSTNQYGSGLVNAEAATR\n",
            "Generated Protein: MKSVTAGHQDAAAVPHRDGPTGTAGVTGHCGHCGQWRWVTGTPGSSNVTNQWCSGQWQWHCGVTGHCGNYTNTNTNNVTNFGGTNNQTNQNQTNWNQTFWTNTNSSPIPTGWGSSWGNGPNPPQWVTGVTGVTGVTGVTGVTGVTGVTGVTGVTGVTGKPVTGFWSNQWWEMDNVVAGPHTNVAGVAGTAGTAGTAGTNVTGNVSVVTG\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   4%|▎         | 116/3111 [01:41<43:05,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MSVVTPRRTRSLLSRAVAVAAAAAATVALAAPAQAANPYERGPEPTESTLAARRGPFSVSEVRASRLGASGFGGGTIYYPRERGTYGAIAISPGYTGTQSSMAWLGPHIASHGFVVITIDTNTTLDQPDARARQLSAALEYMLTDASSPVRNRIDASRLAVMGHSMGGGGTLEAATQRPDLKAAIPLTPWNTNKSWRDITVPTLIIGADDDTIAPVSSHSRPFYNSIPSSTDKAYVELNNATHFAPNITNTTFGKYSVAWLKRFVDEDTRYDQFLCPSPRTGLRSDVGEYRSTCPR\n",
            "Generated Protein: MTMSRRRRRPRPRPRAAPAAPARAAPERAAPTNPAVPAVSSPRAISDVPFERTNRASNYHGTNTNTNTNTSSTNQPDSTSSTSSTNTSSFQQTNHGTNRLAVTNPRNRQRNRQRNRPGGIPLIPLQRQAASSQRPIQRPPQRRRKPAAPAAPQRASDFPRNGTNPRTNTNIIGIIGIPSSPRPRPRPRRTPRPRPRTNPRRYILGNCNCPRTNNCNC\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   4%|▍         | 117/3111 [01:42<43:05,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MSDLVWSRDGEDWPHREASRFIEAGGVRWHVQEMGDPAAPAILLIHGTGAASHSWRGLAPLLARHYHVVAPDLPGHGFTQTPQGHRMSLPGMASDLAALLRVLQVKPQLVVGHSAGAAILARMCLDGSIDPKALVSLNGALLPFGGPAASFFSPLAKMLAMNPFTPSLFAWQAGRRGAVERLIGNTGSTIDPAGIDLYGKLVRSPNHVAAALRMMANWDLEPLLKALPALPPKLVLVAAEGDRVIPPSVADKVSEILPHAVIERLPALGHLAHEENPALIAALILRTAEKLENIE\n",
            "Generated Protein: MRIAVLRRREASRRREASREASREASAVLFRNGNPENGERERREASFRFRREASEGYHYHQWYHEGHGAVLHGAVLEGDMSLEGDEGDFSLHGAWHGAGAAAGAAMANHGNLDEGNLDHSQRYGNGPFGGNVDPAAAWPAAPPQRRAIHSAVLRAIRRKPKTAWNLDAPGFRPAAMELFRMELMELFRAWPPMANERAWMANHGFHEGMELSLPSSLPSAWRDEGEGDAWEGAWEGYHEGAEKLELYHEGMMEAPGAPGAPGAPG\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   4%|▍         | 118/3111 [01:43<43:05,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: MRLSVLLSLLPLALGAPAVERRAEAAPLIEARGERVANKYIVKFKEGSALSALDAAMEKISGKPDHVYKHVFRGAAATLDEEAVDVLRAHPDVEYIEQDAVVTINAEQTNAPWGLARISSTSPGTSTYTYDESAGQGSCVYVIDTGIEASHPEFEGRAQMVKTYYYSSRDGNGHGTHCAGTVGSKTYGVAKKTQLFGVKVLDDNGSGSYSGIIAGMDFVASDKNNRNCPKGVVASLSLGGGYSSSVNEAAARLVSSGVFVAVAAGNNNADARNYSPASEPSVCTVGASDRYDRRYSFSNYGSVLDIFAPGTSILSTWIGGSTRSISGTSMATPHVAGLAAYLMTLGKTNAAGACQVITDTANKGALSNIPSGTVNLLAYNGYQA\n",
            "Generated Protein: MSRYERGAAAVAAAVALTLALTLALTLWQQNPPWQQHCGNPENPEWAATRSTRSTPGFGRDAVSYQGPTGHCGFGKTPTGFGVVFGVVWIFIGKVLGRTSKVLGKVLGAPGFAQYVGILEGNQTNQTNQTNQTAAIDAVKGNPPNPENPEWGYGVVAAVVAAMVKPTGYGIPSSFTQGIPSSFTQGFTQGFTQGWQQFTQGFTQGFTQGFSSASDFASDFYGIIAGIIAGYVGYGTQGIPSSIPSSIPSSIPSSYVGIPSSYVGYVGYVEWQQWQQWQQGLVNTATPLKPGLVNGLPRYG\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   4%|▍         | 118/3111 [01:44<44:01,  1.13it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-746760c35f73>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0mcurriculum_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Curriculum over first half of training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training with sigma-gpt capabilities...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m train_with_random_order(\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-b6a0dd5990d5>\u001b[0m in \u001b[0;36mtrain_with_random_order\u001b[0;34m(model, train_loader, val_loader, num_epochs, device, curriculum_steps, l2_reg, sample_smiles)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m                     \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt_ref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opt_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# type: ignore[union-attr]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped_by_lr_sched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                             )\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    218\u001b[0m             )\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             adamw(\n\u001b[0m\u001b[1;32m    221\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mmaybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdisabled_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_fallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adamw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m     func(\n\u001b[0m\u001b[1;32m    783\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36m_multi_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_div_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq_sqrt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_add_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq_sqrt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    610\u001b[0m             torch._foreach_addcdiv_(\n\u001b[1;32m    611\u001b[0m                 \u001b[0mdevice_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hsqe5zYSJ5Bh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### generation"
      ],
      "metadata": {
        "id": "sLZXFhNq9xvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load the trained model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Path to model checkpoint\n",
        "checkpoint_path = \"/content/drive/MyDrive/classes+projects/plastic_enzyme_project/2024/codes/sigma_checkpoint.pth\"\n",
        "\n",
        "# Load model\n",
        "model = SigmaProtFlamingo(\n",
        "    model_path='nferruz/ProtGPT2',\n",
        "    max_len=914,  # Ensure this matches the training max_len\n",
        "    cross_attn_every=3,\n",
        "    dim_head=64,\n",
        "    heads=8,\n",
        "    perceiver_depth=2,\n",
        "    perceiver_num_latents=64\n",
        ").to(device)\n",
        "\n"
      ],
      "metadata": {
        "id": "vXlyfekIsTlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ProteinGenerationDataset"
      ],
      "metadata": {
        "id": "OS0GAkWg-aV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load trained weights\n",
        "model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
        "model.eval()\n",
        "\n",
        "# Load test data\n",
        "test_data = preprocess_snp_data('/content/augmented_test.csv')\n",
        "test_data = filter_datasets(test_data)\n",
        "\n",
        "# Create test dataset and dataloader\n",
        "test_dataset = ProteinGenerationDataset(test_data,max_length = 914 )\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "JHBmfbMT-FPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_autoregressively(model, smiles_string, max_length=914, temperature=1.0, random_order=False):\n",
        "    \"\"\"Generate protein autoregressively, with option to use random order\"\"\"\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    # Get SMILES embeddings\n",
        "    smiles_embeddings = model.polybert_encoder([smiles_string])\n",
        "    processed_smiles = model.smiles_perceiver(smiles_embeddings)\n",
        "\n",
        "    # Initialize with start token\n",
        "    input_ids = torch.tensor([[model.protGPT2_tokenizer.bos_token_id]], device=device)\n",
        "\n",
        "    # If using random order, generate a random permutation\n",
        "    if random_order:\n",
        "        order = torch.randperm(max_length, device=device).unsqueeze(0)\n",
        "    else:\n",
        "        order = torch.arange(max_length, device=device).unsqueeze(0)\n",
        "\n",
        "    # Track the current positions in the order\n",
        "    current_pos = 0\n",
        "\n",
        "    # Generated sequence in order's positions\n",
        "    generated_sequence = torch.full((1, max_length), model.protGPT2_tokenizer.pad_token_id, device=device)\n",
        "    generated_sequence[0, 0] = model.protGPT2_tokenizer.bos_token_id  # Start token\n",
        "\n",
        "    while current_pos < max_length - 1:\n",
        "        # Get the next position in the order\n",
        "        next_pos = current_pos + 1\n",
        "\n",
        "        # Forward pass to get next token prediction\n",
        "        with torch.no_grad():\n",
        "            # Use only the sequence up to the current position\n",
        "            current_order = order[:, :next_pos]\n",
        "            current_sequence = generated_sequence[:, current_order[0]]\n",
        "\n",
        "            # Get logits for the next token\n",
        "            logits, _ = model(\n",
        "                smiles_string,\n",
        "                order=current_order,\n",
        "                optimize=True\n",
        "            )\n",
        "\n",
        "            # Apply temperature and sample\n",
        "            logits = logits[0, -1, :] / temperature\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            next_token = torch.multinomial(probs, num_samples=1).item()\n",
        "\n",
        "            # Add the token to the generated sequence at the next position in the order\n",
        "            generated_sequence[0, order[0, next_pos]] = next_token\n",
        "\n",
        "            # Check for EOS token\n",
        "            if next_token == model.protGPT2_tokenizer.eos_token_id:\n",
        "                break\n",
        "\n",
        "            current_pos = next_pos\n",
        "\n",
        "    # Decode the generated sequence\n",
        "    generated_ids = generated_sequence[0].tolist()\n",
        "    print('generated_ids',generated_ids)\n",
        "    # Remove padding tokens\n",
        "    generated_ids = [id for id in generated_ids if id != model.protGPT2_tokenizer.pad_token_id]\n",
        "    seq = model.protGPT2_tokenizer.decode(generated_ids, skip_special_tokens=True)\n",
        "    print('seq',seq)\n",
        "    print(\"autoregressive gen done...\")\n",
        "    return seq\n"
      ],
      "metadata": {
        "id": "Sgmyq7fJ8kAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_with_rejection_sampling(model, smiles_string, max_length=914, num_orders=5, temperature=1.0):\n",
        "    \"\"\"Generate protein using token-based rejection sampling with proper MH acceptance ratio\"\"\"\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    # Get SMILES embeddings\n",
        "    smiles_embeddings = model.polybert_encoder([smiles_string])\n",
        "    processed_smiles = model.smiles_perceiver(smiles_embeddings)\n",
        "\n",
        "    # Initialize with start token\n",
        "    prompt = torch.tensor([[model.protGPT2_tokenizer.bos_token_id]], device=device)\n",
        "\n",
        "    # Initialize full sequence with padding\n",
        "    full_seq = torch.full((1, max_length), model.protGPT2_tokenizer.pad_token_id, device=device)\n",
        "    full_seq[:, 0] = model.protGPT2_tokenizer.bos_token_id  # Start token\n",
        "\n",
        "    # Track positions that have been filled\n",
        "    filled_positions = {0}  # Start with position 0 filled\n",
        "\n",
        "    while len(filled_positions) < max_length:\n",
        "        remaining_positions = [i for i in range(max_length) if i not in filled_positions]\n",
        "        if not remaining_positions:\n",
        "            break\n",
        "\n",
        "        # Step 1: Sample tokens at all remaining positions from marginal distribution\n",
        "        # This is our proposal distribution p(x̃)\n",
        "        candidate_tokens = {}\n",
        "        proposal_probs = {}  # Store the probability of each proposal\n",
        "\n",
        "        for pos in remaining_positions:\n",
        "            # Create current filled sequence context\n",
        "            current_context = torch.ones((1, max_length), device=device) * model.protGPT2_tokenizer.pad_token_id\n",
        "            for filled_pos in filled_positions:\n",
        "                current_context[0, filled_pos] = full_seq[0, filled_pos]\n",
        "\n",
        "            # Get logits for this position given current context\n",
        "            with torch.no_grad():\n",
        "                # Order that puts this position last\n",
        "                context_order = torch.tensor([list(filled_positions) + [pos]], device=device)\n",
        "\n",
        "                logits = get_logits_for_position(model, current_context, context_order, smiles_string, pos)\n",
        "\n",
        "                # Sample a token and record its probability\n",
        "                logits = logits / temperature\n",
        "                probs = F.softmax(logits, dim=-1)\n",
        "                token_dist = torch.distributions.Categorical(probs)\n",
        "                token = token_dist.sample().item()\n",
        "\n",
        "                candidate_tokens[pos] = token\n",
        "                proposal_probs[pos] = probs[0, token].item()\n",
        "\n",
        "        # Step 2: Evaluate acceptance under different orders\n",
        "        best_order_acceptances = []\n",
        "\n",
        "        for _ in range(num_orders):\n",
        "            # Create a random permutation of remaining positions\n",
        "            eval_order = random.sample(remaining_positions, len(remaining_positions))\n",
        "\n",
        "            accepted_tokens = []\n",
        "            accepted_positions = []\n",
        "            acceptance_ratios = []\n",
        "\n",
        "            # Try to accept tokens in this order\n",
        "            for pos in eval_order:\n",
        "                # Create sequence with previously accepted tokens\n",
        "                temp_seq = full_seq.clone()\n",
        "                for acc_pos in accepted_positions:\n",
        "                    temp_seq[0, acc_pos] = candidate_tokens[acc_pos]\n",
        "\n",
        "                # Get conditional probability q(x̃|X,x̃σ<i)\n",
        "                filled_plus_accepted = list(filled_positions) + accepted_positions\n",
        "                context_order = torch.tensor([filled_plus_accepted + [pos]], device=device)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    cond_logits = get_logits_for_position(\n",
        "                        model, temp_seq, context_order, processed_smiles, pos\n",
        "                    )\n",
        "\n",
        "                    cond_probs = F.softmax(cond_logits / temperature, dim=-1)\n",
        "                    cond_prob = cond_probs[0, candidate_tokens[pos]].item()\n",
        "\n",
        "                # Compute acceptance ratio r = q(x̃i|X,x̃σ<i) / p(x̃i|X)\n",
        "                # Where p(x̃i|X) is the proposal probability\n",
        "                acceptance_ratio = min(1.0, cond_prob / proposal_probs[pos])\n",
        "\n",
        "                # Decide whether to accept\n",
        "                if random.random() < acceptance_ratio:\n",
        "                    accepted_tokens.append(candidate_tokens[pos])\n",
        "                    accepted_positions.append(pos)\n",
        "                    acceptance_ratios.append(acceptance_ratio)\n",
        "                else:\n",
        "                    # Stop at first rejection\n",
        "                    break\n",
        "\n",
        "            best_order_acceptances.append((accepted_positions, accepted_tokens, acceptance_ratios))\n",
        "\n",
        "        # Step 3: Dynamic token acceptance\n",
        "        best_order_idx = -1\n",
        "        max_accepted = -1\n",
        "        min_sequence_idx = -1\n",
        "\n",
        "        for idx, (accepted_positions, _, acceptance_ratios) in enumerate(best_order_acceptances):\n",
        "            if len(accepted_positions) > max_accepted:\n",
        "                max_accepted = len(accepted_positions)\n",
        "                best_order_idx = idx\n",
        "                # Find the minimum position in the sequence where we see a rejection\n",
        "                if len(accepted_positions) < len(remaining_positions):\n",
        "                    min_sequence_idx = len(accepted_positions)\n",
        "                else:\n",
        "                    min_sequence_idx = len(remaining_positions)\n",
        "\n",
        "        # No need to calculate min across orders if all orders accept all tokens\n",
        "        if min_sequence_idx == -1:\n",
        "            min_sequence_idx = len(remaining_positions)\n",
        "\n",
        "        # Get the best order\n",
        "        best_order = best_order_acceptances[best_order_idx]\n",
        "        accepted_positions, accepted_tokens, _ = best_order\n",
        "\n",
        "        # Limit acceptance to positions before the minimum rejection\n",
        "        accepted_positions = accepted_positions[:min_sequence_idx]\n",
        "        accepted_tokens = accepted_tokens[:min_sequence_idx]\n",
        "\n",
        "        # Update the sequence with accepted tokens\n",
        "        for pos, token in zip(accepted_positions, accepted_tokens):\n",
        "            full_seq[0, pos] = token\n",
        "            filled_positions.add(pos)\n",
        "\n",
        "            # Check for EOS token\n",
        "            if token == model.protGPT2_tokenizer.eos_token_id:\n",
        "                break\n",
        "\n",
        "    # Decode the generated sequence\n",
        "    result = model.protGPT2_tokenizer.decode(\n",
        "        [t for t in full_seq[0].tolist() if t != model.protGPT2_tokenizer.pad_token_id],\n",
        "        skip_special_tokens=True\n",
        "    )\n",
        "    return result\n",
        "\n",
        "def get_logits_for_position(model, sequence, order, smiles_string, target_position):\n",
        "    \"\"\"Helper function to get logits for a specific position\"\"\"\n",
        "    # Run model forward pass\n",
        "    logits, _ = model(\n",
        "        smiles_string,  # Pass the SMILES string\n",
        "        order=order,\n",
        "        optimize=True\n",
        "    )\n",
        "\n",
        "    # Return logits for target position (last position in the order)\n",
        "    return logits[:, -1, :]"
      ],
      "metadata": {
        "id": "Koy4bjRHu5hx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "IhpdI0vMXdUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_on_unique_smiles(model, test_loader, device, output_file=\"generated_proteins_comparison.json\"):\n",
        "    \"\"\"Generate proteins using both methods on unique SMILES from test set\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Collect unique SMILES from the test loader\n",
        "    unique_smiles = set()\n",
        "    for batch in test_loader:\n",
        "        unique_smiles.update(batch['smiles'])\n",
        "\n",
        "    unique_smiles = list(unique_smiles)  # Convert to list\n",
        "    print(f\"Found {len(unique_smiles)} unique SMILES in test set\")\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # Generate proteins using both methods and time each generation\n",
        "    for i, smiles in enumerate(tqdm(unique_smiles, desc=\"Generating proteins\")):\n",
        "        # Track time for autoregressive generation\n",
        "        start_time = time.time()\n",
        "        print('autoregressive generations...')\n",
        "        print(f\"Generating protein for SMILES: {smiles}\")\n",
        "        ar_protein = generate_autoregressively(model, smiles, max_length=914, temperature=1.0, random_order=False)\n",
        "        print(ar_protein)\n",
        "        ar_time = time.time() - start_time\n",
        "\n",
        "        # Track time for rejection sampling\n",
        "        start_time = time.time()\n",
        "        print('rejection sampling generations...')\n",
        "        print(f\"Generating protein for SMILES: {smiles}\")\n",
        "        rs_protein = generate_with_rejection_sampling(model, smiles, max_length=914, num_orders=5, temperature=1.0)\n",
        "        print(rs_protein)\n",
        "        rs_time = time.time() - start_time\n",
        "\n",
        "        results.append({\n",
        "            'SMILES': smiles,\n",
        "            'Autoregressive': {\n",
        "                'protein': ar_protein,\n",
        "                'time_seconds': ar_time\n",
        "            },\n",
        "            'Rejection_Sampling': {\n",
        "                'protein': rs_protein,\n",
        "                'time_seconds': rs_time\n",
        "            }\n",
        "        })\n",
        "\n",
        "        # Print progress occasionally\n",
        "        if (i + 1) % 5 == 0:\n",
        "            print(f\"\\nCompleted {i+1}/{len(unique_smiles)}\")\n",
        "            print(f\"Example - SMILES: {smiles}\")\n",
        "            print(f\"Autoregressive: {ar_protein[:50]}... ({ar_time:.2f}s)\")\n",
        "            print(f\"Rejection Sampling: {rs_protein[:50]}... ({rs_time:.2f}s)\")\n",
        "\n",
        "    # Save results to JSON\n",
        "    with open(output_file, 'w') as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "\n",
        "    # Calculate and print average times\n",
        "    ar_times = [r['Autoregressive']['time_seconds'] for r in results]\n",
        "    rs_times = [r['Rejection_Sampling']['time_seconds'] for r in results]\n",
        "\n",
        "    print(f\"\\nGeneration complete!\")\n",
        "    print(f\"Average autoregressive generation time: {np.mean(ar_times):.2f}s\")\n",
        "    print(f\"Average rejection sampling generation time: {np.mean(rs_times):.2f}s\")\n",
        "    print(f\"Speed improvement: {np.mean(ar_times)/np.mean(rs_times):.2f}x\")\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "2azHLfyMXUyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = evaluate_on_unique_smiles(model, test_loader, device, output_file=\"sigma_gpt_comparison_results.json\")"
      ],
      "metadata": {
        "id": "2xKIwu3LXe7K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}